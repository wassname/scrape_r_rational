## [D] Monday General Rationality Thread

### Post:

Welcome to the Monday thread on general rationality topics!  Do you really want to talk about something non-fictional, related to the real world?  Have you:

* Seen something interesting on /r/science?
* Found a new way to get your shit even-more together?
* Figured out how to become immortal?
* Constructed artificial general intelligence?
* Read a neat nonfiction book?
* Munchkined your way into total control of your D&D campaign?


### Comments:

- u/xamueljones:
  ```
  Last night, I had a strange dream where I became a [posthuman](https://en.wikipedia.org/wiki/Posthuman) in a variety of ways. One resulted in me becoming an unfeeling machine of logic, another I turned into a hive-mind of millions, an individual accelerated beyond all reason with the ability to think for thousands of years on a problem within the span of one second, a godlike being with the power to shape everything within my view, an omnisavant capable of learning every field of knowledge, and other superhuman feats of imagination.

  I blame these dreams on reading [Simulacrum: A Post-Singularity Story](https://gamesoftranscendi.wordpress.com/) before bed the night before. I wouldn't consider it a rational story, but it's a very intruging take on the Singularity.

  However with the passing of my dreams as I woke up, I find myself pondering questions about what would happen if a human, *not an AI*, were to become a superintelligence.

  * Would they have emotions like we do? Many people seem to think being smart means being cold and unfeeling. I call bullshit on this. Emotions are not a force that opposes logic. Our emotions dictate goals and desires that we fulfill. Logic is simply how we determine the path to best fulfill out goals. This [comic page](http://strongfemaleprotagonist.com/issue-7/page-83-3/) is the best statement of this idea I have ever encountered. Therefore I can't help but think a posthuman would actually feel more strongly and diversely than we do as humans.
  * Will communication be possible among all posthumans? Because humans are a tiny dot on the [space of all possible minds](https://raw.githubusercontent.com/tricycle/lesswrong/master/r2/r2/public/static/imported/2008/06/24/mindspace_2.png), and it is virtually guaranteed that there will be more ways to be a posthuman than there are to be a human. With such radically divergent minds, would communication be possible between any two existing minds despite having incredible intelligence at their command?
  * Would they compete over resources? In many stories about an AI becoming superintelligent, there is a common fear and worry that they would eliminate humanity not out of any fear or hatred, but because we use/are resources that can be better used for their goals. I wonder if posthumans will complete over resources like we do today or if they would be capable of making a utopian society where everyone cooperates instead?
  * Will there be more than a few posthumans? It's an extension of the previous question. It's understood that cognition requires energy and while humans as designed by evolution are pretty inefficient, it can be understood that a posthuman will likely require enormous levels of energy beyond what is easily available to a human today. Much like how the AI to first appear might act to prevent the development of any future AIs to monopolize any life-sustaining resources, I wonder if the first posthuman will act to stop any future posthumans to ensure the monopolization of resources?

  I would love to discuss any of the questions above or anything else about the idea of posthumans.
  ```

- u/SvalbardCaretaker:
  ```
  Friendly reminder that on wednesday, 26.September is Petrov Day! A perfect opportunity to invite (non-X-risk aware) friends, raise a glass for a toast and talk to them about that time a single person prevented nuclear war.
  ```

- u/DunkelBeard:
  ```
  Got around to reading 'The Dictator's Handbook', found it pretty engaging - especially as I'd just read 'The Prince'. 

  &#x200B;

  Any book recommendations (academic or otherwise) that follow on from the ideas presented in the handbook? Like how to structure a political system that assumes each agent is not altruistic (so any altruism that appears is a delightful bonus)?
  ```

---

