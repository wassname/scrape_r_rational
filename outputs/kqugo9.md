## [RST][HSF][TH] Lena by Sam 'qntm' Hughes

### Post:

[Link to content](https://qntm.org/mmacevedo)

### Comments:

- u/vimefer:
  ```
  Well, this was exactly the Black Mirror-esque meta-horror I expected from the very first mention of lossy compression.

  Thanks, I hate where it logically went, though I'm enough of an optimist to expect slavery would be re-abolished again eventually.

  There's no exploration of using more recent uploads as tutors or companions for the original image or its branches ? Humans are hyper-social, it makes sense to have them working in groups / tribes instead of in what is essentially solitary confinement.
  ```

  - u/Frommerman:
    ```
    But this is exactly what you expect of capitalism. If they can create a workforce which necessarily subsists on a substrate entirely controlled by the ownership class, you can fucking bet they'll make exactly that.

    Remember that we haven't even abolished slavery. Not really. For one, effective slavery is still entirely legal in many countries, and many of our consumer goods are made in those places. Second, we're still allowed to enslave prisoners in the US, even when the only conceivable beneficiary of the enslavement is a private corporation. Third, chattel slavery by birth or race may have been abolished, but nearly everyone is still compelled to work on pain of starvation. We have enough resources not to need so many workers, as has been conclusively proven by employment statistics during the pandemic, but our society is structured such that automation of positions *hurts people.*
    ```

    - u/SimoneNonvelodico:
      ```
      > But this is exactly what you expect of capitalism.

      I think this is a problem that runs a bit deeper than capitalism. In any economic system, having free human labor accessible even at the individual level would provide obvious benefits. You get more labor, hence more stuff done, which raises your standards of living. If such a thing is possible and cheap, the only thing stopping you would be morals. Reasonably, a certain percentage of people will not let morals stop them. Especially if there are no actual social consequences for the infractions, or if you can easily get away with it anyway.
      ```

      - u/Frommerman:
        ```
        I think you're just wrong here. You can't get free human labor except through coercion, and that coercion represents both a reduction in economic efficiency and an obvious moral failing.  In this example, the coercion comes from the fact that you can threaten to torture the sim for subjective centuries if they fail to comply, and it's obviously true that this threat is a real one.
        ```

        - u/SimoneNonvelodico:
          ```
          I'm wrong on what? I'm not denying anything of what you're saying; I'm denying that it is an inherent problem with capitalism. In fact, while capitalism has had slavery (and to an extent, still does today), slavery vastly predates it. Feudalism was based on serfdom, which while not being slavery still required some significant restrictions of personal freedom. And before that, the Roman Empire had something that's hard to define if not as a servile economy; an economy whose very foundation was the enslavement of large groups of people and the plunder of their resources, to the point that it basically started collapsing when it ran out of lands to conquer. And the reduction in economic efficiency is subjective. Sure, you're doing less work than you would with two willing laborers. But the slave is the one who suffers a net loss, while you still get a gain. Slavery, like theft or murder, exists as long as the opportunity for it is there and someone with no scruples takes advantage of it.
          ```

          - u/Frommerman:
            ```
            I was objecting to the 'obvious benefits' bit. Slavery actually benefits nobody because of how much it holds humanity back. How many potential brilliant scientists have died in a ditch somewhere because they were born to slaves? What could they have produced, which would have pushed humanity further than it is even now? I honestly, truly believe, that even the slaveholders of the American traitor states would have been *better off* if slavery had never been a thing, because we might be centuries ahead of where we were by then.

            These systems manage to even oppress the oppressors, is what I'm saying. It binds them to a status quo which is worse than what it could be even for them.
            ```

            - u/SimoneNonvelodico:
              ```
              > Slavery actually benefits nobody because of how much it holds humanity back. How many potential brilliant scientists have died in a ditch somewhere because they were born to slaves?

              Ehh, that's kind of a game theory thing. Yes, collectively, humanity might benefit without it (I'm not sure that's always precisely the case, especially in antiquity, for example, when even without slavery it's likely there would have been a large underclass in subsistence conditions anyway). But the individual gets an immediate edge. Is it short-term? Sure. But short term individual gains over long term collective ones are a bane of our history again and again. It's kind of a variant of the tragedy of the commons, where the commons are less technologically or politically advanced people that you can just coerce at minimal cost to yourself.
              ```

  - u/SimoneNonvelodico:
    ```
    > I'm enough of an optimist to expect slavery would be re-abolished again eventually

    Dunno, in this scenario, isn't that as hard as abolishing digital piracy? Slave plantations are harder to hide than a few files on a PC.
    ```

    - u/Empiricist_or_not:
      ```
      >Dunno, in this scenario, isn't that as hard as abolishing digital piracy? Slave plantations are harder to hide than a few files on a PC.

      I bet a lot of it will depend on: how legally protected the digital slavery is, how many free uploads there are, and how much the Overton window is established on the balance of the idea that an uploads is a person vs a upload is a arbitrarially long number.

      On the plus side this is one of the few times I'm heartened by the idea of cooperate personhood.  A corporation that owns your upload and is responsible to a trust established to execute per your uploads wishes, with a lot of additional safeties in place so the executor cant act against your upload's wishes and measures for copy-clan arbitration may cost more than your runtime, but it's at least a path to functional personhood, if you secure the original IP rights and that's a hell of an if.
      ```

      - u/SimoneNonvelodico:
        ```
        > how much the Overton window is established on the balance of the idea that an uploads is a person vs a upload is a arbitrarially long number.

        I really wouldn't hold my breath there. We're deep to our neck into "machines can't possibly be people" rhetoric. Everyone who's religious and believes in a soul has all reasons to believe in organic supremacy, so to speak. Naturalistic fallacies are incredibly hard to kill, and worse, in some cases even progressive forces have opted to roll with them (and thus feed them) rather than run counter the tremendous cultural barrier that they constitute - arguably one of the worst beliefs weighing us down. Consider how many people keep arguing in all seriousness something as stupid as "we should let ourselves catch diseases because natural immunity is TEH BEST". You would have a really really hard time convincing anyone that simulated brains are people. It took various centuries to convince most whites that black people are people, and even then, not everyone is convinced yet.

        Consider this - for all we know, we might have *right now* machines that edge on sentience. We don't really know what sentience even is, after all. Is a cat sentient? Is a mouse? A bug, in a very simple, basic way? We certainly have neural networks that exceed the complexity of some of the simpler invertebrates. Didn't they simulate the full connectome of a worm some time ago and put it into a LEGO robotic body? Depending on where the line is drawn, we could already be doing whatever the hell we want with things that, were they made of neurons and flesh, would already be subject to basic animal rights protection laws if for example used for experiments.
        ```

        - u/zorianteron:
          ```
          >we should let ourselves catch diseases because natural immunity is TEH BEST

          Kids raised in sterile environments have their immune systems grow malformed, which is why allergy rates in developed countries are vastly above developing ones- we're calibrated for a certain rate of pathogen-invasion, and if the immune system doesn't see that, it oversensitizes.  

          You should let  your kids roll around in the mud every now and again if you don't want them to die from eating a peanut.
          The naturalistic heuristic exists because it's sometimes/often right- or rather, there's low-probability but high-severity risks in novelty.  
          Most of the new things might be fine, but it only takes one- say you get a job painting radium clocks- to kill you.
          Most of those foreign tribes are fine, but it only takes one to give you a disease you're not resistant to and wipe you out.
          ```

          - u/SimoneNonvelodico:
            ```
            This is a bit different though, you're reasoning in terms of "we evolved so and so and are optimised for certain conditions". But for example we did NOT co-evolve with SARS-CoV-2, so aspiring to developing natural immunity for it is nonsense, vaccines are obviously the way to go. The naturalistic fallacy is seeing nature as better by default, or worse, investing it of some kind of superior moral quality. Which leads to genius takes such as "no AI could possibly be as worthy of rights as a human because it's not natural" or "you should just keep the sex you were born with regardless of how shit that makes you feel".
            ```

  - u/Sinity:
    ```
    > Thanks, I hate where it logically went, though I'm enough of an optimist to expect slavery would be re-abolished again eventually.

    The thing is, it's pretty much impossible. Once your scan is out-there, widely distributed... how exactly do you undo it? Anyone could have it, occupying a tiny part of their storage. Encrypted. Running using almost no computational resources.

    There's one singularity scenario which is fairly safe; singleton FAI + 0 privacy whatsoever from it.
    ```

    - u/vimefer:
      ```
      That's why I'm looking at the incentives for using it non-slave-ly instead.
      ```

    - u/RMcD94:
      ```
      The abolishment of privacy is the only way to secure anything.

      Consider the future of thought crime when ai can think about someone and this results in a simulacrum of much higher quality than your internal model of someone
      ```

    - u/SimoneNonvelodico:
      ```
      It does raise an interesting issue about the possibility of utilitarian Luddism. Doing everything possible to *stop* technological progress before it reaches that point because even if it carries some benefits, they can’t possibly offset the near infinite guaranteed amount of suffering inflicted to sentient (albeit not physical) beings.
      ```

      - u/Sinity:
        ```
        TBF it's all talk about worst-case scenarios and assumptions of maximal malice. People, in general, probably wouldn't set up ~eternal torture of an mind upload even if they were able to do so.

        Present is already pretty _scary_ with this mindset. If someone wanted to torture people, just for the sake of it, they'd have high chance of success if they're minimally competent.

        We're just mostly relying on trust that people around us aren't going to kidnap us for no reason.

        ---

        'Kidnapping" a mind upload is of course much, much worse through.

        Also, ethically, world can be unfathomably bad anyway, and there might be nothing possible to do to fix it. If many-words interpretation of QM is correct, and identity/consciousness doesn't work in a surprising way, quantum immortality is true. Which, if you couple it with heat death of the universe means inevitable personal hell for everyone. Even ignoring consequences of many-words QM, there's nature of existence problem; what if all possible universes exist?
        ```

        - u/SimoneNonvelodico:
          ```
          > People, in general, probably wouldn't set up ~eternal torture of an mind upload even if they were able to do so.

          No, but they would do it for funsies or to see what happens for a while. And others would simply put the mind to work for them, reassured by the thought that "it's not a real person".

          Look at what we do to farm animals. Pigs are quite smart. And if it was possible and useful to us, we'd do it to dolphins and chimpanzees on a similar scale, even though they have awareness high enough to be comparable to ours.

          > We're just mostly relying on trust that people around us aren't going to kidnap us for no reason.

          Trust but also a very high barrier to access. Keeping someone kidnapped, hidden, fed, unable to escape, and getting away with it is hard. Keeping a file on your hard drive is much easier. The bigger the crime, the more people need to be in on the conspiracy or at least willing to let it slide, and thus the harder for the crime to be committed. How many people might own pedopornographic material and we will never even know about it?

          > Also, ethically, world can be unfathomably bad anyway, and there might be nothing possible to do to fix it. If many-words interpretation of QM is correct, and identity/consciousness doesn't work in a surprising way, quantum immortality is true. Which, if you couple it with heat death of the universe means inevitable personal hell for everyone. Even ignoring consequences of many-words QM, there's nature of existence problem; what if all possible universes exist?

          That is a different issue, and one that would be out of our control. Though thinking about this made me go on a different tangent. Suppose MW is true. Then there are certainly infinite (albeit an infinitesimal fraction of the total) futures in which I keep surviving, against all odds, billions of years old, in an empty universe. However there are also infinite (albeit an even smaller infinitesimal fraction of the total) futures in which entropy spontaneously reverses and I exist on an Earth-like planet, quite well off. Now, while *getting* there is a lot more unlikely, *staying* in that branch of the wavefunction is a lot easier, because now we don't need to offset the instant-by-instant near certainty of me dying in the vacuum of space. My wavefunction is vanishing exponentially in the "heat death" branch, but propagates steadily in time and branches out in the "entropy reversed" branch, thus causing it to weigh a lot more in the total. Enough to offset its initial improbability? Hard to say. The final outcome is one of those tricky sums over an infinite number of infinitesimally small terms, and in cases like this, the actual functions matter.
          ```

- u/LazarusRises:
  ```
  I simultaneously really want to know what red-/blue-washing are and really, really don't.
  ```

  - u/Audere_of_the_Grey:
    ```
    Seems fairly clear that they correspond with extreme forms of punishment and reward respectively, using direct alteration/stimulation of the brain state. A highly accelerated brainwashing regimen.
    ```

    - u/alexanderwales:
      ```
      Yes, also heavily implied in a later part of the story:

      > MMAcevedo does respond to red motivation, though poorly.
      ```

  - u/GreenSatyr:
    ```
    They are blueberries and red lollipops don't worry ❤💙❤💙
    ```

- u/Empiricist_or_not:
  ```
  For those of us signed up for cryonics or planning that way, what legal machinery have you set up to preclude this, or other forms of mind capture?

  I see all of this discussion of capitalism, but I see a basic failure in lawafare where the logical extension of rights never happened implied in a few short phrases: "who had been scanned involuntarily"  "A series of landmark U.S. court decisions found that Acevedo did not have the right to control how his brain image was used, with the result that MMAcevedo is now by far the most widely distributed, frequently copied, and closely analysed human brain image."  (US 5th amendment; if your intellect isn't your intellectual property well. . ., and probably a 1st amendment violation if Catholicism goes the anti-upload way most authors expect it will); "red-washing, blue-washing," (yup no personhood recognition for uploads so no 8th amendment protection against cruel and unusual punishment).  

  A more hopeful counterpoint is of course DataPacRat's: [FAQ on LoadBear's Instrument of Precommitment](https://docs.google.com/document/d/1nRSRWbAqtC48rPv5NG6kzggL3HXSJ1O93jFn3fgu0Rs/mobilebasic)
  ```

  - u/awesomeideas:
    ```
    Of course, there would be those who might simulate LoadBear/DataPacRat just to punish him for not finishing stories...
    ```

    - u/Empiricist_or_not:
      ```
      Eh. I think 2k a year would be too much for that, but hiring him to finish stories might be cool if I ever get the resources.  Positive reinforcement is usually better, you might see if yuo ca find him on Patreon or Koff-fi.
      ```

- u/None:
  ```
  Hopefully, we'll have a friendly AI to protect our uploaded minds from this.
  ```

- u/Nic_Cage_DM:
  ```
  well that's terrifying
  ```

- u/VanPeer:
  ```
  Sounds like the plot of [Capacity](https://www.amazon.com/Capacity-AI-Trilogy-Tony-Ballantyne/dp/0553589296) by Tony Ballantyne.
  ```

- u/cysghost:
  ```
  r/TIHI

  Great, and absolutely horrifying story!
  ```

- u/-main:
  ```
  This gives a more plausible scenario IMO than Hanson's Age of Em.
  ```

---

