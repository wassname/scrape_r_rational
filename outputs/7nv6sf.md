## [D] Wednesday Worldbuilding Thread

### Post:

Welcome to the Wednesday thread for worldbuilding discussions!

/r/rational is focussed on rational and rationalist fiction, so we don't usually allow discussion of scenarios or worldbuilding unless there's finished chapters involved (see the sidebar).  It *is* pretty fun to cut loose with a likeminded community though, so this is our regular chance to:

* Plan out a new story
* Discuss how to escape a supervillian lair... or build a perfect prison
* Poke holes in a popular setting (without writing fanfic)
* Test your idea of how to rational-ify *Alice in Wonderland*

Or generally work through the problems of a fictional world.

^(Non-fiction should probably go in the Friday Off-topic thread, or Monday General Rationality)


### Comments:

- u/callmesalticidae:
  ```
  There's this science fiction setting that I've been kicking around in my head (if that doesn't imply a much greater level of development than what it's got so far). 

  I'm aiming for a space opera kind of thing along the lines of *Dune* or some aspects of *Star Wars*. A major aspect of the setting is that, somewhere along the line, people had ideas about how they wanted the universe to work and they had the power to enforce those ideas. Maybe it was a superintelligent A.I. That part isn't important right now. 

  The important bit is what they wanted: for history to be a *human* story, where humans are the protagonists of their own stories. To the people that built the future, this meant removing any technology whose purpose could be accomplished by humans (and therefore can be interpreted as replacing humans). Weirdly, the story that comes to mind most readily is that of the Finnish sniper Simo Häyhä, who killed up to five hundred soldiers in the Winter War: how much of this accomplishment would have been his, had he been wielding an auto-targeting rifle that even guided his hands into the proper position? 

  I'm wondering how far I should go with this, though. Even given the strictest interpretation, spaceships will be a thing because there are no circumstances in which a human can travel through space unassisted. 

  What about power generation, though? Humans can turn cranks, even if that's terribly inefficient. 

  Computers definitely won't be allowed for many things, but should they be totally disallowed? Part of me says "yes," but another part of me says that if, say, the calculations being made would take more than a human lifetime to complete, then it's okay. Basically, pocket calculators are out, but Future!NASA can still run climate simulations. 

  People can beat each other to death with their fists, so are weapons banned? That seems going kind of overboard!

  Unless this is a story of hunter-gatherers who periodically board space ships, "No technology that does things that a human could do" can't be the *whole* story, then, even if it's a good enough summation that most people describe it that way. 

  Even so, I think that most things are handmade, and the only stuff that isn't is what *can't* be: very fine circuitry, spaceship parts, etc. 

  I've got some other random stuff that I've been spitballing, but it's tangential from this part so I'll end my post here.
  ```

  - u/CCC_037:
    ```
    I think that there's a very simple way to do this, and it is this: all *decisions* must be made by humans, and no technology must be permitted to *make decisions* on its own.

    To take your example of the sniper; he is permitted his sniper rifle, because it makes no decisions. He is not permitted an auto-targeting sniper rifle, because that makes the decisions for him. Power generation? As long as a human decides how much power is generated, and where it goes to, you can generate all the power you want. Spaceships? They require human pilots, who make all the decisions. Weapons? Lightsabers, pistols, sniper rifles, nuclear explosives are all allowed; self-targetting drones are not, because they are making their own decisions.

    Since humans make all the decisions, therefore, history is forced to be a human story.
    ```

    - u/trekie140:
      ```
      In real life we’re currently dealing with the problem of humans being influenced by bots and algorithms sending them information to optimize their likelihood of making decisions that make the company money. 

      How does a computer “just following orders” or a human otherwise using technology to effect other humans decision-making ability fall under this paradigm? What’s the point where it stops being a human decision?
      ```

      - u/CCC_037:
        ```
        This is where we start to get into gray areas.

        On the one end of the spectrum, we have a telephone; Alice talks to the telephone, and the telephone transmits her voice to Bob, and Alice tries to influence Bob's decision. In this case, there are very clearly no non-human decisions being made, and thus this is acceptable.

        On the other end of the spectrum, there is an Persuasion Machine. Alice goes to the Persuasion Machine, and tells it "Persuade Ben to choose X", and it persuades Ben to choose X. In this case, there are several decisions (especially as regards how to persuade Ben) that the machine is making, and this is obviously disallowed.

        Between the two, there is a spectrum of prediction bots and algorithms influencing human decisions - some of them influencing the decisions of their own designers, quite unintentionally (e.g. a weather prediction algorithm with an unintentional bias towards predicting rain might make someone less likely to go on a picnic). Even a large, colourful sign saying "Lowest Prices" will influence human decisions to some degree.

        Hmmmmm.

        Clearly humans must be permitted to influence each other, or there will be no communication at all. So the telephone is permitted. And Alice calling up Bob and saying "you should shop here, our prices are cheaper than the place down the road" is, in my view, pretty clearly permissible.

        The question, then, comes in two parts. The first is whether or not Alice can call up Bob on the phone and say "you should shop here, *the computer says* our prices are cheaper than the shop down the road". And the second is whether Alice can record herself saying "you should shop here, our prices are cheaper than the shop" and play that recording down every phone in the street at once.

        I'd say yes to the first and no to the second; Alice can claim that the computer says anything to Bob, but she has to handle the process one-on-one, in a sense 'piloting' the conversation and making all the decisions (even if that involves pulling information from predictive algorithms), but she can't *automate* the process.

        Does that seem like a sensible place to draw the line to you?
        ```

        - u/trekie140:
          ```
          It does. The definition of automated can be tricky, but I like the idea of every machine requiring an operator in order to work even if it’s just to regularly push a button.
          ```

        - u/ben_oni:
          ```
          I don't follow.

          If Alice designs a persuasion algorithm, why shouldn't she be able to let a bot following the algorithm persuade Bob? As long as the algorithm is deterministic in nature, by using a bot Alice has simply pre-committed to following that particular decision-making scheme.

          If you draw the line at *automation*, then it's not decision making that's the issue, but u/callmesalticidae's original idea: removing any technology whose purpose could be accomplished by humans.
          ```

          - u/CCC_037:
            ```
            A deterministic algorithm can still be considered to be making decisions - even though the decision is completely deterministic (along the lines of "IF Bob.Income > 10000 THEN Offer Discount").

            I'm not saying that this is a good idea, or even a feasible idea; I'm merely presenting it as a possible method by which to reach u/callmesalticidae's aim of ensuring that "history is a human story" (along with, of course, completely obliterating any intelligent aliens - a course of action I also do not condone).
            ```

    - u/ben_oni:
      ```
      So, flipping a coin or rolling a die is right out.
      ```

    - u/callmesalticidae:
      ```
      That works pretty well. I don't know why I didn't think of that!
      ```

  - u/Peewee223:
    ```
    > People can beat each other to death with their fists, so are weapons banned? That seems going kind of overboard!

    I agree - People can't cut things without a blade, and people can't put holes in people from a distance without guns. 

    > What about power generation, though? Humans can turn cranks, even if that's terribly inefficient. 

    Same deal as the climate simulations - a healthy laborer can only realistically sustain [75W](https://en.wikipedia.org/wiki/Human_power) for an 8 hour shift. A thousand people working in rotating 8 hour shifts can only put out 25KW. What's the cutoff for parallel calculations done by humans, anyway? Judging by a randomly selected benchmark (bitcoin mining), my GPU on its own is approximately 1*10^13 times faster at calculating than I am... or ~1500 times faster than every human in the world calculating things in their head simultaneously.

    Another interesting idea is that reading and writing is, strictly speaking, unnecessary - people can speak, understand one another, and remember a great deal of stories after all. This also comes with a free explanation of why nobody's gone and reinvented the lost knowledge - the pseudoluddites burned all the books and technical manuals.
    ```

  - u/Weebcluse:
    ```
    In this scenario, was the knowledge to create forbidden tech removed by force with some kind of enforcement agency making rediscovery difficult, or was the laws of the universe changed so the forbidden tech is impossible to make?
    ```

- u/Nulono:
  ```
  I've been mulling over an idea of a world in which people have very limited precognition, granted through either technological or arcane means. Essentially, this would manifest as a momentary burst of alertness at a moment specified after that moment has passed.

  Say, for example, a woman discovers she's forgotten her cell phone when she arrives at work. She can send a small "blip" back to herself that morning when she put it down on her desk, which could serve as a reminder to pick it back up.

  Is there a reasonably consistent, non-arbitrary way to limit this power so that it's useful for simple, mundane tasks such as "Don't forget your keys!" and "That's salt, not sugar!" but not for more complicated things like predicting the next week's lottery numbers or using time-loop haxx to brute-force arbitrary mathematical problems?
  ```

  - u/Jakkubus:
    ```
    So basically it's a tachyonic antitelephone that boosts awareness instead of sending a message? Well, since all it does is highlighting a moment one is supposed to take an action, I don't think it requires any restrictions aside from maybe mentally exhausting user or rewinding up to certain amount of time.
    ```

    - u/Nulono:
      ```
      Basically. Or you could think of it as always sending the same message of "!".

      Having it be exhausting could help some. Most of what I'm trying to avoid is schemes involving precommitting, like "I'm going to look at options A, B, C, and D for a moment each, and then choose the one that future me highlights after the test is graded!" or "If the stock market drops, I'll send an alert to yesterday at noon…".
      ```

---

