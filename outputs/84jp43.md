## Bunkercore, a LitRPG by the author of Threadbare.

### Post:

[Link to content](https://forums.sufficientvelocity.com/threads/bunkercore-post-apocalyptic-dungeon-core-original.45976/)

### Comments:

- u/SatelliteFool:
  ```
  Just read. It's good. Four chapters (plus one interlude) so far, but I like where it's going. MC gets points for being properly paranoid right out my of the gate.
  ```

  - u/xeroxedechidna:
    ```
    I love properly paranoid MCs.
    ```

- u/MultipartiteMind:
  ```
  \*glances through the first chapter\*

  General writing quality, check.  Judgement of protagonist is more worthy-of-implementation than judgement of assisting entity, check.  Protagonist seems to be...  a science-fiction AI, possibly the subject of meatlife prejudice, rather than some sort of disembodied spirit?  *Triple-check.*  Reading more to see how this pans out!

  Edit:  More reactions after having read the rest of what's available!  Before I forget:  the nanohive having ten circuits total, and each being compared to one synapse, makes me wince.  Perhaps if the comparison were a 'dedicated neural net' rather than a single synapse, it would fit the sense of scale better.  Likewise, considering how many circuits a modern processor contains, and how much more advanced a nanohive would be--even if the term were a deliberate game-like overlay for the controller, it feels as though there should have been a more appropriate term.

  My enthusiasm went down a bit upon learning a little more about the nature of the protagonist, then back up and kept climbing as more about the protagonist's background (and specifically the protagonist's relationship with the world) was revealed, along with more exciting science-fiction dungeon-core mechanics.  It is very nice that, so far, everything done has been done with applicable pseudoscience, other than the lack of an explanation for upgrading of existing structures (without consuming extra feedstock or swarm work time to do so...).

  Near the end of the available fiction, one of the original good points got severely eroded; the assistant changed from 'I know how everything works, but my suggestions are somewhat n√§ive, so your decisions are effective and meaningful' (also, appropriate from having only experienced very short crises before) to 'I've seen lots of long-term strategies and seen which ones failed, so my judgement is better than yours about what not to do and whenever you don't follow the rails I lay out you'd be shooting yourself in the foot'.  Moral/Goal approaches as a separate issue.  The issue there is not the assistant saying it, but the reader being able to believe it.

  The dialogue overall also feels a little simple/simplistic, somehow.

  Continuing to enjoy the science fiction nature as this develops!
  ```

- u/Croktopus:
  ```
  dude. nice. was wondering when he'd post his next thing, thanks for posting it here
  ```

- u/Throwitover9000:
  ```
  Hmm. It's not a very sensible world, or at least not one with rational technology design. I'd have to go back to imagining it to fantasy/video game world in order to get proper suspension of disbelief. As is, things like how the AI isn't allowed to freely switch between circuits as needed, how construction upgrades improve all existing construction free of charge, how building a door requires defense tech while making a rock tunnel into a neat corridor is cheap and aesthetics seem to be free all breaks me out of the story each time.
  ```

---

