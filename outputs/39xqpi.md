## /r/rational's view on the continuity of consciousness in teleportation/uploading/etc scenarios

### Post:

After seeing the popular discussion in /r/AskReddit around this [comment](http://www.reddit.com/r/AskReddit/comments/39wkcu/what_scientific_breakthrough_would_be_the_most/cs73gds) and seeing what seems to be a fairly large consensus against sacrificing their consciousness I wonder what the opinion of /r/rational subscribers who are I feel far more likely to be pro transhumanism (which usually involves supplanting consciousness) is on this matter, I couldn't find any thread discussing this already and so:

The question:

Bill Gates perfects teleportation and releases a world wide transportation system, the way it functions is by replicating the exact atomic (or quantum whatever you want) configuration inside the teleporter and replicating it elsewhere. As part of this process the things inside the teleporter are broken into a subatomic mush (which then reforms randomly or whatever). 

Do you use this teleporter?

What if they scanned your brain onto a computer? What do you do if you're the consciousness left behind?

### Comments:

- u/None:
  ```
  #*Pick your poison!*

  In the philosophy corner ... [**EXISTENTIAL COMICSS** with a short but explanatory cartoooon!!!](http://existentialcomics.com/comic/1)

  In the science corner ... [**EEEEEEEELIEZER YUDKOWSKY** with a super-long quantum essay series!!!!!](http://lesswrong.com/lw/r9/quantum_mechanics_and_personal_identity/)

  In the fantasy corner ... [**STEVEN MOFFATTTT** with a shitty, unjustified, one-sentence explantion!!!!!!!](http://tardis.wikia.com/wiki/Souffl%C3%A9)

  No matter which route you prefer, **the answer is clear**: personal identity and continuity of consciousness are evolutionarily-helpful features of the map that have no concrete basis in the territory! A soufflé isn't a soufflé; a soufflé is a recipe - you*!cryoniced*, you*!teleported*, you*!uploaded*, you*!positive-spin-branch*, and you*!negative-spin-branch* are all just as **"you"** as you*!tomorrow-morning* or you*!five-minutes-ago*! No death involved!

  ***!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!***
  ```

  - u/Jules-LT:
    ```
    http://www.smbc-comics.com/?id=3262
    ```

  - u/None:
    ```
    > No matter which route you prefer, the answer is clear: personal identity and continuity of consciousness are evolutionarily-helpful features of the map that have no concrete basis in the territory! A soufflé isn't a soufflé; a soufflé is a recipe - you!cryoniced, you!teleported, you!uploaded, you!positive-spin-branch, and you!negative-spin-branch are all just as "you" as you!tomorrow-morning or you!five-minutes-ago! No death involved!

    Oh no.  It gets worse.  When you get right down to it, the particular recipe for personal identity that *matters* is a matter of your own *preferences*.  It's really all about which potential future versions of me I *want* to be, which is actually *more* interesting and disturbing: the highest-value potential future me's might be quite substantially different from present!me.

    But there's also the psychology corner: personal identity = moral character/alignment, which is where our intuitive notion of identity actually seems to cash out in experiments.

    Anyway, you win the contest!  Pick your ~~poison~~ prize!
    ```

  - u/goocy:
    ```
    Can I interdict and say that exactly because consciousness and continuity are materialistic concepts, it should be possible to extend consciousness to your teleportation partner?
    ```

- u/Chronophilia:
  ```
  Yeah, I think the pro-transhuman crowd will go for "the teleport clone is still the same person". It's almost a prerequisite for talking about immortality or enhanced intelligence or human life outside the narrow range of temperatures and pressures we evolved in. Or any other cool sci-fi ideas like that. (For comparison's sake, you should ask this question on /r/scifi and see how they like the idea.)

  Uploads open a *massive* can of worms that AIs or teleportation individually do not. For example, small errors in the upload's brain chemistry - due to imperfections in the simulation - might change a person's mind enough that I would no longer consider them the same person.


  Copies are cool. I think I could get on quite well with my doppelgänger. We'd consider it rude to ask which of us is the real one.
  ```

  - u/Gurkenglas:
    ```
    Someone who professes to believe the clone would be the same person only because otherwise their dreams of immortality could never come true would be doing it wrong. It should just add another hard problem to be solved onto the pre-existing problem of death.
    ```

  - u/None:
    ```
    > For example, small errors in the upload's brain chemistry - due to imperfections in the simulation - might change a person's mind enough that I would no longer consider them the same person.

    Aging, addiction, and food consumption also have measurable effects on brain chemistry. Do you think, for instance, that 10-year-old /u/Chronophilia is the same person as today's /u/Chronophilia? What about /u/Chronophilia before and after eating a chocolate bar?
    ```

    - u/None:
      ```
      I think that "same person" tries to condense a real number into a boolean value. It glosses over a spectrum in search of a yes or a no. I'm 99.999% the same as I was yesterday. I'd be nearly as happy with my present self being replaced by that self as I would if I survived. I'm so different from myself twenty years ago that I would be indifferent as to whether I died or simply regressed twenty years.

      Similarly, there are potentially versions of uploading that would result in a me that is similar enough to me today that I would prefer uploading now rather than risking death. There are potentially other versions where I'd rather wait and see if they improve them a bit.

      But the means of change are important, too. I am generally happier with changes, even ones that aren't an improvement, that are a result of my experiences.
      ```

    - u/Chronophilia:
      ```
      Sorry, I misspoke. I don't mind becoming a different person, I'd just like to become a *better* person. Since I was 10, I've learned skills and gained experiences which I wouldn't take that back if I had the option.

      Also I've been through adolescence with all the brain chemistry changes that implies, but that's a normal and well-understood part of life. When I was 10 I *wanted* to become an adult, even if I didn't really understand what it meant. I'd seen other adults and I wanted to do the things they did.

      So, there are some changes I would make to my brain, and some I wouldn't. I don't ever drink myself into unconsciousness. I don't want to be hit in the head or otherwise brain-damaged. If there's a way to prevent Alzheimer's disease I'll take it. And uploading would be a much more faster and more complete change than any of those. Maybe after the long-term consequences had been studied in real-world situations for a long time, after I'd met other people before and after uploading and knew what changes to expect...

      ... I'm rambling, of course we know this is all science fiction and I'll never have to make the choice anyway.
      ```

  - u/TimeLoopedPowerGamer:
    ```
    Reddit has long been a hot spot for conversation on the internet. About 57 million people visit the site every day to chat about topics as varied as makeup, video games and pointers for power washing driveways.

    In recent years, Reddit’s array of chats also have been a free teaching aid for companies like Google, OpenAI and Microsoft. Those companies are using Reddit’s conversations in the development of giant artificial intelligence systems that many in Silicon Valley think are on their way to becoming the tech industry’s next big thing.

    Now Reddit wants to be paid for it. The company said on Tuesday that it planned to begin charging companies for access to its application programming interface, or A.P.I., the method through which outside entities can download and process the social network’s vast selection of person-to-person conversations.

    “The Reddit corpus of data is really valuable,” Steve Huffman, founder and chief executive of Reddit, said in an interview. “But we don’t need to give all of that value to some of the largest companies in the world for free.”

    The move is one of the first significant examples of a social network’s charging for access to the conversations it hosts for the purpose of developing A.I. systems like ChatGPT, OpenAI’s popular program. Those new A.I. systems could one day lead to big businesses, but they aren’t likely to help companies like Reddit very much. In fact, they could be used to create competitors — automated duplicates to Reddit’s conversations.

    Reddit is also acting as it prepares for a possible initial public offering on Wall Street this year. The company, which was founded in 2005, makes most of its money through advertising and e-commerce transactions on its platform. Reddit said it was still ironing out the details of what it would charge for A.P.I. access and would announce prices in the coming weeks.

    Reddit’s conversation forums have become valuable commodities as large language models, or L.L.M.s, have become an essential part of creating new A.I. technology.

    L.L.M.s are essentially sophisticated algorithms developed by companies like Google and OpenAI, which is a close partner of Microsoft. To the algorithms, the Reddit conversations are data, and they are among the vast pool of material being fed into the L.L.M.s. to develop them.
    ```

  - u/Zeikos:
    ```
    I'm a transhumanist and i don't go for that concept.

    My explanation is fairly easy and i think the logic is sound :

    Your consciousness is not only the cells and atoms in your brain : it is the continuous biological and electrical processes that happen.
    They never stop , even when you sleep there's no interruption in your brain firing.

    In my humble opinion if you stop the processes and then re-start them somewhere else **they have not the same unbroken continuum** , there's someone else that is complety convinced to be you because the brains are identical.

    And anyway since i really really really want to become immortal i would rather avoid any kind of potential risk. 

    Anyway i don't understand why such concepts are equated with sleep.. Sleep is a loss of awareness but there's not any kind of disruption of the normal processes.
    ```

    - u/Chronophilia:
      ```
      It's usually associated with sleep because sleep is a normal part of most people's lives, and because it's actually a very good example.

      Your sense of self is based around physical continuity? That's strange. Continuity can behave very counter-intuitively in extreme situations - many functions that can seem continuous are not, and vice-versa.

      Suppose I replaced each of your neurons with a synthetic one that acts identically. One by one, over the course of hours or days, until your brain is entirely synthetic. That would be a continuous change, wouldn't it? But doing the same thing instantaneously is discontinuous. Now, what if the process takes a nanosecond? That's continuous again. But surely lightspeed delays make it impossible for me to scan and copy your entire brain in less than a nanosecond? How do you know a discontinuity is even something that can physically exist?
      ```

      - u/TimeLoopedPowerGamer:
        ```
        Reddit has long been a hot spot for conversation on the internet. About 57 million people visit the site every day to chat about topics as varied as makeup, video games and pointers for power washing driveways.

        In recent years, Reddit’s array of chats also have been a free teaching aid for companies like Google, OpenAI and Microsoft. Those companies are using Reddit’s conversations in the development of giant artificial intelligence systems that many in Silicon Valley think are on their way to becoming the tech industry’s next big thing.

        Now Reddit wants to be paid for it. The company said on Tuesday that it planned to begin charging companies for access to its application programming interface, or A.P.I., the method through which outside entities can download and process the social network’s vast selection of person-to-person conversations.

        “The Reddit corpus of data is really valuable,” Steve Huffman, founder and chief executive of Reddit, said in an interview. “But we don’t need to give all of that value to some of the largest companies in the world for free.”

        The move is one of the first significant examples of a social network’s charging for access to the conversations it hosts for the purpose of developing A.I. systems like ChatGPT, OpenAI’s popular program. Those new A.I. systems could one day lead to big businesses, but they aren’t likely to help companies like Reddit very much. In fact, they could be used to create competitors — automated duplicates to Reddit’s conversations.

        Reddit is also acting as it prepares for a possible initial public offering on Wall Street this year. The company, which was founded in 2005, makes most of its money through advertising and e-commerce transactions on its platform. Reddit said it was still ironing out the details of what it would charge for A.P.I. access and would announce prices in the coming weeks.

        Reddit’s conversation forums have become valuable commodities as large language models, or L.L.M.s, have become an essential part of creating new A.I. technology.

        L.L.M.s are essentially sophisticated algorithms developed by companies like Google and OpenAI, which is a close partner of Microsoft. To the algorithms, the Reddit conversations are data, and they are among the vast pool of material being fed into the L.L.M.s. to develop them.
        ```

        - u/duffmancd:
          ```
          I have two problems with this argument (I think). 

          * First the idea of identity relying on continuum is worrying to me. What if in 50 or 100 years we discover that time is discrete? Does this disprove consciousness (or continuity of consciousness)?

          * Second is related to the first, but continuity is a very fragile thing. How can you know that super-powerful alien beings aren't stopping all electrochemical activity in your brain every time you sleep? Or even just once? You (presumably) feel like the same person you were yesterday but how can you ever know? I prefer to base my decisions on what is "me" on whether it feels like me both to itself and to others.

          Edit: discreet/discrete *stupid homophones*
          ```

          - u/None:
            ```
            > What if in 50 or 100 years we discover that time is discreet?

            Well I would hope so, since I don't want her and Wen the Eternally Surprised turning exhibitionist.
            ```

          - u/Jules-LT:
            ```
            > Does this disprove consciousness

            Only a specific concept of it. Even if all I experience is false, there is an "I" to experience it: I know of no surer thing.  

            >or continuity of consciousness?  

            If time is discrete, doesn't it disprove continuity in general?
            ```

          - u/TimeLoopedPowerGamer:
            ```
            Reddit has long been a hot spot for conversation on the internet. About 57 million people visit the site every day to chat about topics as varied as makeup, video games and pointers for power washing driveways.

            In recent years, Reddit’s array of chats also have been a free teaching aid for companies like Google, OpenAI and Microsoft. Those companies are using Reddit’s conversations in the development of giant artificial intelligence systems that many in Silicon Valley think are on their way to becoming the tech industry’s next big thing.

            Now Reddit wants to be paid for it. The company said on Tuesday that it planned to begin charging companies for access to its application programming interface, or A.P.I., the method through which outside entities can download and process the social network’s vast selection of person-to-person conversations.

            “The Reddit corpus of data is really valuable,” Steve Huffman, founder and chief executive of Reddit, said in an interview. “But we don’t need to give all of that value to some of the largest companies in the world for free.”

            The move is one of the first significant examples of a social network’s charging for access to the conversations it hosts for the purpose of developing A.I. systems like ChatGPT, OpenAI’s popular program. Those new A.I. systems could one day lead to big businesses, but they aren’t likely to help companies like Reddit very much. In fact, they could be used to create competitors — automated duplicates to Reddit’s conversations.

            Reddit is also acting as it prepares for a possible initial public offering on Wall Street this year. The company, which was founded in 2005, makes most of its money through advertising and e-commerce transactions on its platform. Reddit said it was still ironing out the details of what it would charge for A.P.I. access and would announce prices in the coming weeks.

            Reddit’s conversation forums have become valuable commodities as large language models, or L.L.M.s, have become an essential part of creating new A.I. technology.

            L.L.M.s are essentially sophisticated algorithms developed by companies like Google and OpenAI, which is a close partner of Microsoft. To the algorithms, the Reddit conversations are data, and they are among the vast pool of material being fed into the L.L.M.s. to develop them.
            ```

            - u/Chronophilia:
              ```
              Interesting. I'd consider myself the process being performed by my brain, rather than the brain itself. The software, not the hardware. And software can be forked, downloaded, backed up, etc. without any problem.
              ```

  - u/Transfuturist:
    ```
    > I think I could get on quite well with my doppelgänger.

    My heart's not of stone,

    As I've frequently shone

    When alone with my own little X.

    And after we've dined,

    I am sure we will find

    Better incest then Oedipus Rex.

    Why should such sex vex,

    Or disturb or perplex,

    Or induce a disparaging tone?

    After all, don't you see,

    Since we're both of us me,

    When we're having sex, I'm alone.
    ```

  - u/RMcD94:
    ```
    >Copies are cool. I think I could get on quite well with my doppelgänger. We'd consider it rude to ask which of us is the real one.

    It's a question that bothers me greatly because when discussing clones and the such people can't get it out of their head that they are the original. I tend to do something like "You go in a dark room and fall asleep, when you wake up there are two of you" so that they might finally realise that the clone is replica. 

    A runaway cloning machine would be a problem for a lot of people based on some of their attitudes towards a "lesser" clone whereas I'm with you on the boat that I hope to be committed to going so far as to die to save two+ of my clones.
    ```

    - u/blazinghand:
      ```
      http://smbc-comics.com/index.php?db=comics&id=1879#comic
      ```

      - u/Jules-LT:
        ```
        Which of the two resulting cells of a mitosis is the original?
        ```

- u/LiteralHeadCannon:
  ```
  The question isn't really "is the copy of you you".  Yes, yes, it is you.  The question is "did you die when you were disintegrated".  The basic premise of copying people perfectly decouples those two questions.
  ```

- u/DCarrier:
  ```
  Yes and yes. I don't believe in continuity of consciousness. If you like the illusion of that, then go ahead and use anything that preserves the illusion.
  ```

- u/alexanderwales:
  ```
  If it were perfect, then sure, I'd use it. However, you have to put a lot of trust in people if you're talking about the core of your being.

  If someone intercepts the transmission, they have their own private copy of you. If someone makes a copy of your brain-state, they have their own private copy of you *and* can probably make their own edits to it. That's the sort of stuff that I find truly horrifying; not the continuity of consciousness stuff, which (to me) isn't that distinct from sleeping and then waking up.
  ```

  - u/RMcD94:
    ```
    I think the only goal in the future is that there would be no personal motivation, at the end of the day I can't see another way to stop such a thing as the power of personal computing grows if it ever reaches a point where people can simulate other people you've already lost that battle. Whether it ends up being you simulated or a random person someone is going to be under the control of someone else.
    ```

  - u/Transfuturist:
    ```
    > If someone intercepts the transmission, they have their own private copy of you.

    \>not using *secure* self-transport transfer protocol

    \>2163
    ```

- u/trifith:
  ```
  Conditional on the teleporter both encrypting the data, and transmitting it over hard wire only, yes.

  I'm not at all interested in my quantum brain state being intercepted by third parties. If somebody has a copy of that, they have a copy of me, can rebuild me, can scan my brain for information, can put me in a simulated torture device for 9^9^9 simulated years, anything, really, and I will have a continuous conscious experience of it.
  ```

- u/FeepingCreature:
  ```
  Instead of writing it up again, lemme [just link my last post on the subject](http://www.reddit.com/r/AskScienceFiction/comments/39mmgi/star_trek_why_doesnt_anyone_use_transporter/cs555d9).

  I've talked about this on Reddit _a lot_.

  > What do you do if you're the consciousness left behind?

  Upload party. Cyberself is invited, of course!

  I'd consider taking some cyanide or something, but I'd probably stick around in case there's some systematic problem with the uploading process and they need to rescan me. But long-term, there's no reason to keep running on a platform that can't even fork.
  ```

  - u/gryfft:
    ```
    It's just about sidebar-worthy at this point. 

    The debate is one I no longer enjoy, because it spirals back around to the same tired intuition pump every time.

    "But... is it *REALLY* **YOU**????? Not like... a COPY of you..."

    Yeah. It is. Yawn.
    ```

- u/MugaSofer:
  ```
  My instinct is that it's fine - and, in practice, I predict that I and most other people would do it - but ...

  Here's the thing. AFAICT, the right way to deal with being copied is to view *both* copies as "really you"; if you're going to be copied, and one of the copies will be given a cookie, you should anticipate a 50% chance of receiving a cookie. (We can kinda-sorta empirically test this via the Sleeping Beauty problem.)

  Which means ... if I'm going to be copied, and one of the copies will then be *killed*, shouldn't I anticipate a 50% chance of dying?

  That's clearly true in the case of one copy being killed by Unnecessarily Painful Slow Death Rays. But is it true if they're killed instantly? Apparently, from a quantum mechanics standpoint, that question is incoherent (which seems intuitive to me; I don't worry that having the atoms in my body replaced over time will kill me, so I don't *seem* to care about the atoms.)

  If I've used this machine fifty times, and I know for a fact it kills me instantly in the process of scanning me, what should I anticipate going in for the 51st time?

  I **remember** emerging seemlessly at the destination, but that would be *equally true* if it killed me via Unnecessarily slow Painful Death Rays. So should I anticipate a 50% chance of everything going black, the same way I would anticipate a 50% chance of Unnecessarily Slow Painful Death if that was what would happen to me?

  Again, I don't think this would stop me from doing it. But it would bother the heck out of me. Hell, it bothers me right now.
  ```

- u/drageuth2:
  ```
  One condition: The subatomitizational-mushimizer must be instant and painless, or the iteration of myself being mushed must be otherwise rendered free of consciousness before being destroyed.  I won't abide by any iterations of myself (or anyone else for that matter) suffering intense mortal pain from the simple use of public transport, no matter how much the next iteration of myself won't know about it.

  That condition given?  Sure.
  ```

- u/wendigo_days:
  ```
  There is no question here, it has nothing to do with transhumanism. Identical atoms are identical.

  And anyone who finds the idea of being made of different atoms scary should notice what is happening to them on a constant basis.
  ```

- u/TimeLoopedPowerGamer:
  ```
  Reddit has long been a hot spot for conversation on the internet. About 57 million people visit the site every day to chat about topics as varied as makeup, video games and pointers for power washing driveways.

  In recent years, Reddit’s array of chats also have been a free teaching aid for companies like Google, OpenAI and Microsoft. Those companies are using Reddit’s conversations in the development of giant artificial intelligence systems that many in Silicon Valley think are on their way to becoming the tech industry’s next big thing.

  Now Reddit wants to be paid for it. The company said on Tuesday that it planned to begin charging companies for access to its application programming interface, or A.P.I., the method through which outside entities can download and process the social network’s vast selection of person-to-person conversations.

  “The Reddit corpus of data is really valuable,” Steve Huffman, founder and chief executive of Reddit, said in an interview. “But we don’t need to give all of that value to some of the largest companies in the world for free.”

  The move is one of the first significant examples of a social network’s charging for access to the conversations it hosts for the purpose of developing A.I. systems like ChatGPT, OpenAI’s popular program. Those new A.I. systems could one day lead to big businesses, but they aren’t likely to help companies like Reddit very much. In fact, they could be used to create competitors — automated duplicates to Reddit’s conversations.

  Reddit is also acting as it prepares for a possible initial public offering on Wall Street this year. The company, which was founded in 2005, makes most of its money through advertising and e-commerce transactions on its platform. Reddit said it was still ironing out the details of what it would charge for A.P.I. access and would announce prices in the coming weeks.

  Reddit’s conversation forums have become valuable commodities as large language models, or L.L.M.s, have become an essential part of creating new A.I. technology.

  L.L.M.s are essentially sophisticated algorithms developed by companies like Google and OpenAI, which is a close partner of Microsoft. To the algorithms, the Reddit conversations are data, and they are among the vast pool of material being fed into the L.L.M.s. to develop them.
  ```

- u/Charlie___:
  ```
  To some extent it depends on your preferences. You are 100% totally allowed to prefer universes in which the pattern-that-is-you stays in the same physical format all the time.

  It's interesting that this preference is only possible for people who care about the entire course a universe takes, rather than just snapshots in time - if you only care about the state of the universe at each given time, then it no longer makes sense to talk about an "original." But humans are not known for having simple desires.

  I think the "what do you do if you're left behind" question is pretty trivial - just do what you would do anyhow. Like, eat a sandwich or something, and then go talk to friends or family. I'm a little worried about duplication on consequentialist grounds - I don't expect it to be a big benefit for me (not me now, nor either of future me), and it takes up resources and makes things a bit more complicated.
  ```

- u/None:
  ```
  What experiments can falsify different theories of continuity of identity?

  Oh, you think this is "pure" philosophy?  No, there's a cognitive structure implementing the measure-predicate that returns the extent to which any possible rebuild, upload, teleport-output, or clone *is you*.    You need to know what that predicate says, and how it can be correctly updated to deal with new ontological models in which more abstract, intuitive concepts don't appear.

  DEAL WITH IT.
  ```

- u/None:
  ```
  Yes, as long as it's safe: I don't get destroyed, I don't end up somewhere else (like, someone steals my information and create another copy of me somewhere else without leaving any trace, making them free to do whatever they wanted to me, because no one knows I exist there).
  ```

- u/notmy2ndopinion:
  ```
  I'm speaking as someone who is in the medical field and has studied neurology to the point where I can discuss the most common pathways and teach medical students.

  There's a HUGE difference between 99.99999999999999% you and 100% you. That 10^-Xth difference may be all it takes between being you and someone who is depressed, or psychotic, or in chronic pain, or anything else that we consider to be purely mental.

  We can't make a machine, label it 100% perfect, and expect flawless continuity.

  Most likely, the first people who are teleported will have a stroke because you can't build organic structures that have grown with time the same way you'd program a 3D printer to try and replicate it, layer by layer.

  Even if you get the physical structure correct, with all of the neurons in the correct locations, how are you going to replicate the exact same electrochemical gradient and internal packaging of neurotransmitters? The wrong number of sodium-potassium pumps or calcium channels will render dendrites ineffective and others will be reinforced instead, altering the delicate patterns of thought-stands we have woven.

  Even if we get that right, how will we "know" that our "knowing" is true? Devastating neurological disorders can be accompanied with the brain's inability to notice that anything is wrong. Any attempts to convince them otherwise just increases agitation and fixation on the wrong idea.
  Examples: read about hemineglect in stroke patients, delusions for psychotic patients, confabulation for Wernicke-Korsakoff syndrome in alcoholics.
  https://en.m.wikipedia.org/wiki/Hemispatial_neglect
  http://en.wikipedia.org/wiki/Delusion
  http://en.wikipedia.org/wiki/Wernicke%E2%80%93Korsakoff_syndrome
  ```

  - u/FeepingCreature:
    ```
    > 99.99999999999999%

    Do you actually mean that or did you just pull a number from a hat?

    I'd be willing to bet most people who are 99.99999999999999% me are indistinguishable.

    > how are you going to replicate the exact same electrochemical gradient and internal packaging of neurotransmitters?

    Really carefully. Come on, it's a thought experiment.
    > Devastating neurological disorders can be accompanied with the brain's inability to notice that anything is wrong.

    It's harder to conceive of a devastating neurological disorder that is impossible to recognize from the _outside_.
     Which is amusing, certainly, considering philosophy's focus on the vaunted "internal experience".
    ```

    - u/notmy2ndopinion:
      ```
      We could say that our nearest simian ancestor is 99.99999999% identical to us (or pick any relative who shares your DNA who isn't actually you.) My point is that there's an illusion of precision that I wouldn't risk. That 0.000000001% difference as it turns out, IS ME.

      Just because I'm thinking about a thought experiment's flaw in defining it "perfectly" and "100%" doesn't mean I'm not willing to engage in it.

      I mean, it'd be fun to teleport, but if the mechanism involved a computer scanning me and them disintegrating a version of me, I wouldn't do it. No matter how small the error bars may be, it's not worth it... in a mundane scenario. If the Earth were exploding and it's the only method of escape and everyone is using it and it's been observed by me to be safe, then I won't be an old die-hard about the risks.

      [edit:] after some more consideration, I realized that we are disputing definitions.
      http://lesswrong.com/lw/np/disputing_definitions/
      I'm pushing back against the simplistic nature of the thought experiment and breaking it down into some of the practical components that CS/EE majors may not realize about how our wetware differs from the circuitry of certainty. You're asking if I had an exact clone of myself, would that be me. Indisputably, yes. I recognize how our fundamental building blocks of mass and energy are just orderly patterns that "magically" could be duplicated and teleported and I would be both versions of me in two different places. I do study the pathology of people for a living, so forgive me if I just expect such a device no matter how well-intentioned, to go horribly wrong in real life. (But who knows, we used to think that humans couldn't live in space or fly too high in the sky because science!danger! And that must be a bias of mine, to assume risks where they may not exist.)
      ```

      - u/gryfft:
        ```
        Is the 99.99999999% figure being applied to the entire physical system (including bones, blood, muscles, fat, digestive system, etc) or to the brain (the only bit I personally care about for the purposes of this discussion?)
        Because, unless I'm mistaken, the brain contains 100 billion neurons and 99.99999999% of 100 billion is 10. I can't find the numbers but I'd be willing to bet that's fewer than is lost in the average concussion.
        That being the case, I'd be far more comfortable with an upload of six sigma fidelity than a baseball bat to the head.
        ```

      - u/None:
        ```
        > I do study the pathology of people for a living, so forgive me if I just expect such a device no matter how well-intentioned, to go horribly wrong in real life. (But who knows, we used to think that humans couldn't live in space or fly too high in the sky because science!danger! And that must be a bias of mine, to assume risks where they may not exist.)

        Essentially, before operating a teleporter, we should do mice experiments or something to figure out what the risks are, and where we can put the safety rails to minimize them.
        ```

      - u/IWantUsToMerge:
        ```
        >Nearest simian ancestor 99.99999999%

        I don't know about our ancestors but if you're talking about bonobo the number is 98.7%, which means you'd be off by a factor of 1.3 billion. That is very very wrong. 0.000000001% *actually ain't shit* on the scales of the genome or the brain. Although I imagine you could do a fair bit of damage if you were able to change 6 specific codons in the human genome, 6 random ones? Really? You think that would do something?
        ```

        - u/notmy2ndopinion:
          ```
          I made up a number to make a point and maybe I should've been more precise in keeping it on at least a micro or nano level rather than a pico/femto level of precision. If we consider "6 changes" to the genome in each cell in our body as well as disruption/displacement of our microtubules, microfilaments, DNA strands... as well as other connective tissues... then yes, six random changes per cell in my body amount to significant amounts of changes.

          If we equate it with milliREM, I would tolerate a transporter machine that equates to levels similar to background radiation or an airplane trip around the world. Much more than that would expose me to too much stochastic risk.

          http://www.epa.gov/radiation/understand/health_effects.html
          ```

  - u/None:
    ```
    How different are we from our 10 year old version? Probably more than that.
    ```

- u/ArgentStonecutter:
  ```
  James Patrick Kelly, *Think Like a Dinosaur*.

  Greg Egan, just about anything before the Clockwork Rocket series.

  John Barnes, *A Million Open Doors* and sequels.

  Vernor Vinge, *Just Peace*, where you don't destroy the original.

  There's another novel involving a duplicative teleportation with a title that's "something star" by blish or aldiss or hoyle or one of those guys that I can't recall.
  ```

---

