## Philosophically Curious George and the Limits of Empiricism

### Post:

[Link to content](http://existentialcomics.com/comic/132)

### Comments:

- u/None:
  ```
  [deleted]
  ```

  - u/None:
    ```
    Ok, before I write anything else, it's worth noting that *I absolutely freaking love you guys on this sub*.  Like, I drop a one-liner, and two other people come in with the *pinpoint correct* objection to the comic.

    That said, it's worth giving credit to the comic for just being about the history of philosophy as commonly taught to, most likely, undergrads.  Philosophers working several hundred years ago didn't possess concepts like "causal role", "discrete versus continuous", "reduction", or "causal generative model", let alone disciplines like topology or information theory.

    Hell, the way that abstract knowledge and domains emerge from the hierarchical correlation structure in empirically-observed data has *only just these past few years* become readily apparent, to the point that I can still (somewhat) write a paper about it and be (almost, mostly) saying something novel.

    Point being, freaking love you guys.
    ```

    - u/creatureofthewood:
      ```
      >the way that abstract knowledge and domains emerge from the hierarchical correlation structure in empirically-observed data has only just these past few years become readily apparent

      Huh. If that's true then I guess previous innovations turn into a culture's subconscious background assumptions *really fast* because I can hardly imagine any other sensible answer...what did they think caused categories before, if not regularities in the underlying structure of observations?
      ```

      - u/CoolGuy54:
        ```
        That's all the stuff about Platonic ideals....but I agree with you, I've totally internalised the "categories for man" "carve reality at the joints" "bleen/ rube" idea of categories to the point where I can't really imagine a sensible alternative.
        ```

        - u/creatureofthewood:
          ```
          Well yeah but that's Plato and he's an ancient. I assume he's mostly the foil against which new philosophers cut their teeth against than an actual representation of what people seriously think?

          I feel like the naive view would automatically tend to the (ostensibly) correct one, and platonism is what you get if you think about it too hard and end up confusing yourself with your own semantics, but that might just be because I've been encultured with that view or something.

          Heh, maybe "thinking so hard they get confused by their own semantics" describes a lot of philosophers actually.
          ```

          - u/None:
            ```
            >I assume he's mostly the foil against which new philosophers cut their teeth against than an actual representation of what people seriously think?

            Well, the issue here is that you used the word "against".  Not so much "against", usually, as "with".  His influence over the field of philosophy has been really, really, *reaaaally* long-lived, to the point that the view labeled "realism" in many fields of philosophy X is easier to just label as "Platonism about X".
            ```

      - u/None:
        ```
        > If that's true then I guess previous innovations turn into a culture's subconscious background assumptions really fast

        LW is a subculture whose founder happens to have reinvented (I'm not sure if he did it independently of Friston et al's theoretical neuroscience work) much of what later became the Bayesian Brain Theory, which has very clear implications regarding how categories and such work, without quite ever becoming a neuroscientist.

        Or he may just have been transcribing the neurosci literature into the Sequences.  I can't date and cross-reference all of it; I just think with the benefit of hindsight that Eliezer should have bothered publishing a lot of his ideas as "real" statistics, information theory, and machine-learning so he could get his name on what're now the best-in-class theories of how minds work.
        ```

- u/PlaneOfInfiniteCats:
  ```
  Most of so-called unconditional beliefs in fact aren't. A good example about 2+2=4 can be seen [here](http://lesswrong.com/lw/jr/how_to_convince_me_that_2_2_3/).

  People are often too fascinated by disciplines based on "pure thought" to notice they have quite mundane origins. Geometry, for example, was born from measuring fields using stakes with ropes tied to them (this is where concepts of a point and line come from).
  ```

  - u/Aabcehmu112358:
    ```
    I still think that articles fails to consider that we can learn from patterns in our observations, as well as the literal content of our observations. Though it appears that I am putting two headphones together with two headphones to get 3 headphones, I am fairly certain that I could puzzle out I seem to be perceiving a single additional illusory headphone, based on the behavior of said headphones.

    Not that empirical observation isn't still key in order to putting mathematics to any actual use. Two plus two equals four because we say so, but that only means anything in a concrete sense because we consistently observe behavior in the world which it models well (mostly because, as you say with Geometry, because we designed it be a decent model to begin with).

    e-

    Because something bothered me about how I phrased this, I put it in slightly more metaphorical terms.

    You can't disprove a hammer does what hammers do, but you can disprove that your problem is a nail.
    ```

- u/None:
  ```
  When do we get nonparametric hierarchical Bayesian George?
  ```

- u/ZeroNihilist:
  ```
  I take issue with the comic as a whole (as I do most of those on that site), but the bit about the concept of time in particular annoyed me.

  No, you don't need the concept of time to make observations about things changing. Look at something twice and you have observed a change in time, even if you do not know what time is. You don't need to have a concept of something to be subject to it, otherwise the concept of ignorance would be incoherent.

  Naturally, once you have observed a change you can keep exploring the concept to discover that the rate of change appears unrelated to many things, like whether you are awake or asleep, bored or excited, running fast or standing still (for non-relativistic speeds of course). Maybe it's an external phenomenon, then.

  Further, you can create a little device that "ticks" at a predictable rate and use that to measure the rate of other things and thus build up a vast and coherent picture of the concept. Heck, you might even find a more reliable "ticker" than your original idea if your results have errors.

  In essence, not only is time a perfect concept for empirical study, our concept of it has been empirically improved since we initially developed it (see relativity).

  And a brief bit about the ladybug: yes, you may need a lot of concepts to be able to understand a particular new concept. As the saying goes, no shit Sherlock. Breaking down a problem and studying its component concepts is kinda one of the core tenets of empiricism.
  ```

  - u/Chronophilia:
    ```
    I thought the ladybird was illustrating that empiricism doesn't bootstrap itself. You need a lot of background knowledge before you can empirically observe "there is a ladybird on the ground". And every part of this background knowledge, in turn, requires its own library of background knowledge before it can be empirically observed. The recursion bottoms out somewhere. There must be pieces of knowledge that you didn't acquire through observation of the outside world.
    ```

- u/renegadeduck:
  ```
  I guess a metal cage isn't so different from an ivory tower.
  ```

---

