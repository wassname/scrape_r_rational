## The two types of rational fanfic. [FF][D]

### Post:

We spend a lot of time here rationalizing established fiction. Most of the time, we take the MoR approach of altering the source to create an AU with as many elements in common as is realistically plausible. I'm going to call this Type 1 fiction rationalization. I'm gonna talk for a bit about what I'd like to see more of, which I'm going to call Type 2.

Type 2 is where you take the established fiction exactly as it is and work backwards to figure out how what's already there can make sense, instead of replacing it with something that already does. "A Bluer Shade of White" does this. At no point does it contradict existing Frozen Canon. It takes it exactly as is, and runs with it.

Type 2 is certainly more difficult. But I feel like it's also likely more satisfying when done well. With things like Game of Thrones, where not much lore is known for certain to begin with, it may even be the more appropriate method. I feel like it's often overlooked as a possibility though. And the hope is that this post will change that.

### Comments:

- u/None:
  ```
  Personally I prefer character-oriented stories about smart people (or dumb people, honestly, but in the specific context of this sub) being all smart and emotionally isolated than a lot of worrying about how magic could *really work* so long as the rules are consistent in-universe.
  ```

  - u/alexanderwales:
    ```
    I'm mostly the same, though I have no idea whether my writing reflects it.
    ```

- u/None:
  ```
  [deleted]
  ```

  - u/Solonarv:
    ```
    Isn't that just rational fiction? As I've heard it defined here, it only requires that the story/universe be rational, not the characters. If the characters are also rationalists, we call that rational*ist* fiction.
    ```

    - u/None:
      ```
      [deleted]
      ```

      - u/None:
        ```
        [deleted]
        ```

        - u/None:
          ```
          [deleted]
          ```

          - u/poliphilo:
            ```
            This is the *agent provocateur* tactic, isn't it? I.e. assist or encourage someone to commit a relatively low-harm crime which then justifies extensive retaliation.

            It seems simpler and safer to do this kind of thing without firearms involved, but we know of at least one case (["ATF gunwalking"](https://en.wikipedia.org/wiki/ATF_gunwalking_scandal)) where something similar was tried with guns. Yes, it was probably a bad idea there, but that might be due to peculiarities of the Muggle world.
            ```

      - u/None:
        ```
        Hahaha no.  Not only did Dumbledore outscheme him, in the end he was *just* a schemer.  Do not let your foolish ape-brain trick you into mistaking scheming abilities for actual rationality, intelligence, optimization power, or anything else.
        ```

      - u/philip1201:
        ```
        Probably true in an in-universe counterfactual, but in practice the characters and/or situation would be rewritten such that they still defeat Voldie. Ratfics are still subject to the laws of storytelling.
        ```

- u/DaystarEld:
  ```
  In my experience and perspective, if you can exclusively do a Type 2 story then the story you're rationalizing wasn't really that irrational in the first place, or there weren't as many disconnected irrational elements.

  HPMOR does a pretty good job of mixing both: it retcons what's blatantly incompatible with intelligent characters and a consistent world (like loving sacrifice being enough to block the killing curse), while rationalizing what is apparently true (the philosopher's stone's true effect rather than "gold and immortality").

  Part of what makes rationalfic so interesting is the latter Type 2 rationalizing, but for longer or complex works it just isn't feasible all the time. Short stories that only explore a bit of the world, yes, because there simply isn't time or space to explore all the possible alternative problems or exploits that can come up with the new rules of reality. Even long stories where only one or two things are different from our world, yes, because there are less riddles there that need solving. But there are fictional worlds where Type 2 rationalizing at every junction and instance, if even possible, would quickly break everything apart in terms of world consistency, story structure or character decisions.

  In other words, Type 1 rationalization vs Type 2 is more the consequence of the fiction being rationalized. Not always, of course: it's possible for someone to think a problem can only be solved by Type 1, and then have someone else think of a Type 2 solution to it. But when you're talking about a more complex world or longer story, the probability of being able to do it with *each* and *every* thing swiftly becomes unmanageable.
  ```

- u/LiteralHeadCannon:
  ```
  I've found that a lot of ratficers (or at least the strawman ratficer I'm constructing in my head as I write this) pay insufficient attention to the fact that humans are very, very broken optimizing functions.  "Why didn't the character do easy option xyz that would have seriously improved the situation?"  Because he had five seconds to think of it, and didn't.  "Why didn't the character put more effort into solving the mystery faster?"  Because he was depressed and it wasn't entirely clear that the mystery was solvable anyway.  "Why did the character take Option A when Option B was clearly a much better fulfillment of his values?"  There was a value conflict and apparently your model of what value took precedence for the character was wrong.  "Why is this entire civilization so inefficient?"  You apparently need to study history and civics some more.

  It's much more satisfying to see a hero use rationality to solve his problems, rather than brute force, but humans are necessarily flawed and those flaws are very important for interesting fiction.
  ```

  - u/FaceDeer:
    ```
    This is one of the reasons why I've always loved the Tremors series of movies. The characters (and the monsters) often make mistakes but they are *plausible* mistakes. The sorts of mistakes that otherwise perfectly intelligent people make when they're scared, tired, and not perfectly educated about the situation they're in.

    There's none of the "let's split up to explore the scary haunted house! Oh, it was just a cat, therefore there's nothing actually sneaking up behind me!" idiocy, that stuff's terrible. But when a character falls off the roof onto Graboid-infested soil and in a panic scrambles onto a spare tractor tire for "safety", yeah, it was a dumb move but it's a mistake that even a really smart person might make under the circumstances.
    ```

- u/mhd-hbd:
  ```
  My fanfic *The World is Your Oyster, The Universe is Your Namesake* is pretty damn close to a Type 2.

  Really it is a spectrum. Type 1 is more focused on preserving plot structure and overall flavor of the original work, while Type 2 preserves canon information as presented.

  One is heavier in world building,  the other on interpreting the facts. A story like Luminosity overall does little to deviate from canon world building but still wrecks canon by making the villains smart. What category does that belong to?
  ```

- u/daydev:
  ```
  Soâ€¦ [Fix Fics](http://tvtropes.org/pmwiki/pmwiki.php/Main/FixFic) and [Fan Wanks](http://tvtropes.org/pmwiki/pmwiki.php/Main/FanWank), respectively?
  ```

- u/None:
  ```
  >We spend a lot of time here rationalizing established fiction. Most of the time, we take the MoR approach of altering the source to create an AU with as many elements in common as is realistically plausible. I'm going to call this Type 1 fiction rationalization.

  Just to make sure, by "rationalization" do you mean making something more rational? Since it also has another meaning: coming up with reasons for your existing beliefs or past actions like convincing yourself how a suboptimal purchase was actually worth it.
  ```

  - u/alexanderwales:
    ```
    The way I see it, it's sort of the same thing.

    You're making the imagined universe "more rational" by coming up with reasons for existing canonical evidence or character actions. If there's a lingering question like "Why didn't character X do this?" then the answer is "There is hidden limit Y which places constraints on their magical power". This is taking a sub-optimal action and making it optimal through author fiat.
    ```

  - u/IWantUsToMerge:
    ```
    Yeah it really is rationalization in the derogatory sense. Reality, canon, gives you a data set you don't like and don't know how to explain. If you respond by inventing another reality where things are simpler and insist that this is how reality really is just because it makes more sense to you, are a godawful scientist. That is the definition of scientific bankruptcy. For a rational fiction author to do that, they need a damn good reason.

    There're a lot of good reasons though. Maybe there's a solid inconsistency in canon that you have no choice but to untangle. Maybe the possibility that there was some conspiracy to misrepresent the reality of the universe(unreliable narrator/explicators) would be genuinely probable and genuinely interesting enough to explore. Or maybe you're just tired of writing about sapient mind-reading daemons, or capricious gods, who run around behind the scenes making sure the universe's mind-projection mechanics(superficially simple but physically intractible magic) work.
    ```

    - u/GaBeRockKing:
      ```
      On the flip sides, some stories have genuine inconsistencies in how their magic systems work, that need to be consolidated by the author. Under those conditions, it's perfectly find to change things around a bit. Alternatively, I feel that, if you can rationalize a magic system with only minor changes, then it's still worth it, as audiences have more fun when they understand the magic involved better.
      ```

    - u/Uncaffeinated:
      ```
      A lot of times, the authors just didn't care about consistency and the simplest possible explanation for the canon data points is that "this is a fictional work". What are you supposed to do then?
      ```

      - u/IWantUsToMerge:
        ```
        Heh, personally, I rather enjoy writing characters who know they're characters in a work of fiction. For the author it's immersive and I like to think that for the audience it makes them seem more real. But there are usually other explanations for seemingly narrativium-driven worlds. Often Mind-Reading Daemon-related, but not always. When I was reading Worm I was nursing a theory that one could collapse the question of why Taylor got so lucky so many times to the question of "why this timeline rather than the many alternatives where she died?" The answer seemed obvious; we are reading a story told in the past tense, and in all of the timelines where Taylor didn't survive, [worm](#s "there is no one left alive to tell this story").
        ```

- u/neshalchanderman:
  ```
  Rationalising characters' actions in previously published work is a small but well-established literary genre. See *Shylock* .
  ```

- u/ancientcampus:
  ```
  For that matter, there are definitely two shades of "Rationalist" stories: ones that attempt to teach cognitive theory, and ones that really should be called transhumanist or singulitarian stories.
  ```

---

