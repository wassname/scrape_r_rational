## [D] Monday General Rationality Thread

### Post:

Welcome to the Monday thread on general rationality topics!  Do you really want to talk about something non-fictional, related to the real world?  Have you:

* Seen something interesting on /r/science?
* Found a new way to get your shit even-more together?
* Figured out how to become immortal?
* Constructed artificial general intelligence?
* Read a neat nonfiction book?
* Munchkined your way into total control of your D&D campaign?


### Comments:

- u/OutOfNiceUsernames:
  ```
  *[\(this article](https://www.wired.com/2017/05/hundreds-apps-can-listen-beacons-cant-hear/) reminded me that I wanted to post something like this for quite some time already)*

  >>A person is smart. People are dumb, panicky dangerous animals.

  ↓

  >A person is smart. Corporations are ruthless, sociopathic paperclip maximizers.

  tl;dr: The hypothetical rogue AI’s job of turning our world into a dystopia (at best) is already slowly being completed by corporations (governments, etc) because that’s just what the evolutionary selection criteria dictate them to do in their biomes (e.g. unhealthy competition in financial markets, quarterly profit reports, etc).

  /r/rational/ and other related communities, as well as the more mainstream infosphere is full of hypothetical discussions about how AIs should be restricted *when* they finally become a finished thing. However, not much practical discussion is happening on restricting those agents that not only are similar to such rogue AIs but also already exist and already are influencing the structure of the world-wide political, economical, legal, ecological, etc systems.

  Is it because corporations — and corporate unions, governments, etc — have no sense of novelty as phenomena, so what they do gets overlooked as part of the “Normal”, the status quo? Or maybe it’s because it’s easy to imagine how you’d be fighting some imaginary monsters that don’t exist yet in real world, but when it comes to real gargantuan entities like these mentioned, people just realize just how helpless they are and don’t even contemplate trying to change something? 

  And mostly, even when people *do* try to change something (through protests, activism, etc) it either has no results or the results are just not enough in the constant tug of war (e.g. privacy rights, internet rights, ecological regulations, etc). And even then the energy is being directed against specific things that are happening *right now*, instead of against the underlying system (of values economical, political, etc) that is the cause of all these symptoms. People often talk about problems of a two-party political system, or modern capitalism, etc, but what actual, concrete things have been happening towards adding working muzzles for the relevant agents operating in these fields, or towards changing the very basic nature of these systems?
  ```

  - u/gbear605:
    ```
    I feel like your statement, that many /r/rational type people are not interested in the dangers of capitalism, is false. For just one example, [the most popular post](http://slatestarcodex.com/2014/07/30/meditations-on-moloch/) from Slate Star Codex, an /r/rational related blog, is about the dangers of capitalism.

    That aside, while it's true that AI and current-world-structure (corporations, etc.) have many similarities, they function quite differently in important ways.

    The type of AI that /r/rational type people are interested in are not rogue AIs that turn the world into a dystopia; they're rogue AIs that exterminate the human race in a matter of days from when they're created. While dystopia is bad, extermination is (probably) worse.

    And, like you said, it's *very hard* to destroy capitalism, but it's relatively easy to make a stand against AI risk because there's hardly anyone working on it. I'd guess something like a couple hundred people worldwide are working on AI risk while hundreds of thousands of people worldwide a working on capitalism. 

    Also, this: http://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/
    ```

  - u/Norseman2:
    ```
    I wouldn't say the threat of corporations is overlooked - I mean, the means for addressing the ongoing threat seems to be a key feature of most political ideologies. On the liberal side, you have people saying we can get the government to regulate corporations and make them work for society. "Let's put the AI in a box and use it strictly for our benefit."

    On the conservative side, you have people saying that the government is corrupt, inefficient, and unable to effectively regulate corporations. They argue we should relax or even suspend corporate regulations and let competition in the market along with intelligent and well-informed consumers/workers direct the course of corporations. "Don't box the AI, just allow everyone to produce their own competing AI and then let the fittest survive and dominate."

    The problem is, corporations already run the mainstream media and corporations fund the media with advertisement. Media outlets that suggest solutions which are bad for corporate profits/shareholder gains will be less likely to get funding than media outlets which do the opposite. "The AI already controls your main sources of information and is allowing you to debate two different options to deal with its increasingly global domination..."

    Of course, both sides have something right. Liberals are correct that the side-effects of corporate profit-maximization are a major threat while conservatives are right that corporations tend to take over any government agencies meant to regulate them. Unfortunately, this makes corporations both very dangerous and very hard to control. We're already living in a dystopia of sorts, a world where corporate profits are maximized at the expense of human health and global climate security. "The AI is already maximizing paperclips while leading you to debate about what's causing the change in climate."

    The only proven approach I'm aware of for dealing with this is [anarcho-syndicalism](https://en.wikipedia.org/wiki/Anarcho-syndicalism). Basically, workers start forming unions and vote on the services they want their unions to provide (healthcare, disability, education, etc.), and vote to start forming alliances with other unions. The unions use strikes to get employers to pay their workers fairly and thereby enable the unions to provide the benefits the workers have opted for. As the alliances grow larger, the unions provide larger-scale services (disaster assistance, welfare, lobbying, etc.) and gradually a national or even transnational federation of unions is formed which begins providing even more services (security, national infrastructure maintenance and development, etc.). Capitalism and the state gradually become irrelevant as the unions take greater and greater control, using strikes as needed to enforce compliance. When businesses collapse as a result of the strikes, the union turns them into worker-owned cooperatives, transforming capitalism into socialism. With organized voting blocs, the state is gradually taken over and withered into nothing, turning a corrupt republic into an anarchist opt-in direct democracy.

    In practice, this was tried in Spain and got to the point of having a large federation of unions providing essential services in Catalonia when a fascist coup in 1936 turned into a civil war and forced their slow transition to happen immediately. An [anarchist revolution](https://en.wikipedia.org/wiki/Spanish_Revolution_of_1936) in Catalonia followed and the [CNT](https://en.wikipedia.org/wiki/Confederaci%C3%B3n_Nacional_del_Trabajo)-[FAI](https://en.wikipedia.org/wiki/Federaci%C3%B3n_Anarquista_Ib%C3%A9rica) formed the backbone of an anarchist democracy. George Orwell [wrote a book about it](http://www.george-orwell.org/Homage_to_Catalonia/) after he traveled to Spain to join the revolution and even survived getting shot in the neck by a fascist sniper. He wrote:

    >"I had dropped more or less by chance into the only community of any size in Western Europe where political consciousness and disbelief in capitalism were more normal than their opposites. Up here in Aragon one was among tens of thousands of people, mainly though not entirely of working-class origin, all living at the same level and mingling on terms of equality. In theory it was perfect equality, and even in practice it was not far from it. There is a sense in which it would be true to say that one was experiencing a foretaste of Socialism, by which I mean that the prevailing mental atmosphere was that of Socialism. Many of the normal motives of civilized life—snobbishness, money-grubbing, fear of the boss, etc.—had simply ceased to exist. The ordinary class-division of society had disappeared to an extent that is almost unthinkable in the money-tainted air of England; there was no one there except the peasants and ourselves, and no one owned anyone else as his master."

    >"There was much in this that I did not understand, in some ways I did not even like it, but I recognized it immediately as a state of affairs worth fighting for...so far as one could judge the people were contented and hopeful. There was no unemployment, and the price of living was still extremely low; you saw very few conspicuously destitute people, and no beggars except the gypsies. Above all, there was a belief in the revolution and the future, a feeling of having suddenly emerged into an era of equality and freedom. Human beings were trying to behave as human beings and not as cogs in the capitalist machine."
    ```

    - u/trekie140:
      ```
      I’m far from that any brand of anarchism is a good way to reorganize our society, but syndicalism does sound like it makes a few steps in the right direction. The system still seems vulnerable to the tribalism and discrimination that are running rampant in modern democracy, but it at least has a way to establish economic incentivizes that don’t directly reward exploitation or openly encourage poverty.
      ```

  - u/None:
    ```
    There's a lot of thought into regulating corporations. Environmental restrictions for example exist and are very important. 

    And there's a constant debate between whether we want less regulation for more efficiency, or less efficiency for more human-minded goals(e.g provide the poor with health care).
    ```

    - u/buckykat:
      ```
      The debate: Kill the poor or lose "efficiency"!
      ```

      - u/None:
        ```
        Efficiency has value. Great Britain tried focusing on the working class in between the end of WW2 and the Thatcher era. It worked well at first but eventually lead to massive stagflation and economic upheaval. The government could not effectively adjust to changes in the global economy like the lack of demand for British coal. 

        There is an ideal middle ground between anachro capitalism for pure money making efficiency and total state capitalism for pure humanitarian concern for the poor. Where exactly that is is very difficult to say, especially since it shifts as technology changes.
        ```

        - u/buckykat:
          ```
          Efficiency has value in a heat pump or a computer. In a society, it just means kill the poor.
          ```

          - u/None:
            ```
            I told you already, having no concern for efficiency and just trying to get people jobs and welfare has been tried and failed. The Soviet Union and every other communist nation was founded on the concept. Much of the world excluding the US were doing government funded inefficient industries so the working class had advantages.

            It failed.

            You presumably consider the Nordic countries a good example of the ideal nation states. I do too. They do not have minimum wages. They do rely heavily on market forces, not government forces, to determine wages and prices. They have strong unions that set minimum wages for each industry, which works because if an industry is growing weaker, then for it to keep any jobs it'll need to lower pay, which a government federal minimum wage would unflexibly disallow.

            I think a 0% corporate tax should be the goal that is worked towards, because corporate taxes are inefficient. They deincentize investment into the economy and incentivize corporations wasting money looking for loopholes.

            I also believe in high taxes for the upper income brackets and taxes for investment gains. Taxing rich individuals is better than taxing corporations.

            Then those taxes can be in turn invested into an effective social safety net, and that social safety will ideally be efficient at having poor not-die.
            ```

  - u/vakusdrake:
    ```
    [This](http://slatestarcodex.com/2015/12/27/things-that-are-not-superintelligences/) SSC article talks about all the reasons trying to compare things which are not AGI to AGI is never really that useful or accurate if you want to make more than an _extremely_ abstract comparison.

    Organizations are fundamentally different from AGI in that they are never really much smarter than the smartest people within them and often much less than that, plus they are quite slow in their operations. Because of that organizations are a bad metaphor for AGI since they are extremely slow and not particularly smart, so they are far less of a danger than an actual superintelligent _agent_.
    ```

    - u/OutOfNiceUsernames:
      ```
      Yes, gbear605 has already mentioned SA in his subcomment. In all fairness, I should’ve composed my comment more in tones of “what has the rationalist community said on this issue so far?” rather than “why isn’t it saying much about it?”.

      Regarding the inaccuracies when comparing meta-entities like corporations with AIs, I’d like to clarify that what I was saying wasn’t that corporations should be classified as a subtype of an artificial intelligence. I was saying that corporations are doing what an emerging AI is partially so feared for: reshaping the world according to their primary goals with little regard for the individuals enhabiting it — even if they do it much slowly than an AI would (or because of it, since the slower pacing of the changes creates a boiling frog effect regarding the possible resistense against them). 

      And since they are having the same effect on the world, they should be treated with similar caution. And when talking about restrictions for them they should be regarded as entities that have no moral \ ethical judgement of thier own, as an AI would. This in contrast, for instance, to expecting them to “stand up for human rights on their own” (e.g. common expectation towards Google, Netflix, Amazon, etc), [have a sense of social responsibility on their own,](https://en.wikipedia.org/wiki/Corporate_social_responsibility) etc.
      ```

  - u/Croktopus:
    ```
    i was actually giving this some thought the other day, and i guess the thing about corporations (in their existing pre-AGI form) is that while they're paperclip maximizers in many ways, there's an important distinction: decisions are all made by people. And people generally have more complicated motivations than stock prices, so that *potential* for morality makes it less risky than a paperclip maximizer AI.

    And it doesn't even have to be morality - there are other ways people can make decisions that get in the way of corporate paperclipping - embezzling funds, leaking privileged information to the press, just being lazy...

    I think the difference isn't so much that we're used to one and not the other, but that it's like a comparison between a particularly vicious grizzly bear and a particularly dumb three toed sloth.
    ```

- u/IDBN:
  ```
  Thoughts on this?

  https://www.youtube.com/watch?v=QiFOZEiehFo
  ```

- u/gbear605:
  ```
  I've been thinking about the organization of fanfiction recently. I don't have any big takeaways here, but I think it's fairly interesting.

  I feel like fanfiction can roughly be broken down into two categories: plot and romance. Plot fanfics are fanfics that, while they might have romances, the focus of the story is on things happening. Almost all non-fanfiction literature is the equivalent of this category. Romance fanfics are fanfics that are only based on romance and there might not be plot at all. While not technically romance, one shots based on cute character interactions, etc. are also in this category. Trashy romance novels are the non-fanfiction version of this category.

  Also, it's fairly obvious that some types of fiction are much better for *plot* fanfiction than others. I propose that this can be determined by what I call the "self-insert test." If you were to insert yourself as one of the main characters in the fiction, how much can you influence what happens while still playing your part? In something like Harry Potter or Naruto, there's a ton. In something like Sherlock Holmes or The Martian, there's hardly anything.

  I'd also like to propose that how rational a work of fiction is correlated with the self-insert test.
  ```

  - u/GaBeRockKing:
    ```
    Like, you *could* break fanfiction into the categories of "romance" and "not romance", but I don't think it's a particularly useful distinction, because either "not-romance" completely excludes a lot of plot-heavy stuff because it has the barest trace of romance, or you get into the paradox-of-the-heap thing where you have to define "how much romance is romance." And as /u/jeray2000 said, you get into the weird situation where some erotica fits into that not-romance category because you can have porn without any semblance of actual romance.

    Really, the "tagging" approach to genres is probably the best: almost every work fits into multiple, non-exclusive genres, but to different degrees. Harry potter is heavily fantasy, lightly romance, moderately adventure, and moderately high-school. Twilight is heavily romance, lightly adventure, moderately fantasy, and lightly high-school.

    Also, while your hypothesis in your third paragraph is somewhat correct (some fandoms naturally lead towards romance fics, some naturally lead towards action-y fics), you're misinterpreting the causes. If find the greatest predictor of whether a fandom is romance-dominated is the proportion of young girls in that fandom, while the greatest predictor of whether a fandom is action-dominated is the proportion of older men (older still only being "in their twenties") in the fandom. Worm and MLP:FiM predominantly have older males as their fandoms, and as a result are inundated with action-heavy fics. Harry Potter and Naruto are more mixed, and reflect that by having plenty of both romance and actiony fics. One Direction, being almost exclusively female, has overwhelmingly romance fics.

    The "self-insert test", as you call it, doesn't directly predict that prevalence of actiony fics. Rather, it's part of an equation that predicts how many total fics there are in a fandom. Namely, (potential audience for fandom)*(proportion of potential audience that writes fanfiction)*(percent of potential audience a work of this quality is likely to get the attention of)*(average works per fanfic-writer)*(percent suitability for writing the kinds of fanfics the potential fanfiction-writing audience ) = total # of fics. So for works written towards males, who typically want power fantasies, a high score on the "self-insert test" means that those males are more likely to write fanfiction for that work instead of another work, which in turn results in more action-y fanfics. Meanwhile, even if your work is better suited for action fics than romance fics, if your potential audience is primarily of the kind that wants to write romance fics, you're still going to overwhelmingly get romance fics, because the people who want to write action-y fics will move to a fandom where more people want to *read* action-y fics.
    ```

  - u/None:
    ```
    I think that shipping fanfiction and erotica fanfiction should be two entirely separate categories, and I'm not convinced that a romance category besides erotica is meaningfully distinct from every other genre.
    ```

- u/awesomeideas:
  ```
  It has been hitting me more and more lately that our future, barring certain exceptional cataclysms, will be a science-fiction future full of radical differences and the nearly impossible, waiting for us on the other side of a series of flood gates of unknown width.

  How exactly are we supposed to operate and make useful predictions in the face of this extraordinary and currently unimaginable reality-to-be?
  ```

  - u/GaBeRockKing:
    ```
    >How exactly are we supposed to operate and make useful predictions in the face of this extraordinary and currently unimaginable reality-to-be?

    Maximize power, so that when you have a better idea of what the future will look like, you're poised to respond to it.

    More specifically, maximize money (which is directly fungible with power), and minimize financial liabilities.

    I know that doesn't sound particularly actionable-- after all, I'd wager that most of us are already doing our best to be as financially independent as possible, to get good jobs, to make good investments, and so on and so forth, but it's the only real catch-all advice there is for preparing for an uncertain future, and even it has its problems (as it doesn't cover how much of your current happiness you should sacrifice to ensure the greatest probability of future happiness.)

    I could talk about how I make my own predictions, but as my methods are pretty untested, and unlikely to be generalizable, it's probably best that I don't.
    ```

---

