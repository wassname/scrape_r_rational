## [D] Friday Off-Topic Thread

### Post:

Welcome to the Friday Off-Topic Thread! Is there something that you want to talk about with /r/rational, but which isn't rational fiction, or doesn't otherwise belong as a top-level post? This is the place to post it. The idea is that while reddit is a large place, with lots of special little niches, sometimes you just want to talk with a certain group of people about certain sorts of things that aren't related to why you're all here. It's totally understandable that you might want to talk about Japanese game shows with /r/rational instead of going over to /r/japanesegameshows, but it's hopefully also understandable that this isn't really the place for that sort of thing.

So do you want to talk about how your life has been going? Non-rational and/or non-fictional stuff you've been reading? The recent album from your favourite German pop singer? The politics of Southern India? The sexual preferences of the chairman of the Ukrainian soccer league? Different ways to plot meteorological data? The cost of living in Portugal? Corner cases for siteswap notation? All these things and more could possibly be found in the comments below!


### Comments:

- u/None:
  ```
  [deleted]
  ```

  - u/Anderkent:
    ```
    Theory: when you have two agents fighting either one of them is evil, usually in a stupid way, or you have actual moral conflict, which can be pretty unenjoyable if you're just looking for a power fantasy.

    Fighting against natural disasters etc works around that problem.

    I think liking training / coming-into-power arcs is pretty common. It's easier to emphasise with a non-all-powerful character, and you still get the power fantasy once they actually get there.
    ```

    - u/Dwood15:
      ```
      And I think with a training arc in a story, you're there, trudging through it with your characters, so that when they reach full power, it is super satisfying.
      ```

- u/Kishoto:
  ```
  Does anyone ever get tired of being a rationalist? Or, even less pretentiously, just having rationalist tendencies? Specifically I ask because of how some of the "magic" of life seems to be gone. I'm not talking depression or anything that severe but I feel like I've lost my belief in things like true love, the innate goodness of humanity, life having an overarching purpose, etc. because it seems so trivial and easy to break those concepts down into 1s and 0s (metaphorically speaking). Life has no purpose beyond the one we give it. Love is a series of biochemical reactions. Humans aren't innately good; we're innately nothing and shaped by our surroundings more than anything else. 

  I'm the type of person where I need to know the truth. It's almost compulsive. But I feel like I may have had an easier time being happy if I'd never stumbled across the rational path of thinking. But, even having come to that conclusion, I can't just turn it off. It's like someone pointing out a crack in a glass you thought was perfect. You just can't unsee it.

  Am I making any sense or am I just being a classically whiny millennial?
  ```

  - u/Anderkent:
    ```
    That's sad. I corellate such feelings more with general depression, than with the rationalist tendencies.

    You have to remember - just because you can explain love, take it apart, doesn't mean it's no longer a thing. A rainbow shouldn't stop being pretty just because you know it's the result of light hitting droplets of water in the air.

    It seems like you have a tendency of only assigning value to mystical, unachievable things. I'd suggest trying to dig deeper into why that is. In the meantime; carpe diem!


    p.s. sorry if this sounds condescending, or dismissive. I don't mean it so, but I spent 5 minutes on this and couldn't find a better way of conveying the idea.
    ```

    - u/Kishoto:
      ```
      It's not a binary thing. It's not like something has value or it doesn't. It's just the mystical sheen surrounding certain concepts has been brutally torn away and I regret their loss. 

      For example, the concept of "the one". That used to be a comfort to me, when I was younger. "Oh, Becky doesn't like me. But that's ok, the one is out there!" 

      Ha. No. I'm not pessimistic. I know there's more than enough women out there that I could find one to be happy with. But it's also possible that I never find one to be happy with. I don't say that to whine or complain; but my innate knowledge of that possibility dims my view on relationships quite a bit.
      ```

      - u/Anderkent:
        ```
        Isn't that just growing up, though? Yes, people get a bit disillusioned as they learn more about the world; and it takes work to reestablish the emotional valence of some ideas that used to be simple. But you can definitely still do it.

        Taking your example, if you think about it a bit more, the fact that there isn't one soulmate that you have to wait for means you have a chance to actually make a successful relationship happen. You can work at it, rather than wait for it to happen to you. This, to me, is a positive thought.

        I find that many concepts work in the same way. You lose some naive positivity, but in trade you find out more about how things really work, and how to turn that to your advantage.

        Successful relationships have grown more impressive to me, rather than less, once I learned that they actually take work. If that's not the case for you, try to figure out why?

        Of course sometimes you'll find out about something that you can't help at all. And that sucks, and getting over it can often be difficult. I have no advice there other than with time I've grown numb to the impossible to solve problems (their impossibility actually helping here, I feel, because it means I don't feel responsible at all); while the ones where I have hope of success have grown more important to me.

        If it's just the loss of simplicity, of naive optimism, that you're mourning, - rather than any subject that you were naive about in particular - then I'm afraid I can't help you there. Sure, being naively happy and childish is cute. In children. And fictional characters that always succeed due to Manic Pixie Dream Girl plot armor.

        But I don't envy it in adults.
        ```

      - u/gabbalis:
        ```
        >For example, the concept of "the one". That used to be a comfort to me, when I was younger. 

        Yeah, I think the thought of Neo coming to save us comforted us all when we were younger...
        ```

  - u/b_sen:
    ```
    You are making sense!

    You might not have heard of the [Sequence about that](https://wiki.lesswrong.com/wiki/Joy_in_the_Merely_Real).

    Also, I have a relevant mini-rant regarding [this Terry Pratchett quote](https://www.goodreads.com/quotes/66591-all-right-said-susan-i-m-not-stupid-you-re-saying-humans), which I'm going to test out:

    Sure, there are no atoms of justice or molecules of mercy.  But there are no atoms of chairs or computers either, yet anyone claiming either of those to be a lie would be seen as delusional.  There are real *arrangements of matter in the universe* that fit your concepts of chairs and computers, just like there are real arrangements of matter in the universe that fit your concepts of justice-recognizing-and-improving-thing and mercy-recognizing-and-improving-thing.  What difference does it make to their reality that the latter sets happen to exist in people's brains instead of in visible external objects?
    ```

  - u/TaoGaming:
    ```
    There are several (many?) stories I read that posit that the universe is cold and indifferent, or outright hostile and actively rooting against you, and that the only meaning that life has is the meaning you **choose** to give it.

    Yes, we are shaped by our environment ... dashed to and fro, but we make the choices and we shape it (and the rest of us) in return. 

    As they say in the *African Queen*:
    Charlie Alnutt (trying to explain away his drinking): "... It's only human nature."
    Rose Sayer: "Nature, Mr. Allnut, is what we are put in this world to rise above."

    If the idea of an uncaring (or hostile) universe doesn't strike you as inspiring, I recommend the "Welcome to Nightvale" podcast, or "Awake in the Night Land." I'm sure there are others.
    ```

  - u/Frommerman:
    ```
    Just because you know how those things work doesn't mean they have to lose meaning for you. The only thing that has changed is your knowledge, after all. The things themselves remained unchanged when you learned how they work. If empathy and helping a person in pain felt awesome before, it still should! If loving someone felt amazing, knowing that it's a chemical reaction shouldn't lessen the feeling because nothing about love changed. Only you did.
    ```

  - u/Sparkwitch:
    ```
    Rationalism actually *convinced* me of the innate goodness of humanity. If, in general, people were not fundamentally gentle, kind, and caring society would fall apart fast. The temporary power gained by even small betrayals is so out-of-proportion with the amount of effort required that if people were even slightly more selfish and unforgiving they'd be stabbing each other in the back all the time.

    Sure, there are rare exceptions... and the obvious damage they do (and the largely undamaged state of the social fabric) makes it obvious how rare they must be.

    No individual necessarily has an innate goodness, but humanity absolutely does.
    ```

- u/Anderkent:
  ```
  I've skimmed a blog a while ago that discussed dating, and in particular one post I remember was it analysed the consequences of choosing particular okcupid questions as either important or not. I couldn't find the post again, and since it was probably coming either from /r/rational, rationalist-adjacent facebook friends, or rationalist tubmlr, I was hoping someone would know what I'm talking about and could find it.

  The particular trick I remember was a way of compressing your 'matching %' range from 80-100 to 90+-100 (so that the relative order of matches is the same, but the numbers are higher), by treating some questions as less or more important. But I can't really remember the details.
  ```

  - u/somerandomguy2008:
    ```
    Was it [this](https://putanumonit.com/2016/02/03/015-dating_1/) one? Or more specifically, the [1.5](https://putanumonit.com/2016/02/10/017-dating_2/) section where it talks about match percentage?
    ```

    - u/Anderkent:
      ```
      It was! I definitely remember the upside down underwear stripper pole picture :P

      Alas it doesn't seem that useful on a more detailed read, but thanks for finding it.
      ```

- u/hoja_nasredin:
  ```
  IT'S ROBOT FIGHTING TIME.

  Who here watched Battlebots FInale? What do you think?
  ```

- u/trekie140:
  ```
  This week, CPGrey released a video where he extolled the virtues of self-driving cars and how they'd make navigating traffic better for all of us. While I agree completely, at one point he suggested banning human drivers from the road, an idea to which I instinctively react to with horror. Not because I'm afraid of robots, but because my values include human autonomy.

  I think that forcing a person to use an autopilot instead of giving them the option to do so is a violation of a person's rights. I'm all for incentivizing people to use autopilot, including making manual operation more difficult, but for human society to decide that humans cannot be trusted to do something for themselves horrifies me. Does anyone else feel this way?
  ```

  - u/sir_pirriplin:
    ```
    > for human society to decide that humans cannot be trusted to do something for themselves horrifies me. Does anyone else feel this way?

    That sounds like status quo bias. Humans already cannot be trusted to do all sort of things, but this particular thing horrifies you because you are used to it.
    ```

    - u/trekie140:
      ```
      No, it horrifies me because it applies universally. This isn't a matter of doing work better, like with automation or assistance in the workplace, but something individuals do of their own volition with their own property. Their actions effect other people, of course, but I value a person's control over their own property and would consider a law that forbids them from directly controlling their property as a consequence of owning it to conflict with that value.
      ```

      - u/sir_pirriplin:
        ```
        Maybe the robots are a red herring.

        Suppose you don't like your house and want to build a nicer one on the same terrain, which is also yours. Are you allowed to just blow it up with your own explosives? 

        It's your property and your life on the line, but most people would agree you should hire a (human) professional. Do you agree with that? Is it the robot part or the freedom part that bothers you the most?
        ```

        - u/trekie140:
          ```
          The freedom part. I love robotic drivers and will encourage people to use them at every opportunity, I just think it's wrong to force people to. In the example you give, I am completely okay with regulations surrounding how the demolition is carried out like permits, but I equate the banning of human drivers to forbidding the property owner to have any role in the demolition beyond requesting it.
          ```

          - u/callmebrotherg:
            ```
            What about the ban keeping intoxicated people from driving?
            ```

      - u/DaystarEld:
        ```
        Things individuals do with their own property aren't inviolate currently, though. They're subject to restrictions. Maybe your values dislike those restrictions too, but if it's not a universal absolute, that's not quite addressing the potential of status quo bias. Can you think of an exception that you're okay with? Something you agree humans shouldn't be allowed to do with their own property?

        Also, what if people were still allowed to drive their own cars but had 100% liability for any accidents and harm they're involved in. Would you be okay with that?
        ```

        - u/trekie140:
          ```
          That is a scenario I would be completely fine with, since it still permits someone to drive their car if they choose to, it just attaches potential consequences to the decision. I am okay with, and even desire, regulations on what people do with their property. I want people to have the option, but the law should regulate how they do it.
          ```

  - u/Aabcehmu112358:
    ```
    Assuming an ideal system where autopilot not only drives more-or-less perfectly (which is already the case) but is also secure against infiltration, then I agree entirely with Grey. As it stands, however, self-driving cars only defense, as far as I'm aware anyway, is that they are so rare that they are ineffective as a means of manipulating or killing people.
    ```

  - u/Sparkwitch:
    ```
    Where do you draw the line?

    Is it okay to ban human driving on certain roads? In certain municipalities? For drivers with less than perfect vision or hearing? How about drivers above or below particular ages? Drivers with multiple DUIs?

    Is it fair to ban human driving above particular speeds? Is autonomy restricted if drivers are made to stop rather than simply yield at red lights?
    ```

  - u/Dwood15:
    ```
    I can understand your sentiment, however at one point, the human has to leave the driver's seat behind and become a passenger. This is probably in the next 50-75 years, however, so I expect a much more effected Self-Driving car system by then than we have now.

    My second concern, however, is people getting all hot-and-heavy with networking in cars, and their security. As someone who has followed Self-Driving cars steadily, as well as IT security, I am terrified of a rogue state or FBI guy not liking an activists opinion and then slamming the car into a tree or highway traffic at 70+ mph.
    ```

- u/DataPacRat:
  ```
  **Any spreadsheet jockeys who can help?**

  I've had a thought which might help with some of my writing, but I don't quite have the chops to work out the details. In short, I want to try comparing how long it takes for a billion person-years to pass, in various eras, and with various assumptions about ems and computing-capacity. Anyone here who might be able to help me draw a few graphs and charts?
  ```

  - u/ulyssessword:
    ```
    I just slapped [this](https://docs.google.com/spreadsheets/d/11al0Ly97GydAySG9YQ2D9oKD9MyL95zw79FoLNKZyC8/edit?usp=sharing) together in a few minutes, I'm not sure what features you're looking for.  

    In short, I took the UN population estimates for 2020-2100, and assumed that people are awake for 0.66 of each day.  For Ems, I assumed that they start at 1000 population and 3x speed, and double in population and increase in speed by 20% every five years.  (These numbers are easy to alter).  Lastly, you add together (people * people time rate + Ems * Em time rate) and divide a billion by that to get how long a billion person-years takes.
    ```

- u/Polycephal_Lee:
  ```
  Is anyone here watching Mr Robot? I haven't made a main post about it because it's not text fiction, but I think it meets all of the criteria for rational. And beside that, it's fucking awesome. Great writing, great story, great acting, great cinematography, great music, great message.

  It's kinda hard to talk about it without spoilers though.

  (We have a very robotful discussion today!)
  ```

  - u/blazinghand:
    ```
    There is no requirements that top-level posts be only about text-based fiction. Video games, movies, art in any form really counts. It just so happens that the vast majority of rational work comes in text form (and a lot of it comes in fanfic form) but this is not a requirement at all.
    ```

  - u/gvsmirnov:
    ```
    Oh, good point! I find myself making predictions on what happens next, detecting foreshadowings and interesting moments. Although I am not convinced that it's solvable. For instance, [eps2.6_succ3ss0r.p12 spoiler](#s "The fact that Elliot turns out to be in jail") would be very hard to predict. On the one hand, we know from [season 1 spoiler](#s "that Elliot left behind some evidence of hacking, i.e. the microchip that the dog ate") and the general lifestyle of Elliot is suggestive. But on the other hand, there is other evidence [eps2.2_init_1.asec spoiler](#s "Eliot going to Ray's place to play chess and hack the FBI") that makes it much less predictable.

    Actually, now that you've mentioned it, I found /r/MrRobot/, which seems to have all I want.
    ```

---

