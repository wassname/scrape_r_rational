## [BST][D]Useful tools for authors describing Utopia or Best Possible Worlds? Sufficiently Advanced RPG? CYOA? GURPS? Other? Theory of Fun?

### Post:

Hi, I was trying to come up with some useful tools, and useful uses of tools, which one could use to describe a more 'ideal world' or 'ideal setting' or 'utopia that doesn't suck', given particular constraints.

For example, how would you use the tools in the roleplaying game 'Sufficiently Advanced', at http://suffadv.wikidot.com/ to describe a really fantastic place to live?

Or for another way, look up 'Magical Realm CYOA', which is specifically designed for writing and communal storytelling, and how would YOU describe a place that is a really fantastic way to live, minmaxing that?

In a major way, what would some of the major core values of a civilization be? Has anyone taken -- say -- the list of Core Values in Sufficiently Advanced and tried to come up with a set that a Theory of Fun-compliant (see the posts on Lesswrong) civilization would probably follow?

What other tools are there?  How can we bound this problem to make it more solvable for the purposes of writing fiction?

As an example, what are some of the values that Iain M. Banks' The Culture would have, using Sufficiently Advanced, or perhaps whatever GURPS uses when describing sci fi settings in a social and moral way (and what DOES Gurps use to do that)?  We know that The Culture isn't the best place to live, but it's decent and it's probably something most of us are somewhat familiar with, being the 'maybe least sucky utopia for future-looking Western civilization people in popular consciousness'?

### Comments:

- u/Charlie___:
  ```
  My general thoughts on utopias: focus on characters. If there are characters with interesting relationships with each other, it doesn't matter if there's no huge conflict. People still need things to do, and utopias still need to experience change, and stories set in utopias often rely on these things, but they seem most utopian when they're about the characters.

  Think of themes and story categories that don't need the threat of serious harm to their characters, or major upheavals of the world order - sports, travel, romance, growing into adulthood, exploring the past, moving into a new town, studies of character and occupation, group rivalry, exploring the wild, undertaking a heroic task.

  Eschewing events or characters of grand Significance is unpopular in sci fi, but not at all impossible. You could write Player of Games without anybody's life hanging in the balance, or set Catcher in the Rye in a time without death.
  ```

- u/ToaKraka:
  ```
  > As an example, what are some of the values that Iain M. Banks' The Culture would have, using Sufficiently Advanced, or perhaps whatever GURPS uses when describing sci fi settings in a social and moral way (and what DOES Gurps use to do that)?

  GURPS's treatment of societal freedom isn't any more nuanced than [the D20 system's](http://www.dandwiki.com/wiki/MSRD:Equipment_Basics#Restricted_Objects), with a very similar system of "Control Rating" for societies and "Legality Class" for equipment. On the other hand, GURPS does have slightly more complicated technological ratings, which can be applied on a per-sector basis (e.g., TL7 in general, with TL8 medical science and TL6 transportation):  
  \- TL0, the Stone Age  
  \- TL1, the Bronze Age (3500 BCE)  
  \- TL2, the Iron Age (1200 BCE)  
  \- TL3, the Middle Ages (600 CE)  
  \- TL4, the Age of Sail (1450 CE)  
  \- TL5, the Industrial Revolution (1730 CE)  
  \- TL6, the Mechanized Age (1880 CE)  
  \- TL7, the Nuclear Age (1940 CE)  
  \- TL8, the Digital Age (1980 CE)  
  \- TL9, the Microtech Age (2025 CE)  
  \- TL10, the Robotic Age (2070 CE)  
  \- TL11, the Age of Exotic Matter  
  \- TL12, the Age of Miracles

  I don't own *[GURPS Ultra-Tech](http://www.sjgames.com/gurps/books/Ultra-Tech/)*, which covers TLs 9 through 12--it probably contains more detailed information on what you're looking for. Certainly, [its table of contents](http://www.sjgames.com/gurps/books/Ultra-Tech/toc.pdf) points to a sidebar titled "Superhuman Minds and the Singularity", at the very least.

  In reference to morals/values, that wouldn't manifest much more clearly than an AI character's having the negative trait "Social Stigma (Valuable Property)", or something along those lines, IIRC.
  ```

  - u/Reasonableviking:
    ```
    This is the entirety of the sidebar btw: 
    "Volitional AIs with intelligence equivalent to a human genius are possible at TL10+. If created, they build better hardware or software for themselves, resulting in the evolution of AIs whose
    intellects make humans look like dumb animals or insects. These beings might be able to advance science and engineering to a point human minds can no longer comprehend – a technological
    “singularity.”
    In such a society, super-intelligent “AI gods” may rule civilization – or they may remain aloof from lesser intelligences. Their works may be used to justify the existence of superscience technologies (e.g.,
    FTL drives or wormhole networks) that people can use, but do not understand. Such entities can serve as a posthuman alternative to the ancient, wise, and long-vanished “precursor” races that appear in many space opera settings.
    Of course, this scenario is by no means predestined! It’s just as likely that superhuman AI is difficult or impossible to achieve, or that sapient AIs would be built with strict restrictions to prevent
    their evolution."
    ```

---

