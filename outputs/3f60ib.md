## Dark Side Rationality: Taking Advantage of People's Non-Rationality

### Post:

[Link to content](http://www.cracked.com/personal-experiences-1762-5-reasons-i-lost-249000-iphone-game.html)

### Comments:

- u/eaglejarl:
  ```
  The rationality here is with the game designers, not the players.
  ```

- u/ArgentStonecutter:
  ```
  That's pretty impressive, but consider that Star Citizen has taken in $77M for virtual starships and hasn't even shipped yet.

  http://www.wired.com/2015/03/fans-dropped-77m-guys-buggy-half-built-game/

  > The United Empire of Earth Navy caused quite a stir last November when it announced that it would be putting 200 decommissioned Javelin Destroyers up for sale. Each 1,132-foot-long spaceship has the sort of amenities that your average interstellar mercenary finds hard to resist: four primary thrusters, 12 maneuvering thrusters, a heavily armored bridge, private quarters for a captain and an executive officer, six cargo rooms, general quarters for a minimum of 23 crew members, and a hangar big enough to accommodate a gunship. There's even a lifetime insurance policy.

  > The document that announced the Javelins' impending sale took pains to stress that these warships were fixer-uppers. “They are battle-hardened and somewhat worse for wear,” it read, “and have been stripped of the weapons systems.” Thus, any would-be buyer would eventually have to shell out extra to equip the 20 gun turrets and the two torpedo launchers. The asking price for each ship: $2,500. And that wasn't some form of fictional futuristic space bucks; it was 2,500 real dollars. Actual, real, present-day American Earth dollars.

  > Despite those caveats, all 200 Javelins sold out. In less than a minute.
  ```

  - u/Transfuturist:
    ```
    If Star Citizen fails, it will be the biggest Early Access shitstorm yet.
    ```

    - u/ArgentStonecutter:
      ```
      [I'm ready](http://replygif.net/i/1112.gif)
      ```

- u/Kishoto:
  ```
  I also seek to be able to do this. I'd love to learn enough about the errors in the average humans way of thinking to turn a profit, be it monetarily, socially or otherwise. Does the fact that the thought of being that sort of puppeteer is an exciting one mean I'm a little messed up?
  ```

  - u/daydev:
    ```
    We all love "munchkining the system" here. But it's one thing to twist the rules of an impartial arbitrary magic system, and it's a very different thing to exploit people through evolutionary "bugs".
    ```

    - u/Newfur:
      ```
      Why so? I feel like playing devil's advocate today, and I'm interested to hear you elucidate your reasoning.
      ```

      - u/eaglejarl:
        ```
        I won't speak for daydev, but one argument that could be raised is:  munchkining magic systems doesn't hurt anyone.  Munchkining evolutionary bugs actually does hurt people -- for example, in the linked article you'll see that gamers spent thousands of dollars on the game.  That money could have been used to help a lot of people, but instead it was spent on virtual goods that were then destroyed; if people had skipped playing the game and just set a giant stack of money on fire the result would have been *less* harmful, because the opportunity costs wouldn't have been paid.
        ```

        - u/redrach:
          ```
          Well to be precise no money is being set on fire, even metaphorically speaking. It's all going to the makers. What's really happening is they've managed to sell an enormous number of people extremely perishable virtual goods.
          ```

          - u/eaglejarl:
            ```
            Fair point.  Still, the general idea applies -- the players could have made the world a better place with that money, but instead they gave it to a corporation.
            ```

            - u/None:
              ```
              [deleted]
              ```

              - u/traverseda:
                ```
                On the meta level, we don't want people who identify with the broader rationalist/lesswrong community doing that. It makes all of us seem less trustworthy. Utilitarianism is scary, idealism and love and tolerance and puppies aren't.
                ```

              - u/Chronophilia:
                ```
                I know you're not being serious, but that gave me chills. How self-absorbed and self-righteous would a person have to be, to think that they are that much more intelligent and moral than the average? That even accounting for the losses in the system, it'd still be better for the world than working in charity *yourself* and letting everyone else spend their money how they feel it should be spent - because the general, irrational public is just *so* irrational and *so* immoral and *so* far beyond help that they shouldn't be allowed to make spending decisions that affect the world? And you *can* make those decisions, because you're far more intelligent than everyone else?

                I've always thought the textbook description of a utility monster was unrealistic, and now I've found the example I was missing.

                ----

                But just in case you're actually thinking of doing this: making a profitable company from scratch is far from trivial. Behind every billion-dollar Farmville and Candy Crush there's ten thousand games that barely recouped development costs and a million games that crashed and burned. Even if you think you've got a brilliant revolutionary idea that can't possibly fail... well, that describes half of Silicon Valley, and most of their startups still don't work.
                ```

                - u/eaglejarl:
                  ```
                  Much more than half.
                  ```

                - u/None:
                  ```
                  [deleted]
                  ```

                  - u/Chronophilia:
                    ```
                    >Do you not think it plausible that someone might see enough evidence of their intelligence and altruism relative to others' that they can be confident in the statement that they are "much more intelligent and moral than the average"?

                    No, I really don't. Rationality is not about being better than everyone else, it's about recognising and overcoming one's cognitive biases. And several of those biases are actively pushing in the direction of "you're better than everyone else" - the Dunning-Kruger effect, the bias blind spot, the way your own moral code is the standard by which you judge everyone else's so by definition you'll always be the most moral person, etc.

                    The wisest man is the one who knows he knows nothing, and the easiest way to lose your rationality is to assume that you've got it.

                    Anyway, the number of people who could actually be a truly benevolent dictator is massively less than the number of people who could become an evil but misled dictator, to the point that even if you've spent a long time self-reflecting and analysing your motivations it's still more likely that you're in the second group. And even if you're not... is it worth sending the message that taking over people's lives for them is OK, as long as you're more moral than them? Do we want scientologists and creationists to take home that lesson?
                    ```

                    - u/None:
                      ```
                      [deleted]
                      ```

      - u/daydev:
        ```
        Well, rationality presumes that we should "rise above" our flawed biological hardware. So it's kind of hypocritical to pronounce that everyone should overcome the evolutionary bugs, but in the meantime take advantage of those who haven't.

        And it's "not fair" precisely because they are bugs. It's like hacking computer systems. It may be fun as intellectual exercise, but if you then proceed to steal people's money through hacked systems, you're a crook. So pranks for fun may be OK, but cons for money are not, and this kind of freemium is almost an industrialized con. It's not exactly the same, since you're actually getting what you're paying for, but they arrange the system to suck you into paying for things you never would've wanted to pay otherwise. It's like middle ground between extremely aggressive marketing and cons.  

        Also, as eaglejar said, you can't hurt the universe by exploiting its rules to get an advantage. But you can hurt people by exploiting their wiring to get and advantage.
        ```

      - u/None:
        ```
        It's kind of like what I've been told reading *Thinking Fast and Slow* is like: you think you know the tricks and will see them coming, but then they're used against you, and you totally fall for it every time.
        ```

- u/FuguofAnotherWorld:
  ```
  It's the perfect storm. I've read the theory the makers of this kind of thing used before, and it's fascinating but this one takes it one step further. It seems they've advanced to the pinnacle of manipulation through flashing numbers. It's like a dollar auction mixed with the sunk cost fallacy, classical conditioning and an ocean of evaporative strengthening of peers.
  ```

- u/Farmerbob1:
  ```
  People are looking at electronic games and seeing this behavior, but the same behavior is far older that any electronic games.

  Gambling.  Lotteries.  The house always wins in the end.
  ```

  - u/eaglejarl:
    ```
    There's some differences, though.  Take a look at, for example, blackjack:

    * Pay to play; you know you're spending money if you sit down
    * Can win money, and the money comes from the house
    * Players don't interact [1], and can't gain or lose money from/to each other
    * Can leave at any time, no consequences
    * When you leave, you keep all your money and whatever you've won from the house.

    Now look at the linked game:

    * Sit down for free, but lures you into spending money
    * Can't win
    * Continually interact with other players by costing them money
    * Can't leave without cost
    * When you leave, you steadily lose all the money you've put in

    The house's money is never at risk, and the player can only lose, not win or break even.  Furthermore, players are directly pitted against one another to make each other lose faster.

    ----

    [1] Technically blackjack players interact to the effect that if I take a card then the next person gets a different card.  That's not generally relevant, though.
    ```

    - u/Farmerbob1:
      ```
      There are differences, but in both cases the victims have been fooled into engaging in a contest that is either unwinnable, or has an extraordinarily low probability of winning decisively.

      'Winning' is a practically unattainable goal, but a lot of people will see the goal and not understand the impracticality of it.

      A sufficiently unscrupulous rational individual can implement 'entertainment' that will attract irrational people who are attracted to winning.

      Is there a functional difference between a tiny chance of winning and no chance of winning?

      No, not for most individuals.  Most 'winners' of games of chance end up losing more than they win before they are 'lucky' and win big.  Occasionally, some newbie gambler will win big after just a few hands or a few slots, but that's rare.  It has to be.  If it wasn't, the house would lose money.

      The game specifically referred to is simply a gambling operation with no way to win *against the house*.  You can still win *against other players*.

      A lot like poker.
      ```

- u/darkflagrance:
  ```
  The players burn each other's money. What's not to love about this game design? It's beautiful.
  ```

---

