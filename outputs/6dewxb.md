## [deleted by user]

### Post:

[removed]

### Comments:

- u/FeepingCreature:
  ```
  The more upload fics I read, the more I think we need some sort of So You Want To Become An Upload: A Primer In Applied Transhumanism leaflet, with rules like "Don't try and hide bad news from yourself- it never works", "Trust your fork; they have the outside perspective" and "Only fork if you want to take *both* roles".

  [Edit] Let's add "p-zombies and why there's no such thing" and "Why people who can't even cooperate with copies of themselves are the saddest sacks of failure".
  ```

  - u/Noumero:
    ```
    Why the hell not. [Let's do it.](https://i.imgur.com/9OZL06T.png)

    Ideas for more advice? Something about timeless prisoner's dilemma and superrationality, perhaps? And text about p-zombies and sacks of failures, do you have anything particular in mind?.

    (I would actually prefer if someone with more experience in creating such things (or, like, someone capable of using an image editor other than bloody Paint) took over, but nobody will, will they.)
    ```

    - u/FeepingCreature:
      ```
      [I made one in GIMP](http://i.imgur.com/cSYfPNv.png). It's roughly inspired by the "so you've travelled back in time" poster.

      Admittedly it got away from my original advice somewhat.
      ```

      - u/jcolechanged:
        ```
        That was really cool to read and I really enjoyed it.

        I'm not at all convinced p-zombies can't be real though. In general, I think the stuff about p-zombies makes assumptions that rely on philosophy that doesn't really have to hold true. Like having to have the two universes obey the same physical laws in order to be identical to observers? Why would they have to do that? WoG can be much more powerful then that. For sure, you can write computer programs that display the same thing, but have different underlying mechanisms. 

        Leaving aside that how consciousness works is kind of unknown, so I could be way off in details...

        The argument against p-zombies given in the pamphlet doesn't make them impossible. It just means that all their arguments would match what a version of them that was a p-zombie would make. So they wouldn't be able to convince someone that they weren't a p-zombie by their actions. Presumably, there could potentially be other things that could decide that. Other evidence. For example, the runtime itself or the code running on it would be evidence that could sway one way or the other.

        Consider a simulated environment that has qualia within it and the ability to save and load. It also has a way for someone to watch it. The simulation is run. The simulation software makes a recording of the only output screen. It also saves the environment every few minutes. Later that same simulation is run again. This time, instead of actually simulating the environment for real, it just uses the cached output. It only bothers with more complex interactions when a divergence point hits due to outside interaction. In that case the simulated environment loads from the closest save file before the divergence and uses it like a video's keyframe to reach the relevant divergence point. Whatever interaction was supposed to happen at that time plays out.

        This is a basic example. It's also a shortcut that probably really would be used for simulations in order to save on resource usage, since we pretty much do something analogous with videos. It has the side-effect of making something that may or may not be a p-zombie, from an external persons view, since if you didn't know if you were the first person to watch that simulation you wouldn't be able to tell if the person was real or just a recording. However, you could still interact with them. Still treat them like a real person, in a way.

        Thanks for taking the time to make that.
        ```

        - u/FeepingCreature:
          ```
          The argument doesn't _exactly_ mean it's impossible, but it does mean that given a straight upload that functions correctly, there can be no evidence that should convince you the upload is not conscious that shouldn't also convince you that you are not conscious.

          > it just uses the cached output.

          Still has qualia. Just because you compute a value once and then cache it, doesn't mean you didn't compute it. It's still the output of that algorithm, it's just you're accessing the output twice at different points in time.
          ```

          - u/jcolechanged:
            ```
            Okay.

            Lets say there is a simulation that uses the mechanics mentioned earlier. The sim on the video starts telling you he is real and that by running him you are causing him to experience emotional pain. He just can't prove it to you, because everything he says can be assumed to be what a p-zombie would say.

            You pause the sim. You open up the folder the sim uses to save cached videos. You find the one where he waxes about being real. It's pretty long. You've just found evidence that suggests that even though he experienced emotional pain, watching him isn't causing emotional pain like he suggested. He isn't real right now. Someone else watched the sim first. As long as you don't interact, he feels no pain.

            Do you feel real? You pinch yourself. Yeah. Still feel real.

            Can you press play without causing him pain? Yes. He can't feel anything. He's not real. Yet... if you talk to him? Save file loaded. He answers.

            You can press play on the sim, knowing he isn't real, because he isn't. You aren't causing him pain by pressing play, because of how the sim is implemented.
            ```

            - u/FeepingCreature:
              ```
              He isn't real right now. But he _was real at the time he's talking from_.

              You're watching a real thing with lag. The pain is real, despite the fact that you're not causing it.

              The best analogy I've heard for this is it's akin to talking into a cellphone. The cellphone can't feel pain, obviously. But the pain is still _real_, it's just not where the voice is coming from.
              ```

              - u/jcolechanged:
                ```
                You're right. He was real at some point. I'm not contesting that. 

                What I'm trying to show is that its possible to have clever workarounds that mitigate new qualia production and that theoretically there might be other abstractions that could further mitigate them. Or remove them.

                For example, if you know all the details of an environment and you also have the mind state of someone, can you derive what they've done recently? Can that be used to postcog part of a simulation? Can you iteratively postcog with that? Does the postcog produce qualia? If you can't derive from that well enough to be useful, how is it that some people can have perfect recall well enough to be useful? If you derive what happens successfully, but you did it without needing to run the qualia producing actual simulation... then you just expanded the number of things that can happen in simulation without requiring qualia to be a thing.

                I feel like there is enough that we don't know, that ruling out the idea that its possible to implement things without qualia is naive. Especially when every example of an AI that I actually do know how to make doesn't seem to have a mechanism that allows for consciousness and whatever that mechanism that allows for consciousness is, I don't know it.

                Meanwhile, the claim that its not possible to find evidence of the simulation being real or not real? It isn't true. It's looking at the simulation only, which is equivalent for practical purposes, rather then the wider world- which doesn't have that restriction and can cache or do a whole host of other things which are going to be investigable. 

                Interestingly, practically speaking? Treat them as real anyway. Even if they aren't, if they are equivalent, they aren't going to take kindly to being treated badly. No point in being cruel, especially when reciprocity is a thing.
                ```

                - u/FeepingCreature:
                  ```
                  "But it isn't _really_ cruel, is it? They don't have _real_ feelings, just facsimiles." is what I'm arguing against.

                  It's certainly possible to make a simulation that fakes having qualia well enough to be very hard to distinguish. But it won't happen on its own just from making an upload, and all things being equal you should take people's words for it when they say they have feelings unless you have _concrete_ evidence to the contrary.

                  The point of the argument is just that if qualia can be subtracted without changing the physical machinery, which is after all what our reason runs on, we have no reason to believe we possess them in the first place. A thing that acts equally in presence as in absence is not evidence.
                  ```

                  - u/jcolechanged:
                    ```
                    > The point of the argument is just that if qualia can be subtracted without changing the physical machinery, which is after all what our reason runs on, we have no reason to believe we possess them in the first place.

                    The physical machinery is changed, implicitly, in the context of an upload. The runtime is a simulated environment rather than the original. We've already shown that by changing facts you can absolutely subtract qualia.

                    I suspect in general that philosophy has poisoned the discussion. I've seen a few people talk about p-zombies not being real, because of the p-zombie arguments about physicalism. Those thought experiments rely on duplicated facts. They are not relevant to the discussion as a consequence, because it would be absurd to actually duplicate facts and impossible besides- the fact that they are a simulation on a different run time adds a meta-fact, that goes beyond their own universe and subtly changes it from our own. Or not so subtly, if the creator intervenes.
                    ```

                    - u/FeepingCreature:
                      ```
                      > The physical machinery is changed, implicitly, in the context of an upload. 

                      Eeeeeeh.

                      It's changed indexically but not computationally? In principle, you should be able to do a straight 1:1 upload that goes from "direct physics" to "physics embedded in a computer"; since it's computationally equivalent I wouldn't consider that a change of machinery anymore than running Windows in a VM is a different OS. The simulation ought to "screen off" facts outside it.

                      And yes, obviously it's possible to just tell the upload that they're in a simulation, but that alone seems an insufficient additional fact to subtract qualia.
                      ```

                    - u/Empiricist_or_not:
                      ```
                      I'm not sure if you are making an argument for P-zombies as a devils advocate, so I'll only ask: have you read Blindsight? (Warning if you haven't: there are some real existential dread that may result if you do)
                      ```

- u/mcgruntman:
  ```
  It's so tense.. feels like a jumpy thriller film.
  ```

- u/Dwood15:
  ```
  Each update, I love this fic more and more.
  ```

---

