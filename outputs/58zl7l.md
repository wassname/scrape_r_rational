## Transcendence (yes, the movie)

### Post:

I re-watched [Transcendence](https://www.youtube.com/watch?v=VCTen3-B8GU) the other day out of some misplaced masochistic tendency and the desperate belief that it really couldn't be that bad, could it? Only to find that yes, yes it really could be that bad.

I won't go into a full listing of its faults here, but a few points that really jumped out was how comprehensively bad the characters were at answering their own questions. The main conflict in the story is that they aren't sure if the uploaded consciousness of Johnny Depp is the guiding intelligence of the AI, or if it is merely an improved version of the weak AI they had at the beginning of the movie. Morgan Freeman actually asks the AI "Can you prove that you are conscious?". This question is so pointless on so many levels, first and foremost because, as far as I am aware, there *is* no definitive proof of consciousness, and it may be **impossible** for such a proof to exist without the capacity to read another person's mind.

There are other problems, like the fact that they eventually decide to shut down the internet to kill the AI, ignoring that this would lead to the collapse of technological civilization and the death of, at a conservative estimate, hundreds of millions of people; or that the terrorists call killing an augmentee 'giving him back his humanity'; and other such rot.

But, since uploading and AI are likely a subject near and dear to many of our hearts, does anyone know a more rational version of this story? Besides the excellent [Friendship is Optimal](http://www.fimfiction.net/story/62074/friendship-is-optimal) of course, which is more or less what should have happened.

Edit: Actually found a decent example! [Singularity's End](http://archiveofourown.org/works/1534028/chapters/3246698), but more are welcome.

### Comments:

- u/Gurkenglas:
  ```
  Don't forget the plot hole of him [Spoiler](#s "not needing to actually shut himself down when a hostage was taken - he could have just appeared to drop dead and waited a few more minutes for his nanomachines to replicate beyond physical resistance.")
  ```

  - u/totorox92:
    ```
    Yeah, lots of plot holes.

    I mean, honestly, if he actually cared about humanity, he would be willing to allow his wife to die. Their whole model is: 'if he lets her die, he's an unfriendly AI... and now he's unstoppable' or 'he saves her, in which case he *isn't* an unfriendly AI... so now he's dead'. So dumb. Massive bummer. It's actually one of the things that started prompting me to try and make a genuine Hollywood style scifi action blockbuster about an *actual* strong, friendly AI, but I'm not super good at that sort of story so...
    ```

    - u/Gurkenglas:
      ```
      Well, their reasoning wasn't that bad there: If they are fortunate, he still hasn't self-modified all of his humanity away yet, and can be defeated by exploiting his human scope insensitivity. They've already decided that him winning is the worst possible outcome.
      ```

      - u/totorox92:
        ```
        Hmm. I suppose that makes sense. But it seems that they assume he *has* already modified himself away from that, or more precisely, that he is merely PINN (the weak AI) able to exploit the memories and personality remnants of the upload to become a strong, unfriendly AI. 

        I don't know, I may just be having trouble wrapping my head around their logic. They seem to feel that an AI would automatically eliminate some essential part of the human experience by virtue of its very existence. That just seems highly inconsistent, because *all* tools remove something from the human experience. For hundreds of thousands of years, hunting and gathering was an essential part of what it meant to be human. The advent of agriculture robbed us of that experience. Penicillin robbed us of the experience of dying of bacterial infections, the domestication of horses robbed us of the experience of walking everywhere.

        I don't get it.

        But I guess that's why the bad guys are literal terrorists, huh?
        ```

        - u/Bowbreaker:
          ```
          What a powerful GAI removes is humanity's ability to believe in their own agency and primacy. The ability to be the ultimate arbiters of their own destiny. Many theists already believe that we don't have that, but they either actually only *believe* that they believe that or they think there is already a greater and more perfect intelligence doing that and that the manmade GAI is an imperfect disruption of the order of things as wanted by said higher intelligence.
          ```

    - u/Noumero:
      ```
      >'if he lets her die, he's an unfriendly AI... and now he's unstoppable' or 'he saves her, in which case he isn't an unfriendly AI... so now he's dead'

      That reminds me of medieval witch trials by drowning: if the woman doesn't drown, she is a witch and should die; but if she does drown, she... *was*... innocent.

      Quite an uncanny connection.
      ```

  - u/OrzBrain:
    ```
    >Don't forget the plot hole. . .

    I thought **spoiler** was exactly what he *did* do. Pretended that they both died, then left the humans to rot in their self-created disaster, having no further interaction with humanity beyond running and existing on the networked environmental improvement nanites. My understanding was that the virus was completely ineffective on him.

    You think the nanites could do what they were shown to be doing without an AI directing them? How would they know what to eat and what not to to improve the environment? How would they know where to make forests grow back? What would keep them from eating cities? He won by transcending his opponents so completely they didn't even know he existed afterwards.
    ```

    - u/Nighzmarquls:
      ```
      That is more or less the jist of the story. Also all the transhuman stuff he did? It was for his wife. 

      He didn't actually care, transcendence is the story of a husband who loves his wife but made a value judgement failure of what she wants and when he gets the resources to provide what he thinks she wants it all goes pear shaped.

      In other words exactly what I'd expect from  an AI trying to emulate a man as he was.

      All it was trying to do the entire time was recreate/be what he was. It just so happens the wife who created the AI / uploaded the guy had a lot of very loud and obvious transhumanist flavored technology to the rescue goals.

      So it gave her what she wanted. 

      Then when the error was finally resolved it just stopped doing that.
      ```

---

