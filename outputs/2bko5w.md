## Ra: It Has To Work

### Post:

[Link to content](http://qntm.org/work)

### Comments:

- u/Anderkent:
  ```
  Is it bad that I'm cheering for the VR people (and thus Ra) most of the time?

  I mean, sure, there's a couple billion people on the line here, but theres millions more 'frozen' in Ra's VR, and the resources these couple billion people are using could presumably host orders of magnitude more people if they were being used efficiently.
  ```

  - u/alexanderwales:
    ```
    I don't have a lot of respect for the Virtuals, considering that they've been depicted as nothing more than lotus eaters. To me, that's not an acceptable end game for humanity. That's not even to mention the fact that they were the ones to fire the first shot in the war (assuming that's true). So basically, you're siding with a section of humanity that's decided genocide was the proper way of dealing with the fact that they want to have more fun.
    ```

    - u/Nepene:
      ```
      Since the virtual humans outnumber the reality humans millions to one it's a bit like the US not having proper mental health treatment for schizophrenia. The extra deaths of 159 kinda weird people isn't a massive priority compared to the lives of 318 million. And these 159 people are taking up a quarter of the budget.

      It's sad but you can understand the morality. The ability for an extra hundred million people to be able to live is more important than 159 schizos. 

      It'd be nicer if some compromise was reached but in terms of ratios if you don't think about people with mental health issues dying as a serious issue as weighty as genocide 1/2 million humans dying isn't a huge moral concern for most humans.

      Edit. And so I feel that you can't rely on morality to dictate what should be done in these questions. You should instead ensure you have adequate weaponry and security instead. You can rely on others thinking "Killing people with no reason is bad." Not on them thinking "Killing a tiny minority for the good of the majority is bad."
      ```

    - u/Anderkent:
      ```
      Consider the source, though. The only image of Virtuals we have is from the Reals, who themselves admit they don't understand Virtuals any more.

      And the Reals are pretty much lotus eaters too, except much more wasteful. They lock down technology to avoid any kind of progress, and just sit in a static environment while watching the 'new humanity' re-do all the work, so that they can 'enjoy the *true* human experience'. That's... Probably the same thing the least productive virtuals are doing? After all maximising happiness is not about flooding yourself with drugs; every uploaded person that's focusing on that is doing art, or re-discovering physics, or other similarly fulfilling tasks.

      (and maybe most of them aren't doing real progress; though progress when the AI has 'solved' the world is difficult to define; but at worst they're the same as the reals, and the possibilities for actual productivity are greater - they could be planning to expand to other solar systems (or perhaps already have, and the reals just didn't notice), working on simulation efficiency, etc.)

      Presumably at the point where the new humanity would actually become able of doing something new, the wheel would reset them in fear of them uploading again (since uploading lets one be much more productive).

      As for being the ones to start the war, at *some* point the wastefullness of Reals must become grating. It's like... Imagine you're in a food-constrained country, and must limit your population to a constant number, while the country next to you has thousands more arable land, but they insist on using it inefficiently. You could give them the new technology, and with no impact on their quality of life allow both you and them to increase population.

      That's how I see the Reals' refusing to upload.
      ```

      - u/Empiricist_or_not:
        ```
        It's funny <I'll find the quote latter> but Banks already commented on how intelligent life eventually developed rules about Hegemonizing swarm, which these virtuals seem to be, and the disposition of matter. The rules boiled down to ~"you can't take other people's stuff"

        Besides why eat Earth when you can eat Mercury and get a head start on starlifting?
        ```

  - u/None:
    ```
    It depends heavily on what kind of society the Virtuals had in the beginning.

    My interpretation was that the Virtuals were a bit similar to the Vile Offspring from Accelerando in that you can't really be sure what's happens in that world anymore because you can't comprehend any of it. So you can't be sure how worthwhile their lives are, if any. I think it's implied that in Accelerando capitalist competition eventually makes sentient beings obsolete inside the Dyson sphere.

    Anyway, this is how Virtuals' society supposedly was:

    >The new worlds would be tuned to whatever anybody could ask for, and to live in them would be as easy or as difficult as any human wanted. Rather than conquer the universe, they would write a fiction in which they had already conquered it. Infinite fun space.

    If the rules of that VR society aren't perfectly thought out beforehand, then the fast pace of computation relative to normal life means that the rules are extrapolated to their logical conclusion and any selection effect in the original rules changes the nature of the beings very quickly. See [this](http://www.nickbostrom.com/fut/evolution.html) and [this](http://slatestarcodex.com/2014/07/13/growing-children-for-bostroms-disneyland/) about those kind of selection effects. This kind of selection effect could happen in "fun society" too, if the fun includes a lot of interaction and zero-sum games of significance (like status competition). For example it could turn out that the ultimate form of fun is to make others miserable by dominating them in games and these have to be real people because defeating pseudo-people is like loving pseudo-people who cannot love, e.g. pretty lame. So then people modify themselves to adapt to these game and so on. There could be lots of these kind of "unknowns" that hide in the system and would lead to nasty results if extrapolated to their logical conclusion. A "fun society" could optimize for many things we're not aware of and selection effect is not the only kind of development that could lead to unforeseen consequences.

    So it depends on if their society was engireered this in mind (and in you can trust whoever engireered it, I'm not sure if I could trust Ra) or if it was allowed to grow organically. There's nothing bad about society growing organically but in this case you can't be sure what the end result is. I think the Virtuals probably were sentient, but in a vastly different way than humans and I can't be sure if their lives are really worthwhile so my best bet is to root for humans.
    ```

- u/Riddle-Tom_Riddle:
  ```
  Sweet! Another update to distract me from my slight dislike of having 15+^+ slowly updating stories!
  ```

  - u/drageuth2:
    ```
    The trick is to keep on accumulating stories that update at different times until the combined update rate matches your consumption rate.
    ```

    - u/gabbalis:
      ```
      The trick is to keep a spreadsheet of all the things you read and when they update, so you don't waste time trying to figure out what it was again that updates today.

      Or go into a coma for a year. Then binge all the tasty stories... mmmm.
      ```

      - u/alexanderwales:
        ```
        I usually just do a combination of RSS feeds (via feedly) and updates that go to my inbox. With those two together, I don't need to worry about actively checking for updates - the updates come to me.
        ```

---

