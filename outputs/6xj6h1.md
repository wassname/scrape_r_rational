## [Challenge Companion] Effective Altruism

### Post:

**This is the companion to [the biweekly challenge](https://www.reddit.com/r/rational/comments/6xj599/biweekly_challenge_effective_altruism/). Post comments, recommendations, discussion, or general chit-chat below.**



### Comments:

- u/artifex0:
  ```
  So, here's a setting I've been thinking about, which might provide some inspiration:

  Suppose, in the near future, someone engineered and released virus that caused people to develop an extreme amount of empathy and compassion.  As in, so much empathy that hearing about the death of a stranger on the other side of the world would cause an emotional reaction like the death of a loved one, and hearing about a stranger giving birth would feel like having a child yourself.  If most of humanity was infected, what might happen?

  My take: in the short term, you'd see an enormous amount of chaos.  There would be a global epidemic of severe PTSD as the traumatic experiences of individuals caused global effects.  Most people might eventually learn to cope with both that and the constant mix of extreme joy and grief, especially with the entire world motivated to develop new psychological techniques and drugs. Initially, however, suicides would be a huge problem.

  On top of that, industries and maybe even entire economies would collapse as consumers would feel uncomfortable about buying unnecessary goods while other people were still starving or suffering.  Something like the economic mobilizations during WWII might occur, though focused on massive third world development projects.  In first world nations, you might start to see things like food rationing, while people in extreme poverty would see a dramatic increase in standard of living.

  A century later, the world might look like a kind of utopia- free of poverty and most kinds violence and abuse, with  a global economy slowly reapproaching pre-virus first-world standards and with huge medical research initiatives.  It might be a world where few people could endure learning about history, however, and where taking any kind of risk was severely discouraged.
  ```

  - u/LiteralHeadCannon:
    ```
    It seems to me that a few very powerful people might conclude that the suffering caused by the new empathy is the easiest problem to solve; we'd then wind up with a carefully-zoned world whose zones hear very little information about each other, which is carefully-controlled to only be positive; hospitals might fade away and become replaced with involuntary euthanasia factories and a state-mandated religion featuring a universal pleasant afterlife. And that's assuming negative utilitarianism (ie, altruistic omnicide) doesn't rear its ugly head, in which case we're all fucked.
    ```

    - u/trekie140:
      ```
      That's utterly horrifying and hits too close to home for me. When confronted with a source of traumatic information, people instinctively distance themselves from that source in order to preserve their mental stability. Unless eliminating the source of trauma is easier than killing the messenger, people will choose to cut themselves off because the costs and risks of doing anything else are higher. This has the makings of a Black Mirror episode.
      ```

- u/trekie140:
  ```
  Effective altruism is always an idea I've had trouble with implementing. As an economist, I believe the thing that would do the most good in the world is altering current behavioral incentives to encourage optimization of utilitarian humanism. However, even if you can do that, you have to contend with at least some people not knowing how, not understanding how, or simply not choosing to optimize the values you want.

  Then you're up against the basic flaws of human psychology that have always hampered progress. Not everyone has empathy for everyone else, not everyone is willing to make the same sacrifices for the good of others, and not everyone's flawed reasoning can be corrected the same way. So in the end, I concluded that the most effective mindset of an altruist is to use whatever power you personally have to help people when you have the opportunity.

  If you decide to alter human psychology so that these are no longer a problem, you then run into the problem of violating people's right to self-determination. If optimizing human well-being requires fundamentally changing what it means to be human, then I think you should reconsider your values and methods of optimizing them. One solution could be to make such alterations voluntary, though you'd have to be careful about inequality between these groups.

  So some possible scenarios that come to my mind: sell sentient robots programmed to be rationalists and good samaritans when not working, give people the option of uploading into an altruistic hive mind, or construct an AI-operated communications network dedicated to sharing information about altruistic activities that people can do. All have potential failure states, but present opportunities for good things to happen that currently aren't without directly causing harm to humans.
  ```

---

