## [D] Complexity penalties

### Post:

So over at HPMOR, and occasionally here as well, theories about plots and characters make a big deal about using complexity penalties to discard other potential explanations. I get that this is just one of several tools in the tool box, but... Doesn't it leave the average rationalist vulnerable to *deliberately* convoluted plans? There are plenty of times when the villain has enough time that they *could* do something really time consuming and seemingly unnecessary instead of doing the obvious thing, and where this wouldn't jeopardize their plans, but just cost them a little extra time/resources. What I'm getting at is when a rationlist *knows* they are fighting/investigating a rationalist, isn't it fair to assume that the other rationalist will occasionally do things in unnecessarily complicated ways just to deny their opponent the use of one of their logical tools? Or to set a trap that wouldn't have worked if they didn't do Simple Task X in a very round about way?

### Comments:

- u/None:
  ```
  [removed]
  ```

- u/Escapement:
  ```
  I think this argument would make more sense to me if you expressed it with concrete examples. As-is, I am not sure I entirely grasp what you are getting at, or in what situations your idea would apply. That said, I am going to try to address some of your ideas anyways. I may be horribly off-base here.

  Fundamentally, whatever plan has the best possibility of working, tautologically has the best possibility of working. So if choosing between plans A and B for accomplishing a goal, you would choose whichever had the greatest chance of success after assessing all the factors affecting the chance of success that you can. If you have a plan that has 5 steps each with a 99% chance of going right, against a plan with two parts each with a 95% chance of going right, the latter is obviously worse than the former. 

  However, in most circumstances the number of parts of plan has no correlation with each part's likelihood of success, so the less complex is better - 4 stages of 98% vs 3 stages of 98%, for example. 

  Also, a complexity penalty is a method of determining probable ideas, not necessarily proving anything. This has a lot to do with ideas of parsimony of explanation for events - see Somonoff induction and related ideas (I think Less Wrong had a nicely written explaination somewhere?). If you have two ideas of how something could have occurred, then the simple explanation is more likely to be the actual reason than the more complex reason.

  That said, if making plans against intelligent opposition then deliberately choosing what may otherwise be a normally suboptimal but unexpected option to defeat them is fairly common. A related concept from the world of fighting videogames is "Yomi", knowing the mind of the opponent - for example, say there are two plans, A and B, that side 1 could enact, and two counterplans, C and D that side 2 could enact. If side 1 chooses A then he wins if side 2 chooses D and loses if side 2 chooses C, and vice-versa if side 1 chooses B. Logically therefore each side has a 50% chance of victory and essentially no way to differentiate - however, if tested serially and the rewards of victory/failure are uneven somewhat, it is quite possible for a person in these circumstances to read another deeply enough to predict what their opponent is doing and respond with much greater success than random chance - much like Quirrell plays at a level deeper than Harry (in his own assessment, anyways, taking his words at face value - which may be unwise).

  Of course, in the real world there are degrees of winning and possible failure associated with each plan and it's responses, and of course multiple variations possible on each plan, and no certainties of victory or defeat due to the vagaries of chance, and etc. ideally you could attempt to quantify it all a little and come up with some sort of decision theory of what plan to pick, but in reality things rarely work out so neatly as to be readily quantifiable. 

  That said, I would appreciate it if you would clarify your argument with more concrete, less abstract examples - I don't feel the above really struck to the heart of the matter, because I am not sure what exactly you are arguing in favor of goal-directed people doing in the face of intelligent opposition, and perhaps a more concrete example could get me on the same page as you so I could better discuss this topic.
  ```

- u/Prankster42:
  ```
  The point of complexity penalties as I see it is not so much that we should disbelieve complex hypotheses, but more that we should require evidence for each moving part we postulate.

  This means that the hypothesis "Quirrel is doing something very complicated" does not get a penalty, but if you say "Quirrel is going to exploit the loophole in quidditch rules using timeturners, memorycharms and a rigged snitch for the last game of the year to make both Slytherin and Ravenclaw win the house cup" you have to prove not that he is using a complex plan, but rather that he is going to do precisely this, at precisely this time for this exact purpose.

  You can expect convoluted plans, but you can't expect that these plans are easily guessable, and so you need evidence for each part. If the above statement had read "Quirrel is going to make both Ravencalw and Slytherin win the house cup, and it is likely to involve timeturners" the burden of evidence is a lot lower, since your hypothesis has less moving parts. It means that he could do all the other stuff and more, but you aren't trying to infer the entire plan, just the bits and pieces that you have enough evidence for to make a strong prediction.
  ```

- u/None:
  ```
  Yes.  This is called Obfuscating Insanity.  EDIT: Also the Refuge In Audacity.
  ```

- u/agamemnon42:
  ```
  Yes, this is possible, but it is much less common than simply trying to achieve whatever objective they're seeking.  Hence the complexity penalty, it doesn't say that's impossible, just that it has a lower prior, so you need more evidence to believe that.  If I flip my light switch and the light goes on, it's possible that a clever bad guy has rewired my apartment to have exactly the same behavior so I won't suspect anything, but it's far more likely nothing in the wiring has changed.
  ```

- u/Suitov:
  ```
  To my very basic understanding, complexity penalties are a way to break yourself out of jumping to very complicated conclusions - a mental time-out to remind yourself to look for a simpler explanation for something you've observed.

  That is to say, it doesn't *rule out* the complicated hypothesis as being the correct one, if after you've reviewed all your options it still seems to fit your observations best.
  ```

- u/None:
  ```
  If the fact "Quirrel wants to screw with my head." is in evidence, then a lot of added complexity can be explained with that fact.
  ```

---

