## Passive

### Post:

[Link to content](https://www.smbc-comics.com/comic/passive)

### Comments:

- u/bubba3737:
  ```
  There are already people who can persuade most anybody to do terribly self-destructive things, like buying a time-share in Florida or investing their life savings in that initial coin offering. That's why not having an open mind, and instead sticking to your opinions no matter what arguments your hear is a great strategy.
  ```

  - u/iftttAcct2:
    ```
    I've always liked the expression, "keep an open mind, but not one so open that your brains fall out"
    ```

    - u/Lightwavers:
      ```
      "The trouble with having an open mind is that people will keep insisting to put things in it."
      ```

      - u/appropriate-username:
        ```
        I don't think that quite gets to the issue. I think something like "The trouble with having an open mind is that people mistake it for a garbage can" makes more sense.
        ```

  - u/raptorbarn:
    ```
    Clinging to no opinion but resolving not to update easily based on the words of people with motive to influence you also works.
    ```

  - u/SoylentRox:
    ```
    >That's why not having an open mind, and instead sticking to your opinions no matter what arguments your hear is a great strategy.

    The flaw with *that* is you can't correct any errors your thinking may have in it.

    &#x200B;

    The specific error that most adults presently alive today, but who soon will not be, are making is they trust various bullshit artists, such as the medical directors of "memory care" centers, religious priests, popular fiction - all sellers of unadulterated bullshit, even the ones licensed by the state with medical degrees.

    &#x200B;

    So even when they are diagnosed with Alzheimers/dementia and there is a clear and logical course of action - preserve their brain before all the memories are destroyed - they instead willingly let themselves rot into a vegetable and then a corpse.
    ```

    - u/None:
      ```
      The problem with brain preservation is suppose it's utterly impossible to revive a brain. Then they've just committed committed suicide. And like the person above said, many people are capable of tricking others. Say you're advocating to an elderly person to go for brain preservation. How do they know you're more trustworthy than the person trying to sell them a trust share in Florida? 

      Brain preservation is a risk. A lot of people choose to not take that risk and just stick with what they know for sure is safe, because it can be hard to know if that risk has an 80% chance of success or a 1% or a 0.000001% chance.
      ```

- u/iftttAcct2:
  ```
  I feel like this almost assumes the opposite: that a certain line of argument will persuade someone to change their views. In reality, people are stubbornly irrational about the things they think and the things they believe in.
  ```

  - u/None:
    ```
    The point I think is that the AI is capable of threading the single possible argument that would change someone's mind. Like a chess puzzle that has a single solution and takes 1000 moves to complete, no human is capable of solving it, but an advanced AI could.
    ```

    - u/GaBeRockKing:
      ```
      Yep. The one big upcoming technology I'm most interested in/scared of is superpersuaders. There won't be any radical change-- advertising techniques have been getting better and better for decades, if not centuries. But once the most powerful governments and corporations have techniques so sophisticated as to convince individuals, not just demographics, to do what they want, I fear what will become of everything from commerce to culture.
      ```

    - u/SoylentRox:
      ```
      *Maybe* .  While it makes good sci fi, present AI technology has a very key limitation.

      &#x200B;

      *You have to be able to objectively measure a correct answer*.  This has wide ranging consequences.  This means present technology is capable of solving things like the movements of a robot in a warehouse or object manipulation, even in dirty and chaotic environments.  This is because you can accurately simulate these environments and in the simulation, accurately score how well the AI's policy is doing against a heuristic for success.  This allows the AI to continue to improve, and given enough time and an accurate enough simulation, it will eventually improve to superhuman levels of performance.  (in terms of heuristic scores.  Obviously a badly designed heuristic will give you an AI that is amazingly consistent at doing a shitty job)

      &#x200B;

      Note that the simulator can use AI itself, where a different AI system is doing it's best to make the simulation better reflect the behavior observed in the real world.

      &#x200B;

      The reason such a simulator cannot yet be used to make a super-persuader is you need an accurate simulation of a human being in order to do this.  This is probably achievable, but it will take a *lot* of data.  Note that this "simulation" I am describing isn't quite what you are thinking, you wouldn't be simulating an actual human mind, just modeling the probable responses a human being will have to any line of argument you might make.
      ```

      - u/None:
        ```
        Yeah, it is fiction, I think the author wrote it as if passive-aggressive manipulation was a game of perfect information like chess where the best possible move against a grandmaster will be the same best possible move as against a novice, so the AI just needs to play against itself to improve and never needs to simulate weak opponents.
        ```

- u/Neon_Powered:
  ```
  This is like a super power...
  ```

---

