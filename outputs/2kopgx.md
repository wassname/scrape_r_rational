## [Q][BST] Seeking LWist Caricatures

### Post:

I've written the existence of a cult-like "Bayesian Conspiracy" of mostly rebellious post-apocalypse teens - and now I'm looking for individuals to populate it with. What I /want/ to do is come up with as many ways that someone who's part of the LW/HPMOR/Sequences/Yudkowsky-ite/etc memeplex could go wrong, that tend not to happen to members of the regular skeptical community. Someone who's focused on a Basilisk, someone on Pascal's Mugging, someone focused on dividing up an infinity of timelines into unequal groups...

Put another way, I've been trying to think of the various ways that people outside the memeplex see those inside it as weirdos.

(My narrative goal: For my protagonist to experience trying to be a teacher. I'd be ecstatic if I could have at least one of the cultists be able to teach her a thing or two in return, but since I've based her knowledge of the memeplex on mine, that's kind of tricky to arrange.)

I can't guarantee that I'll end up spending more than a couple of sentences on any of this - but I figure that the more ideas I have to try building with, the more likely I will.

### Comments:

- u/noggin-scratcher:
  ```
  The hypocrite: has absolutely taken to heart the idea of cognitive biases and takes great delight in pointing them out in others (using overly formal language all the while) without regard for whether it's an appropriate moment and without noticing their own enormous biases.

  The calculator: insists on multiplying together a bunch of made up numbers before making any decision, no matter how trivial. Likely while muttering quietly about their utility function.

  The "surely technology will save me": can talk at great length about existential threats to humanity and how we're morally obliged to oppose death with a convulsive effort and ought to be funding cryonics and life-extension like a new Manhattan Project, but hasn't seen fit to take any simple steps to extend their lifespan the 'regular way' through lifestyle changes involving their diet and exercise.

  The phony-physicist: is very firmly convinced that the Many-Worlds Interpretation is the only correct way to view the universe but would be utterly lost within minutes if asked to solve (or even write down) any Schrödinger Equation.

  The "obsessively consistent under reflection": spends a lot of time deliberating about how they ought to make decisions, under the assumption that all other agents sufficiently similar to them will follow the same logical process and reach the same decision. May very well still be neglecting some of the more commonplace tragic-commons situations, because other people aren't literal self-clones.
  ```

  - u/DataPacRat:
    ```
    > The hypocrite

    This is the baseline I've been keeping in mind: teens who get a kick out of being able to out-argue their parents.

    Your other four ideas are exactly the sort that I was hoping my post would evoke. :)
    ```

  - u/None:
    ```
    >Phony physicist

    This would be the one who reads every popsci article, singles out far-fetched high-level hypotheses as soon as they're proposed, and then asserts them to be obviously true – even if they contradict his previous claims.

    >Of *course* our universe is just on the edge of a black hole in the fourth dimension! Our perception of "time" is just us moving towards the center! And of course this must be compatible with the holographic universe *and* Barbour's timelessness *and* Bryanton's dimensions *and* Tegmark's multiverses *and* Smolin's fecund universes …
    ```

- u/None:
  ```
  The obsessed: Someone who, rather than being a rationalist (though they could be) is instead obsessed with the *idea* of being a rationalist, or with Yudkowsky.
  ```

  - u/None:
    ```
    I think this accurately describes all the characters in this thread.
    ```

- u/E-o_o-3:
  ```
  The Epistemist

  He (or she) spends a very large amount of time on the internet or reading books, honing his philosophical skills and understanding the nitty gritty of epistemic rationality. He understands a great many other topics as well - he's well versed in science, health, politics, social skills, and a great many other topics besides. He has the ability to perfectly articulate exactly what mistakes in thinking and action every other character is making (including himself). He sees the world clearly and is rarely horribly wrong about anything. He analyzes everything, spends hours thinking about word meanings and whether a certain bit of logic is *really* sound and which hypothesis is *truly* more parsimonious. He has boundless energy to do this, because it fascinates him.

  However, he doesn't actually have the drive to do anything practical or accomplishing anything meaningful in real life.

  (In general, I think the archetype of "genius who chronically underachieves because of some issue" - be it a mental health issue or mild personal defect, growing up in poverty, too many family responsibilities, or simply lack of desire to do things, is exceedingly common in all circles where smart people tend gather for some reason unrelated to practical networking or jobs - simply because the smart people who do accomplish things are too busy to participate.)

  You could potentially give him a happy ending by putting him on stimulant drugs or something. Or maybe he could be the teacher!
  ```

- u/alexanderwales:
  ```
  Mostly I think you'd have to have people that have other issues that are exacerbated by the memeplex.

  * The guy who only sees human suffering in the context of the wider world and fails to empathize with people's petty problems when millions of people are dying around the world
  * The guy who thinks that two people shouldn't take offense when arguing if they're trying to change their mind (I forget the name for this) and gives a lot of offense to people because he thinks they're being unreasonable by not taking his offensive comments in the spirit they're intended (and it might be that he uses his bluntness as a weapon and reasonableness is just his defense).
  ```

  - u/None:
    ```
    >The guy who thinks that two people shouldn't take offense when arguing if they're trying to change their mind

    Yees, this so much. I did this for about a month, and it's very very annoying to deal with. You're referring to the principles of "Radical Honesty" and "Crocker's rules", both of which are passed off with the excuse "People should be able to convey information optimally to help others make rational decisions, without worrying about offending anybody!" [It can have some pretty ~~disastrous~~ ~~hilarious~~ interesting consequences.](http://www.esquire.com/features/honesty0707)
    ```

    - u/ArmokGoB:
      ```
      Also included: not acknowledging the fact crockers rules are explicitly opt-in.
      ```

- u/None:
  ```
  The typical SSC reader, who has gone so many levels of "meta" up in their reasoning and meta-reasoning that they now place no epistemic trust in anything whatsoever, considering all thought to be inherently tribal-political.  In Bayesian terms (well, actually, Jaynesian terms), their subjective distribution assigns almost all of its mass to various levels of "deception" and "cognitive bias" hypotheses, and almost none to actual beliefs.  When questioned, they mutter something about Loeb's Theorem and try to flee.

  Oh, and then, of course, the typical Robin Hansonian, who believes that *absolutely everything* is done just to get wealth and status, and whose plan is to take over the world by mind-uploading and then fork-bombing.
  ```

- u/Charlie___:
  ```
  The brand-namer. "Rational cooking. Rational training. Rational babies. So many babies. 400 babies."

  The self-helper. "I've been working on implementing this sock-folding system I read on a blog." (this caricature is a bit more unfair than the others, but there are plenty of bad habits plausibly associated with consuming lots of self-help advice)

  The casual insight junkie. "I don't see how this could be false."
  ```

  - u/CantorsDuster:
    ```
    Rational babies.  107633/7 babies.
    ```

- u/Vermora:
  ```
  I can't think of any way that someone could follow ALL of the rules of good, logical reasoning and rational thinking, and still make these kind of mistakes. It seems almost paradoxical. The only ideas I can come up with involve taking one aspect of rationality too far, to a fault, while ignoring some others. And I'm sure that is covered in the Sequences somewhere. (If it wasn't, once it was noticed that this over-specialization was occurring, "do not focus too much of one aspect of rationality at the expense of others" would simply be added to the scripture).

  Assuming the memeplex taught real Bayesian/rational thinking/etc, and not phony stuff, any instances of flawed logic or irrational thinking would be noticed, isolated and corrected. Every time I think of how it could fail, I think of an article in the Sequences on Less Wrong that takes that possibility into account.

  Having said that, you could have people who focus too much on developing their rational mind and eliminating their biases, to the expense of other skills they need to survive. Or be a master of hypotheticals but unable to apply their skill, or fail to notice when their hypothetical scenarios occur in the real world (possibly related to the void, from the twelve virtues).

  Or simple human weakness: even if somebody tries to avoid all of the cognitive biases at once, they'll probably slip up at some point. We aren't robots.
  ```

  - u/DataPacRat:
    ```
    > I can't think of any way that someone could follow ALL of the rules of good, logical reasoning and rational thinking, and still make these kind of mistakes.

    If it helps, I'm thinking of the [Valley of bad rationality](http://wiki.lesswrong.com/wiki/Valley_of_bad_rationality), the idea that some of the initial stages of learning about reasoning can leave you worse off than before you started.

    As an alternative approach, the cultists aren't necessarily /real/ rationalists, they're just the gang of kids who would have snuck into the occult section at their local library to find spells to try to cast, but got caught up in an alternative source of hidden knowledge to Have A Secret About instead. Possibly in the form of some surviving listicles, instead of the full Sequences.
    ```

    - u/noggin-scratcher:
      ```
      Hm, if we're "allowed" to suggest ideas for characters who have picked up the wrong end of the stick and applied the LW tropes badly... that may create some extra latitude.

      I'm thinking of the kinds of mistakes that EY describes his younger self making in pursuit of being "rational" like moving awkwardly and robotically because he thought that ought to be more efficient. 

      Or the other pseudorationalist failure-mode that can be concisely referred to as "Spock"; eliminating emotion in favour of logic (ignoring the perfectly real motivating forces of emotion) and expressing things as percentages with far more decimal places than you could possibly have real confidence in. If we assume that the particular post warning against that failure-mode was lost to the ages.
      ```

      - u/None:
        ```
        >moving awkwardly and robotically because he thought that ought to be more efficient.

        Oh wow that's bad
        ```

        - u/EliezerYudkowsky:
          ```
          ...for five seconds before I noticed it didn't work, and then I stopped.  It's not like I was doing this for an hour, let alone six months.
          ```

          - u/None:
            ```
            Oh I know, just the principle of it. Rest assured, I didn't mean it as a personally.
            ```

- u/traverseda:
  ```
  >Another problem of LessWrong, is that its isolationism represents a self-made problem (unlike demographics). Despite intense philosophical speculation, the users tend towards a proud contempt of mainstream and ancient philosophy[36] and this then leads to them having to re-invent the wheel. When this tendency is coupled with the metaphors and parables that are central to LessWrong's attraction it explains why they invent new terms for already existing concepts.[37] The compatibilism position on free will/determinism is called "requiredism"[38] on LessWrong, for example, and the continuum fallacy is relabeled "the fallacy of gray." The end result is a Seinfeldesque series of superfluous neologisms.


  http://rationalwiki.org/wiki/LessWrong#Criticism
  ```

  - u/DataPacRat:
    ```
    I'm, shall we say, generally a little leery of relying on RW's editorial processes. However, for an outsider's negative perspective, it might be vaguely usable.
    ```

- u/EliezerYudkowsky:
  ```
  I question whatever authorial process led you to ask this question.  I expect the results to be horrible reading.  If you don't know real people who've made mistakes, caricatures you construct of Mistaken People are not going to end up as believable characters.  I question your story purpose, and wonder if you're trying to do Display of Independence a la

  > It's like going to a library, and when you walk in the doors, everyone looks at you, staring.  Then you walk over to a certain row of bookcases—say, you're looking for books on writing—and at once several others, walking with stiff, exaggerated movements, select a different stack to read in.  When you reach the bookshelves for Dewey decimal 808, there are several other people present, taking quick glances out of the corner of their eye while pretending not to look at you.  You take out a copy of The Poem's Heartbeat: A Manual of Prosody.

  > At once one of the others present reaches toward a different bookcase and proclaims, "I'm not reading The Poem's Heartbeat!  In fact, I'm not reading anything about poetry!  I'm reading The Elements of Style, which is much more widely recommended by many mainstream writers."  Another steps in your direction and nonchalantly takes out a second copy of The Poem's Heartbeat, saying, "I'm not reading this book just because you're reading it, you know; I think it's a genuinely good book, myself."
  ```

  - u/DataPacRat:
    ```
    > I question whatever authorial process led you to ask this question.

    My response is going to be a spoiler for anyone reading the story as it's written, but I don't want to make EY have to go through ROT13ing to read my reply:

    .

    .

    .

    My protagonist's mysterious enemy is actively-but-subtly trying to sabotage the rationality group, and I wanted a baseline selection of believable errors (as compared to unbelievable ones), so I could try to work out how many clues it would take for my protagonist to realize that such interference is going on.
    ```

    - u/EliezerYudkowsky:
      ```
      Then I very strongly recommend errors that you remember your own past self actually making, or finding very tempting; or at second-best errors that you have personally *seen*, not heard someone talking about someone else allegedly making.  'Errors' imagined by someone who holds the error-maker in contempt do not realistic characters make.
      ```

      - u/None:
        ```
        ...So how much time have you spent around blood purists, anyway?
        ```

        - u/ArmokGoB:
          ```
          That's just a find-replace of racism.
          ```

          - u/None:
            ```
            Not *yet*.  They need to invent "neoreaction" first, to explain how their entire societal structure is actually a perversion designed to destroy their blood-purity so that Dementors can Kiss them all.
            ```

---

