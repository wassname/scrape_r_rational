## [D] Monday General Rationality Thread

### Post:

Welcome to the Monday thread on general rationality topics!  Do you really want to talk about something non-fictional, related to the real world?  Have you:

* Seen something interesting on /r/science?
* Found a new way to get your shit even-more together?
* Figured out how to become immortal?
* Constructed artificial general intelligence?
* Read a neat nonfiction book?
* Munchkined your way into total control of your D&D campaign?


### Comments:

- u/chthonicSceptre:
  ```
  In a 5e session I was running a few months ago, my players were looking after a young girl who was about to become a hag. Hags reproduce by eating babies and subsequently giving birth to seemingly-normal girls who suddenly become hags when they turn 13. The girl was understandably upset by this and asked the heroes to kill her, for the greater good, when they avoided the whole moral quandary using an item I gave them without thinking about it.

  But what's the ethically correct solution? What about for mind flayers? Without an elder brain they're peaceable, except they have to eat one sentient brain per day. Killing fiends on the material plane is straightforward since it sends them back to whatever hell they came from, but goblins automatically go to a shitty afterlife if they die in battle (hence why they're cowards). There are a surprising amount of monsters who are evil as a terminal goal; is it morally acceptable to just end them? What about Changing Their Minds via magic (I think it's possible in 5e RAW, without homebrew).

  Heck, my players spent a small fortune on the potion they were using on the kid, should they have spent it on something more efficient?
  ```

  - u/OutOfNiceUsernames:
    ```
    >[a young girl who was about to become a hag](http://d20.sabotender.com/5th/Source/DnD%205e%20Monsters%20Manual.pdf) [...] my players spent a small fortune on the potion they were using on the kid, should they have spent it on something more efficient? 

    approach a: It is their money, they are free to do with it whatever they want (no social responsibility \ chaotic neutral).

    approach b: Having to walk through that particular quest makes them emphasize with that specific creature\girl more. So if the group as a whole highly values personal interactions, experiences and connections, it will be more valuable to them to spend large amounts of money just to improve that single creature’s life (similar real life examples: personal patronages, nepotism).

    approach c: If the players (or their characters) have such personal history that it makes them empathize with this girl’s problem more, they will value helping her more.

    approach d: If the group as a whole is able to step back and think on a more abstract level, it could end up being more valuable to them to spent the same amount of money to improve lives of as many more creatures similar to that little girl as possible (real life example: Bill Gates’ philanthropy projects).

    approach e: The group members analyse themselves, the feelings and instincts that are forcing them into the personalities they have, and based on those decide which choice would make them the happiest later on — often despite their “will” or perceived “preferences”. For instance, if the players’ characters were a group of stage-two hags, wouldn’t they see forcing the girl into her own stage-two transformation as the “right” thing to do?

    approach f: If the girl is an orphan, with no one else existing who would be caring about her, they can quickly and suddenly kill her in a manner that will cause her minimal to no distress. (real life example: parents killing their children before killing themselves)

    approach g: Approach f would mean that they would be taking her choice away from her, so they will ask her instead what she wants (“The girl ... asked the heroes to kill her”) and only then kill her (real life example: legalized euthanasia, to some degree). This approach would be conflicting with the “minors can’t give informed consent” viewpoint though.

    approach h: The players (or their characters) choose whichever flavour of morality has been enforced on them by their country, state, and surroundings to be perceived as the default, the common-sense one.

    approach i: The heroes consider and try to predict which choice will make it more likely for them in the future to be interacting with people they find enjoyable more (similar example: RPG systems with karma and fractions, where the player gets variable reactions based on the choices he makes) and to be in situations they find enjoyable more (e.g. legal punishment).

    approach j: The heroes consider and try to predict how the girl’s society as a whole will change 1) based on their choice 2) based on other people’s choices in similar situations. Then from all available decisions they pick the one that, in their opinion, will change the society as a whole to the best degree, and also try to advertise that choice to others.

    approach k: a mix of all the above, with different weights assigned to each.

    approach l(?): a mix of all the above, with different weights assigned to each.

    ---

    The problem for me is that usually when someone uses the words “morality” and “ethics”, I have no idea what they really mean by those — one of the viewpoints listed above, perhaps, or something else, etc.

    Also, as a counter-question, if someone has any other approaches or viewpoints that I failed to list above, please share them as well.
    ```

    - u/chthonicSceptre:
      ```
      Mate my players were one step away from being murderhobos, this analytical depth is beyond them. They're all neutral at least, since your actions in life are reflected in your afterlife they're only really compelled go intervene when someone's mucking with souls. They, being the avatars of my friends just wanted to have fun.

      I was more curious what this sub thought about Always Chaotic Evil.
      ```

- u/None:
  ```
  Has anyone else's sense of normality just gone and totally broken?  Like, if you had asked me five years ago what I actually expected to happen and what constituted "the world is working according to understandable principles", I couldn't have told you most anything about today.

  The only things I've managed to get right were that austerity capitalism would continue indefinitely and that global warming will kill us all.  Even so, both of these deny normality: most of the time, people are trying *not* to suffer or die.
  ```

  - u/traverseda:
    ```
    >1. Anything that is in the world when you’re born is normal and ordinary and is just a natural part of the way the world works.

    >2. Anything that's invented between when you’re fifteen and thirty-five is new and exciting and revolutionary and you can probably get a career in it.

    >3. Anything invented after you're thirty-five is against the natural order of things.

    > ~Douglas Adams

    I mean, maybe that's just a normal thing humans do?
    ```

    - u/None:
      ```
      I guess I don't so much mind that new things are invented.  I mind that many of the new things that happened, more-or-less happened because someone just *made them up* rather than because they were built into the way the world works.  It feels like a "dream gap": some people can just dream stuff into being (like, apparently, for instance, half the political far-right), while other people have to follow the rational order of the world.  I definitely feel that I belong to the latter group.

      It sometimes begins to seem as though, should godawful but privileged people decide the clouds ought to be made of cotton candy, quite suddenly, they'll discover a cheap and convenient engineering technique by which *clouds actually become cotton candy*.  Then somehow, to boot, the water cycle is not fucked -- despite one portion of it being made of sugar fibers rather than water.
      ```

      - u/CCC_037:
        ```
        [](/discordjazzhands) Oh, but where's the fun in making *sense*?

        [](/sp)

        > It sometimes begins to seem as though, should godawful but privileged people decide the clouds ought to be made of cotton candy, quite suddenly, they'll discover a cheap and convenient engineering technique by which clouds *actually become cotton candy*.

        I can't really see this as a negative. This is, if anything, a sign that those people are being very intelligent and finding ways to solve problems. They are saying, in effect, "this is how I wish the world to be" and then they are *successfully making it happen*. Is this not the very definition of technological progress? Not only that, but they're doing this without messing with the metaphorical water cycle - so they're implementing their technologies in a comparatively non-disruptive manner.

        I'm not quite sure what your analogy is referring to, and I might well take issue with the goals that are being served here once I know what they are - but your analogy is already suggesting that those goals *are* being sensibly served, and that *is* a thing to be encouraged, in my view.
        ```

        - u/None:
          ```
          What feels shocking and problematic to me is that intelligence and technological knowledge are supposed to be, so to speak, equal opportunity.  If *you* know how to replicate feats of a minor god of chaos (I *knew* that was coming from somewhere!), I should be able to read the patent, so to speak, and replicate everything myself.

          Instead it now often feels as if somehow some people have access to reality-breaking knowledge, but when you read it, it goes dead on the page.  I can't run a sleazy blog and meme my way into high office.  For that matter, I can't get game-breaking results and a gajillion dollar company in London (aka DeepMind) off a technology that even I admit nobody truly understands (neural networks).

          Admittedly, that latter one looks *more* replicable and has a clearer path open, but it's not actually in line with what I want very precisely.  I might use it if nothing else comes through :-/.

          Overall, though, it sometimes seems like the *real* magic is *privilege*.  Even protexia (connections) is easier to replicate.
          ```

          - u/CCC_037:
            ```
            > If *you* know how to replicate feats of a minor god of chaos

            Only a few of them, and only in a severely limited way.

            (Lucid dreaming covers most of it).

            > I should be able to read the patent, so to speak, and replicate everything myself.

            If you can get *hold* of the metaphorical patent, yes.

            David Copperfield (stage magician and illusionist) once made the Statue of Liberty vanish on live television. He walked *through* the Great Wall of China. (You can probably see both of these feats by looking through old recorded footage). Of course, he didn't publish his patents on these feats; but just because you saw what it *looked* like does not mean that you saw the patent.

            Similarly, "running a sleazy blog and memeing your way into high office" isn't the full story. There's no doubt a *lot* in that story that is not visible to public view. (Just because I don't know the specifics either, doesn't mean that they don't exist). And you don't have to understand a technology to use it (as proven to tech support personnel every day).

            > Overall, though, it sometimes seems like the *real* magic is *privilege*. Even protexia (connections) is easier to replicate.

            Con men and Bavarian Fire Drills have been taking advantage of this for centuries now. (The real magic isn't privilege. The real magic is *convincing other people* that you have authority over them, at least temporarily. It's not the actual superiority, it's thw air of superiority)
            ```

          - u/traverseda:
            ```
            I've given this a bit more thought.

            >often feels as if somehow some people have access to reality-breaking knowledge

            Imagine you saw someone win the lottery, and you didn't know how lotteries worked. It would also seem like they have access to reality breaking knowledge.

            Systemized winning is no match for getting lucky once, right now.
            ```

- u/callmebrotherg:
  ```
  I have bipolar-II, and the downswings been kicking my ass lately. As of a couple of weeks ago, I've started writing down anything that seems to be helping me with that, because it turns out that it's a lot easier to just reference a sheet and start going down the list, than to try to redesign or remember a winning strategy at a time that I'd really just like to curl up and die. 

  I know that a few other people here have depression, so maybe this'll help someone else too.
  ```

  - u/ProudTurtle:
    ```
    My wife has depression and anxiety as well as ADHD. She has coped for years until she got meningitis last year and now she seems to have lost the critical edge that let her cope with a pretty messy brain stew. I've been wearing myself out trying to keep everything together and stay sane myself while homeschooling a 9 year-old and enjoying a 3 year-old. Recently I realized that I can use Trello project management software to help manage the family and her treatment. It has been working well so far. We just use the free version and set up boards for things like household work and recreation.
    ```

- u/SevereCircle:
  ```
  I have an intuition that hypothesis complexity penalties should apply to the laws of physics but only weakly to the initial configuration of the universe. I find this intuition suspicious. Thoughts?
  ```

  - u/somerandomguy2008:
    ```
    I mean, complexity penalties are just a probability thing. If you break one hypothesis down into four propositions, each of which you're 70% sure is true, and another into three statements, each of which you're also 70% sure is true, the first hypothesis will be less likely to be true. "Complexity" is a little vague and hard to measure at this kind of specificity, but it's a hand-wavy attempt to encapsulate the same idea. If there are ten different parts to your hypothesis, I'm going to give it a complexity penalty because even if you're 90% sure of each part individually, it's still unlikely to be true as a whole.

    I see no reason to think that this kind of probabilistic reasoning would break down when confronted with the initial configuration of the universe. As long as the penalty applied is proportionate to the complexity of the hypothesis, the math is still going to check out.
    ```

    - u/SevereCircle:
      ```
      I thought it had more to do with Kolmogorov complexity.
      ```

      - u/somerandomguy2008:
        ```
        Kolmogorov complexity is related. [Minimum message length](https://en.wikipedia.org/wiki/Minimum_message_length), in particular, is an attempt to formalize the concept of complexity. I said is was hard to measure complexity and minimum message length doesn't really change that (writing programs that simulate all relevant aspects of the universe is hard) but it at least states how you could, in principle, distinguish between the complexities of competing hypotheses.

        You'll notice that it's still fundamentally probabilistic though. It's not competing with the probabilistic analysis I gave, it's just more Bayesian and more concrete about where the probabilities are actually coming from.
        ```

      - u/None:
        ```
        Kolmogorov complexity sort of asks, "What's the minimum number of yes-or-no propositions I can break this hypothesis into, by writing the smallest computer program equivalent to the hypothesis?"
        ```

  - u/eternal-potato:
    ```
    Seems reasonable. Unlike all subsequent configurations, the initial one does not have to be generatable from previous one via repeated application of some 'simple' transformation laws.
    ```

  - u/MrCogmor:
    ```
    Wouldn't the laws of physics be part of the initial configuration of the universe?
    ```

- u/None:
  ```
  [deleted]
  ```

---

