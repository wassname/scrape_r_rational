## [D][MK(?)] Reddit and simulated sentience

### Post:

There's a short story, whose name I have forgotten, where a catholic priest baptizes an insane, weakly godlike AI. Because, paraphrasing from the story in question, if fetuses and convicted murderers have souls and a right to life, then so do AI. The idea that personhood and intelligence aren't tied to any particular substrate isn't particularly controversial on /r/rational so I won't belabor the point. But another of that short story's plot conceits was that sentience was a property of not just individuals, but organizations; that a corporation, or a religion, or a social network could be the substrate for a rudimentary meta-intelligence.

This shouldn't be particularly controversial either. In three images, I can describe a [register](http://cpuville.com/Educational/Registers.html) using NAND gates:

http://cpuville.com/Educational/images/register_2.jpg  
http://cpuville.com/Educational/images/register_3.jpg  
http://cpuville.com/Educational/images/register_4.jpg  

Anyone who perfectly simulates this register in their mind is an intelligence that also wholly contains an separate, independent intelligence that "thinks" independently of the mind (that is, the substrate) it runs on, except for those stimuli which that mind chooses to apply to it.

If you go one step further and supply those stimuli based on stimuli external to your own mind (for example, by simulating the register on a sequence of randomly generated pairs of ones and zeros), then this primitive sentience is essentially completely untethered from your mind. Indeed, if you add a notebook and pen, you can simulate an entire turing machine. Given enough time, paper, and ink, you can simulate another entire person; your mind, your paper, and your writing implement in theory could form what I'd call a "metasapient"\* intelligence. But given that simulating a person with pen and paper would probably last until well past the heat death of the universe, let's go one step down and talk about "metasentience" instead.

Let's imagine we have a reddit user who hangs out on slate star codex, and immediately posts any new blogs from Scott alexander onto /r/slatestarcodex. This user transmits an idea as a "wire" in a logic diagram-- recieves 0 or 1, outputs 0 or 1. Then we have another user, rather more contrary who takes anything he sees on /r/slatestarcodex and reposts it to /r/sneerclub with a disparaging headline, thus displaying the inverse of the opinion. This user transmits ideas as a "NOT" gate in a logic diagram-- receives 0 or 1, outputs 1 or 0. From this extremely reductionist example, it's possible to see how reddit itself can host an extremely simple metasentience.

But reddit is a site with millions of daily users. A single contrived example simulation of a NOT gate isn't the most complex reddit gets. What's the most complex "intelligence" you can argue reddit simulating? Defining information that can be clearly placed into a state or state gradient (for example, "agreement/disagreement with a statement"), what's the most complex simulation you can describe reddit as performing? Can you describe an AND gate? A NAND gate? A register? A collection or registers?

\*I am under absolutely no illusions that I am the first person to think about this kind of thing. I offer the terms "metasentience" and "metasapience" not as coined terms to describe interesting new phenomena, but as a lazy man's attempt to avoid having to look at any published literature for the terms they use instead.

edit: the short story is [Vitalics](http://www.miraclejones.com/cream/vitalics.html) as provided by /u/Badewell

### Comments:

- u/Badewell:
  ```
  Don't have much to add to this, but...

  >There's a short story, whose name I have forgotten, where a catholic priest baptizes an insane, weakly godlike AI.

  [Vitalics](http://www.miraclejones.com/cream/vitalics.html) by Miracle Jones.
  ```

  - u/miraclej0nes:
    ```
    Hey, if you liked that one, I wrote an entire short story collection a few years ago that is a "discontinuous narrative" about an AI slowly becoming sentient enough to write narrative, specifically Hollywood movies.

     [http://www.miraclejones.com/tomorrowland.html](http://www.miraclejones.com/tomorrowland.html)   


    One of the things that I think is novel in this conceit is that I draw the distinction between "temporary" and "permanent" AI, which I think will become more important as we move forward and need problems solved but don't want to leave a trace.
    ```

- u/None:
  ```
  [deleted]
  ```

  - u/GaBeRockKing:
    ```
    >Once, when I was wondering what life after death would be like,...So what's the point?

    You might be interested in the idea of the [Boltzmann brain](https://en.wikipedia.org/wiki/Boltzmann_brain). What I'm talking about differs because metaintelligences, as I've defined them, can be pointed out and understood (or at least, that's what I'm trying to do in this thread) by ordinary intelligences. I've constructed the definition of metaintelligences so they're guaranteed to exist, so whether or not they exist isn't a disprovable hypothesis. Instead, this thread is an experiment to see if they can be useful, even if only in a theoretical, [galactic algorithm](https://en.wikipedia.org/wiki/Galactic_algorithm) sense.

    >Also I though just occured to me. Right now You (if you decide to comment of this) and Me are interacting on the internet. Does each pair of interaction from it's own metasentience? In that case is their a metasentience for every possible user interaction on reddit that is separate from the whole.

    So as per the previous paragraph, yes and no. I can frame pretty much anything involving 2+ intelligences as a metaintelligence, but at least from this conversation, there's nothing I can point out as being a well-defined metaintelligence. I guess I could say that us, plus anyone willing to downvote/upvote this pair of posts, serve as a metaintelligence for coming up with a estimate of how likely my OP is true, but that's not really generalizable.

    >This is kinda how I feel about your idea. Unless there is some mechanism by which a metasentience is differentiable from just a bunch of regular sentiences interacting in the physical world then it wouldn't matter. I wouldn't care if the reddit sentience were to cease outside of the emotions I would feel about a website I use going down.

    Metaintelligences are differentiable from their substrate because they affect and are affected by the outside world. I could use a sentiment analysis program to find out how common people acting like the "NOT" gates in the OP are, and that would give me information about how much reddit's karma system rewards contrarians.

    Here's an example about how a metaintelligence could be useful. A program can post an article on a website as an ad to a user, without making it available outside that link, where that article represents a 0 if it's meant to be transmitted as-is by the first user, or 1 if it's meant to be disagreed with. (In reality, it would likely represent some value on a gradient, but I'm keeping things simple.) That first user then performs a transformation. 0 is fail to transmit the article, 1 is transmit the article with disagreement, 2 is transmitting the article (with implicit or explicit agrement) . That is to say, the first user has a function a->f ^2 (a) \*: A={0,1} -> B^1 ={0,1,2}.

    Another user sees the post (if it exists) on the user's page and decides whether to repost it. Other users, in turn, do their own transformations, as user N performs transformation b->f^N (b):B^N-1 -> B^N.

    For any given chain of N users, a metaintelligence has performed a linear transformation from A to B^N . What transformation did this metaintelligence do? Well, that depends on the chain of users selected. You can select a metaintelligence that finds the echo chambers user 1 belongs to by feeding in a bunch of 0 articles and selecting the chains that result in 2s, or a metaintelligence that determines which articles that cause arguments by feeding in articles and choosing the chains that either go 0->... or 1->1->1->1->... because those are the chains where articles are either boring or controversial.

    With the examples above, metaintelligences can come up with novel, useful information with the participation but without the awareness of the substrate they run on. Sort of like parasitic memes, really, where they leech brainpower to propagate themselves

    Of course, any of the examples I've given so far can be thought of in other ways; there's plenty of work done in the fields social science, economics, psychology, and marketing to determine how to best exploit the  users of a platform or members of an organization. The reason why I'm insisting on viewing this from the perspective of "metaintelligence" is because ~~it's an interesting thought experiment I had to distract from a boring day of work~~ recontextualizing things this way lets us look at group behavior in a kind of [Asimovian](https://en.wikipedia.org/wiki/Foundation_series) lens, as it exploits the predictability of human beings in aggregate, as opposed to individual unpredictability.

    \*I'm using superscripts because as far as I know markdown won't let me do subscripts.
    ```

- u/ArgentStonecutter:
  ```
  > But another of that short story's plot conceits was that sentience was a property of not just individuals, but organizations; that a corporation, or a religion, or a social network could be the substrate for a rudimentary meta-intelligence.

  This is kind of conventional wisdom these days. For example:

  http://www.antipope.org/charlie/blog-static/2018/01/dude-you-broke-the-future.html

  Also, you seem to have independently invented Searle's "Chinese Room". Except Searle didn't really take it seriously and was just trying to provide a negative proof.
  ```

  - u/GaBeRockKing:
    ```
    As I said, nothing I'm saying is new or controversial to /r/rational; the short story is at least a decade old too. Though this isn't really the same thing as a chinese room; the point of that though experiment was to think of something that appeared sapient but in actuality wasn't. Using the terminology I made up for this post, a chinese room would be a metasapient running on the substrate of the room, the interpreter, and all the people who thought of how a sapient would self-consistently respond to any given query.
    ```

    - u/Putnam3145:
      ```
      There's no compelling reason even in the original are you in the Chinese room ought not be sapient. It's essentially a philosophical zombie argument.
      ```

- u/WalterTFD:
  ```
  I think you might have hold of the wrong end of the stick here, in terms of reddit bots that simulate simple gates being intelligent.

  Like, nobody here is trying to argue for souls, yeah?  You are free to do whatever you want, not free to want whatever you want, deterministic universe, etc.  Calling a brain in a human body a 'person' is a useful social illusion, not a cutting of reality along the joints sort of deal.  People are part of physics, same as their chairs, exactly equally free of causality.  


  The point, then, of the label of 'personhood' is its utility to our polity, not what it describes.  To call a Reddit bot a 'person' isn't to say anything about its nature, it is a useful handle for a bunch of other things.  Like, can you be friends with it?  Should it be allowed to vote?  These are examples of the kinds of questions that 'personhood' is salient to.  


  Whether a skull with a Chinese room inside it is useful to call a Chinese person is down to how it acts, not what shows up when you x-ray it.  Bots don't fail because they are bots, they fail because of the social considerations of them not failing.  


  Whenever AI passes a hurdle a new hurdle gets put down further along.  This isn't because there is some distinct degree of usefulness that an AI needs to pass to 'be a person', it is because AI being a person seems like it would have bad consequences, so we move the goalposts.  It is a motivated judgement.  The real "tell me what my AI needs to do to be considered AI" is something like 'vote without deception under its own identity', or some other test that is equally recursive.
  ```

  - u/GaBeRockKing:
    ```
    I'm not really disagreeing with you; I'm a fan of /u/DataPacRat's "Trader's definition" of personhood from this blog: http://blog.datapacrat.com/2013/05/page/2/ (warning:furry transhumanism). That is, that a person is anything it's useful to treat as a person. But even by that definition, or perhaps especially by that definition, personhood is applicable to metaintelligances that arise as emergent properties of organizations, since what I'm trying to determine if we can describe and therefore locate metaintelligences that could perform useful computational work. At this point I'm just trying to find a NAND gate as a thought experiment, but maybe the social networks of the future will be complex enough to allow for commensurately complex metaintelligences.
    ```

---

