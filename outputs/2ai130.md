## [Discussion] /r/rational has a lot of clever people. Let's solve some problems.

### Post:

Anyone have any problems they want to discuss?

---

I'd like to say discuss the problem space in full before proposing solutions, but in this format that's kind of hard.

### Comments:

- u/traverseda:
  ```
  I have a problem with capitalism in general.

  It's kind of a stupid optimization processes. But it does work, generally. Just replacing it with something else entirely isn't likely to work, if only because whatever we'd replace it with would need to be *complicated*. And have rules for updating the rules and all that built in. And also generally out-compete capitalism, which is hard if you don't have some way of enforcing cooperation.

  My biggest complaint with capitalism is that it's optimizing (poorly, all things considered) towards a damn stupid utility function. That is, profit of a single business entity. Not profit of a society of a whole.

  It's captured value vs created value. In capitalism, it doesn't matter how much value you create across your entire society. Just how much value you manage to capture. That leads to a lot of entities choosing, let's say, 2 private utilitons (units of utility) and 1 public utiliton, instead of choosing 1 private and 3 public. Sure, there's more overall utility in situation two, but there are selection pressure's to consider.

  The most relevant examples of captured vs created value are probably health care and student loans. An educated populace increases utility across society as a whole, but universities have know way of capturing any of the value they create. We use student loans as a sort of shim, but it still completely decouples value creation from receiving value. Instead favoring schools that can attract large numbers of students and operate cheaply.

  So what approaches might we take to solving that? Either changing capitalisms utility function or figuring out alternative ways to run (scale models of) a society?
  ```

  - u/None:
    ```
    YOU.  I *like* you.

    >My biggest complaint with capitalism is that it's optimizing (poorly, all things considered) towards a damn stupid utility function. That is, profit of a single business entity. Not profit of a society of a whole.

    Capital/money is optimization power, stored in liquid form.  This makes it pretty easy to explain what the hell is actually going on when we say someone is "poor" or "rich", *especially* when we remember that people can only optimize in limited ways and at limited rates via singular, personal effort.  Capitalism just maximizes capital, but... *yeah*.  Bloody stupid utility function.

    Personally, my favored solutions are [syndicalism/cooperatives](http://en.wikipedia.org/wiki/Worker_cooperative), [guaranteed basic incomes](http://en.wikipedia.org/wiki/Basic_income), and several forms of [Georgism](http://en.wikipedia.org/wiki/Georgism).  I also like the idea for  [socialized capital markets](https://www.jacobinmag.com/2012/12/the-red-and-the-black/), but think it needs a bunch more work to get it beyond "Just socialize the institutional investors", since you want a system that can direct investment by well-informed individuals to social purposes just as well as it directs mass investment by professional financial managers to such purposes.

    What can be said, to those who read the links, is that each of these "reforms": is actually a major change in class relations, can be executed (hypothetically) through ordinary and nonviolent politics, and *has actually been tried and found to succeed in experiments*.

    If /u/mylittleeconomy could come over here, being a market monetarist, I'd also like to propose a kind of "Georgist money", in which currency is issued as a liability/entitlement to some form of positional or ecological (ie: Truly Scarce, cannot be made in a factory) good.

    I expect that any and all of these changes, made individually or together, would make the world a much better place, and, notably, a much safer place for other things rationalists like, such as transhumanism.  I actually feel that [Bostrom's response](http://www.nickbostrom.com/papers/dangerous.html) to [Fukuyama's critique of transhumanism as inegalitarian](http://www.foreignpolicy.com/articles/2004/09/01/transhumanism) was inadequate, and failed to address the genuine crisis of stratification that I personally expect to occur should transhumanism be wed to capitalist exploitation (or rather, the capitalist mechanism of exploitation in the absence of AI).  Yes, biological-limitation transhumanism + way capitalism makes even the barest survival and barest happiness a positional good = vast human misery.  Rather than addressing that problem by attacking transhumanism, we should address it by treating capitalism as a broken, obsolete economic machine and simply building a better one.

    (All this assumes that we cannot produce a Friendly AI *Real Soon Now*, as in, soon enough to deal with the problems inflicted by capitalism on most currently-existing humans.  There is enough human effort in the world to fix our economic system *and* build a Friendly AI in the coming decades, at least in my view.)
    ```

    - u/traverseda:
      ```
      As an aside, I thought [this](http://c4ss.org/content/12491) article was an alright overview of the problem space of "power, and how to topple it" in a lot of ways. I don't know where to post it, but it mirrors my general strategy in a lot of ways. Especially

      >1. Identify the vulnerabilities: Fragility, overconcentration, ignorance, arrogance, lack of diversity, centralization, lack of redundancy, popular disgust, anxiety, dissatisfaction or apprehension, ill-preparedness, lack of agility, overcomplexity (left hand doesn’t know what the right is doing), lack of imagination and creativity, etc.

      >2. Acquire resources stealthily: Put together what you need without letting your target know you’re doing so, or even what you are capable of doing with them.

      >3. Develop solutions that exploit the vulnerabilities.

      >4. Rigorously assess the likelihood of those solutions working effectively (incapacitating the incumbent power), and deploy only the high-probability solutions, quickly, before the incumbents have time to react and defend themselves.


      Firstly, I'm trying to capture some of the utility of the quickly growing 3D printing market. Then expand the market into just-in-time/decentralized manufacturing. Something everyone is trying to do, just stupidly.

      ---

      I'm firmly in the camp of "AI is probably too dangerous, friendly or not. Do it that hard way and uplift existing humans.". But there's some many existential risks coming to a head at once that it may be our best bet, even if the odds aren't good.

      Better then that would be a sane organization taking control, and initiating a slow singularity along with measures to deal with radicals and extremists. Mostly good psychiatric care, plenty or opportunities to kill/wire-head yourself, and generally keeping everyone happy.

      Basic income was on my list, but I forgot it add it. It's also good for reducing existential risk. People who are content are a lot less likely to be extremist/blow-up-everything.
      ```

      - u/Earthian:
        ```
        I question why humans are assumed to have a less dangerous utility function than other empowered intelligences. I'm thinking it's probably unwise to meddle with hyper-intelligence of any kind until we have much better models of axiomatic space. Now if we could just invent some kind of AI to help us understand axiomatic space.
        ```

        - u/traverseda:
          ```
          >I question why humans are assumed to have a less dangerous utility function than other empowered intelligences.

          It's not that. It's that you can uplift a bunch at once, and you should be left with an average that isn't too harmful to humans.
          ```

        - u/None:
          ```
          >I question why humans are assumed to have a less dangerous utility function than other empowered intelligences.

          What would "less dangerous" *mean* without human ethics to ground evaluations?
          ```

  - u/None:
    ```
    You might want to follow along with [this](http://www.fimfiction.net/story/201692/deathonomics).
    ```

    - u/None:
      ```
      You deserve the karma for posting it, but good job on the Trollestia.
      ```

  - u/None:
    ```
    > That leads to a lot of entities choosing, let's say, 2 private utilitons (units of utility) and 1 public utiliton, instead of choosing 1 private and 3 public. Sure, there's more overall utility in situation two, but there are selection pressure's to consider.

    Ah, externalities. Like when a dragon's smoke drifts over the quiet town of Ponyville....

    It is worth noting that in the absence of externalities capitalism achieves exactly what you want it to. In the absence of transaction costs, capitalism is ridiculous at achieving every achievable and present human goal.

    Universities capture the value they create with tuition. Students capture the value they create with higher future incomes. And so on.
    ```

    - u/None:
      ```
      > Universities capture the value they create with tuition.

      With respect, no they don't.  I mean, there are *really obvious counterexamples* to this universally-quantified statement of yours: Harvard and MIT.  Two of the most prestigious universities on the planet, and they mostly actually run off their endowments and real-estate holdings in Boston-Cambridge.  Their tuition is actually artificially low *precisely because* they're not actually funding themselves through tuition, which means their tuition *isn't* a rationalized inputs-to-outputs price signal.

      And then there's *public* universities, which are a major thing *everywhere* but the United States of America... and also sometimes even in the United States of America.  These run off state funding, which again, means their tuition is artificially low and not a price signal.

      >Students capture the value they create with higher future incomes.

      This is circular logic: it assumes value is "that which is captured in market transactions".
      ```

- u/aintso:
  ```
  How do we design a game that makes people build transferable information-processing and decision-making skills. Rationality games, basically. Besides Zendo and Fallacy Mania, what's out there already?
  ```

  - u/AmeteurOpinions:
    ```
    You forgot *EVE Online*. Anyone who's heard of it before knows why I'm putting it here.
    ```

    - u/miningzen:
      ```
      I actually don't see how Eve applies, after playing it for a few years. Could you explain?
      ```

- u/None:
  ```
  There are a lot of things I think about, but I'm going to post my most selfish (currently, at least) problem that could still benefit a wider community.

  I'm currently unemployed and the main thing that I've learned (apart from how not working sucks) is that the skills needed to **get** a job and the skills needed to **do** a job are often completely unrelated. This isn't true for all jobs, but it is true for probably the majority of jobs.

  This leads to the problem of perfectly capable human beings (such as me) spending a lot of time and effort applying for jobs they could handle, without any real result (apart from feedback, which becomes useless after the first few times you apply). Not only is this a source of worldsuck, it also seems a highly inefficient way to do things (which is currently only allowed because there are more applicants than jobs).

  ----

  Relatedly, figuring out which job actually fits you is also a rather hard problem for quite some people (I notice a lot of people stuck on "good enough" jobs) and it's a problem you're supposed to tackle when you're 14 - 18 years old.
  ```

- u/MadScientist14159:
  ```
  How can we convince people to sign up for cryonics?
  ```

  - u/traverseda:
    ```
    Is that a goal? I'd probably say something like "making cryonics easier to obtain" or "get more people signed up for cryonics". Is this specifically about *convincing* people? Is it about cryonics' PR? I'm going to presume it's not.

    ---

    The reason I'm not signed up for cryonics is that it's too expensive. I imagine that's true of a lot of people.

    The first step would be to figure out why people in general aren't signed up for cryonics. Presuming price is as much of a factor as I intuit, figuring out where that cost comes from is important.

    So what do cryonics companies spend their money on? Presumably a lot of it is spent on upkeep, and investments ensuring that they can continues to pay for upkeep.

    ---

    Significantly decreasing the cost of upkeep hits both of those quite nicely.

    Technologies that might make cryonics upkeep cheaper:

     * Heat echangers.

    They've seen a lot of commercial application recently. It looks like the technology is maturing pretty quickly. Potentially a lot more efficient then whatever cooling methods they're using now. I don't really know, but it might be something other people haven't looked into.

     * Aerogels

    Very very efficient insulation. Minimize heat creep. Too expensive to implement now, but with a significant initial investment aerogel vessels could be a pretty big game-changer.

    ---

    Alternatively, you could make their investments more efficient. I imagine they can afford pretty top tier investment council. That leaves getting the government more involved, or crazy schemes involving crypto-currencies. 

    Or doing it better then the best investors around. They have to deal in bulk, but some dedicated venture capitalists might get a better ROI, if they're very good at predicting the future.

    Riskier, and most cryonics groups are rightfully risk-averse.
    ```

    - u/andor3333:
      ```
      I agree with all these points, especially getting current organizations to spend more efficiently. (and not on their boardmembers' salaries- yes I am looking at YOU SA...) I highly encourage you to hold cryonics organizations you involve yourself in accountable for their spending.

      The most pressing concern to me is getting a process that will receive scientific endorsements as capable of preserving the structures of memory. Then the competent scientists and doctors might start getting on board. I responded in more detail above.
      ```

  - u/None:
    ```
    Counterpoint: how do we create cryonics/body-preservation methods and providers whose treatments verifiably work, with strong evidence for their working?

    Point 1: this is a life-or-death decision.  A positive, even highly positive, expected-value based on a low probability of success *is not good enough*: expected values are measurements of average-case utility, which implicitly assumes a repeated set of either possible worlds (Bayesian) or experiments (frequentist).  For me to sign up for such a treatment and start pushing it on others, I want it to pass a hypothesis test: "with high probability based on experimental evidence, this thing actually works".  Those are the statistical tool you use when you will only get one opportunity to make your bet.

    Point 2: Ideally, I would like to see the development of methods that could, for instance, preserve a dead lab-rat (or other experimental mammal) (after its heart was stopped, say) to the degree necessary that it can actually be "resurrected" at a predetermined later time (by restarting its heart, say).  ALCOR can't do this, the Brain Preservation Foundation only does brains and has gone quiet, so I don't know whom to turn to.

    Yes, this is *mountains of evidence* I'm talking about demanding, but again, it's a life-or-death decision.  You only get life-insurance money once, after all, so if I'm going to spend it on something other than my family (when I have one), I need, at the very least, solid molehills of evidence that I could in fact be brought back *without the use of a Friendly superintelligence*.

    Because any plan that hinges on Friendly AI demands putting my money and effort into MIRI stuff, not signing up for medical treatments not known to work.
    ```

  - u/andor3333:
    ```
    For one thing, you could start by creating a cryonics organization that is actually fiscally responsible. From what I have seen several are extremely shady and pay far too much money tot heir boards, and alcor, which seems legitimate, spends ridiculous amounts inefficiently on do it yourself projects when they could buy their materials much more cheaply and with less chance of problems. Because of their poor finances alcor will go under unless they expand like a pyramid scheme, and this isn't happening.

    Also relevant, I have studied molecular biology with a  focus on neuroscience. In my opinion, cryonics as it is now is very unlikely to preserve what I believe to be the core structures for memory, and even if it did it would not preserve enough detail for eventual recovery even if every molecule could somehow be mapped in its state at the time of revival. I am EXTREMELY in favor of cryonics if they can get it to work. I will be donating large amounts of my income to get it to work. I do not believe it currently works.

    What has been happening is that cryonics has been improving significantly in the last few years, especially since they began vitrification. 

    The problems are...
    We haven't determined what structures contain memory, though we are getting close. None of the current prevailing models would be preserved by cryonics in its current state even for magical Drexlerian nanotech which is not feasible under out current understanding of physics.

    Most of the money in cryonics is going to organizations run by people with little or no medical knowledge, spending resources inefficiently, and with the majority of the money going to preserving people with the current faulty processes instead of developing new ones.

    If you want to convince competent molecular biologists and doctors to help you, these are the problems you solve.
    ```

    - u/None:
      ```
      Ok, so here's a question: whose efforts should I support?  Yours?  I generally seem to share your opinions of current organizations and techniques, so I feel like I ought do *something*.
      ```

      - u/andor3333:
        ```
        I am trying to answer that too. I have been keeping an eye out for organizations doing pure research and admitting it doesn't work now, or even reasonably responsible companies that do claim the freezing could work now as a fundraiser. There was one under development I had high hopes for but it went under before it started. At the moment if there is one out there I don't know where it is. 

        I wish I could be more help, but for now I am stuck saying there is a problem without being able to offer a solution beyond "someone should make an organization that fixes this." (maybe a little better than doing nothing, but not by much) I will donate money if I ever find one that I think has the right approach but right now I haven't got disposable income because law school and I don't know of any that fit the bill. I don't imagine you'll think of it, but if you somehow run across one in the near future that has these qualities let me know. I could at least spread the word then.
        ```

- u/Abpraestigio:
  ```
  This seems like a great idea! Wanna hijack /r/solvingproblems for our rationalist agenda? No one seems to be using it at the moment anyway.
  ```

---

