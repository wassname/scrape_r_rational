## [D] Monday General Rationality Thread

### Post:

Welcome to the Monday thread on general rationality topics!  Do you really want to talk about something non-fictional, related to the real world?  Have you:

* Seen something interesting on /r/science?
* Found a new way to get your shit even-more together?
* Figured out how to become immortal?
* Constructed artificial general intelligence?
* Read a neat nonfiction book?
* Munchkined your way into total control of your D&D campaign?


### Comments:

- u/rationalidurr:
  ```
  Guys, Monday is almost over.
  Ain't nobody gonna talk about nothing?
  ```

  - u/DaystarEld:
    ```
    Guess everyone's having a busy start to the week :)
    ```

  - u/ShiranaiWakaranai:
    ```
    Okay, I guess I can talk about a certain snake hypothetical that I have been thinking about.

    The scenario is a country of snakes, where the king snake has absolute power and so doesn't have to give a damn about what the other snakes want. However, one day the king snake goes missing without any warning, and years pass without anyone finding him.

    The king snake has two official sons: the eldest son is called Work-Snake, because he likes work, like, a lot. The second son is called Bio-Snake, because he likes biology, like, a lot. The king snake also has a countless illegitimate children, collectively called the Rush-Snakes. And some more children who I won't mention because this story will get too long. Since the king has gone missing, his children are now eying the throne, and a succession war is brewing. 

    The Work-Snake is the most popular snake, especially among the merchant class because they like his work. However, he has a bad personality, so most snakes don't want him to be king, they just like the work he does. Nevertheless, he has a decent chance to become king anyway, seeing as he is the eldest and most popular heir. 

    The Bio-Snake is a less popular snake, because he is less outgoing and less productive than his elder brother. Nevertheless, he has a reputation for having a much better personality, and a decent fraction of the population wants him to be king.

    The Rush-Snakes are a dime a dozen, and have no real support for the throne. Their upbringing was a wreck, and their personalities are a mess as a result. Most of these Rush-Snakes are just plain crazy as a result, so no one really wants them to be king. However, they have a special ability: when supported, they are far more likely to become king than the real heirs. No one really wants to support them though, so this special ability is useless. Or so it seems.

    So the competition for the throne is really between the Work-Snake and the Bio-Snake, who hate each other to death and would kill the other the moment they become king.

    Our scenario begins when one day, both princes wake up with a (brilliant?) idea: Each can tell the citizens to support them for the throne, otherwise when they become king, they will imprison and torture the citizens who didn't support them. The question is, is this really a good idea? Let's put aside all the spiteful things the citizens could do in retaliation to being threatened, and suppose instead that all the citizens of the country are cowards, and would obey when threatened. Would this threat be a good idea then? I think the answer is no.

    The reason is because if one prince threatens the citizens, so would the other. The citizen snakes would then have no idea who to support. After all, if they support one snake, and another becomes king, the new king snake would torture all of these citizen snakes who supported his rival instead of himself. Effectively, the only way for a citizen snake to avoid being punished would be to obey one snake at maximum speed, rushing to make it the king.

    But then, the citizen snakes wouldn't need to obey either of the two prince snakes then would they? They are just trying to make one prince snake the king so the other can't punish them. In that case, they could choose to support a Rush-Snake instead. And in fact, it would be in their best interest to support the Rush-Snakes, because of the Rush-Snakes' special ability of being easy to make into the King when supported. So by supporting a Rush-Snake, they would increase the chance of supporting the snake that ends up being King, and thereby decrease the chance of being tortured. 

    Effectively, the more the first two snakes threaten the citizen snakes, the more the citizen snakes would be cornered into obeying the Rush-Snakes. Which is probably a really bad outcome for the two princes, because Rush-Snakes are plain crazy and would probably ruin everything the princes currently have. As for the rush snakes, they can't threaten anyone at all, because they wouldn't become king anyway if no one obeys them, and no one in their right mind would obey the illegitimate heirs if they weren't being threatened by the real heirs to the throne. Also, the Rush-Snakes are a dime a dozen, many with different desires that go against one another, so threatening the citizen snakes could just result in them making another Rush-Snake the king instead, foiling whichever Rush-Snake threatened the citizens.

    So I think that they, being clever snakes, would choose not to threaten the citizen snakes in this scenario, since any attempt to do so would horribly backfire even if the citizen snakes were obedient serfs.
    ```

    - u/SkeletonRuined:
      ```
      Sounds unstable, since if Work-Snake commits not to threaten, then Bio-Snake can easily win by threatening (and vice versa).

      Hopefully the snakes can cooperate in one-shot prisoners dilemmas, I guess?
      ```

- u/Veedrac:
  ```
  There was a [Google, Microsoft and Facebook AI AMA](https://www.reddit.com/r/science/comments/7yegux/aaas_ama_hi_were_researchers_from_google/) a few days ago. I find these things interesting sources of information about what people generally think of the future of AI.

  There were two quickly-dismissed responses to AI risk [[a](https://www.reddit.com/r/science/comments/7yegux/aaas_ama_hi_were_researchers_from_google/dugqdwb/), [b](https://www.reddit.com/r/science/comments/7yegux/aaas_ama_hi_were_researchers_from_google/dug5bmi/)], but the other parts were more interesting.

  IMO, the most interesting answer was about [Superfetch and other under-the-hood ML systems](https://www.reddit.com/r/science/comments/7yegux/aaas_ama_hi_were_researchers_from_google/dugl69a/). Alongside the recent paper [The Case for Learned Index Structures](https://arxiv.org/abs/1712.01208) and the general, unassailable hype for this stuff, I see a rather interesting future computing landscape where gradually more and more components of programs get swapped in for more general optimization procedures.
  ```

- u/crivtox:
  ```
  I guess I'l, put part 1 here , and continue in the next thread , that way I can prevent myself from overediting this and procrastinating , and people still sees it.

  **The dangers of exploiting time loops ,and optimization proceses (or how  to avoid  reward hacking the universe) part 1.**

  In this subredit a recurring idea in the munchkinism tread is using certain powers to create optimizations proceses and get that they want , often a time loop ,either some process that repeats itself until  some condition the  or  any kind of stable time loop that obeys Novikov self-consistency principle(winch has a lot of extra complications that I'm not going to talk munch about).


  For multiple reasons that  I wont discuss here(I originally did but the post was becoming absurdly long) humans  in general are horribly bad at modeling optimization proceses that aren't human-like(one can become better at it by studying evolution and  programming but its still difficult  ) and unless you know that you have really good intuitions about this you should assume that you are biased to the optimistic side .


  And since I see a lot of optimism in the plans there(though i guess assuming the most favorable conditions is in the spirit  of the saturday munchkinism thread, but let me have fun overanalicing things) and that I was having fun thinking about it ,I'm going to try to analyze those situations(and especially time loops) , try to outline some heuristics to know when your clever idea would doom us all(or just kill/reward hack you) and see what security measures would be usefull(apart from solving ai alignment which is necessary in a lot of cases as I'll explain later, though this is probably not feasible in most scenarios ,so needs to solve AI alignment here mostly  means do not try).
  disclaimer( I actually wrote this last year ,but since the year started I have been procrastinating on a lot of things , and not feeling a lot of motivation to work on my personal projects, so I hadn't finished it If this is incomplete its because I precomited to sending it today )

  So first what is  an optimization process.
  An optimization process is some process that explores diferent conbinations of variables to maximice some other variable.
  So what are the features of a optimization process?.

      1. What it is optimizing for:

  The exact thing begin optimized , and how this differs from what you want , ( borrowing terms from eliezer's last book the adequacy of the optimization process)  is something very important ,  especially since humans tend to commit a lot of errors in this and asume that whats being optimized is what they want instead of what they actually are using to as a proxy for that.
  We don't know, even on principle , how to formally specify from simple rules a system that will get us complex things like human values , this is actually a big part of what ai safety is about, and actually  an unsolved problem.

      2. What it is optimizing

  We can think about   the combinations of things the optimization process can affect as a space ([relevant robert miles video](https://www.youtube.com/watch?v=q6iqI2GIllI)) .

  Here we are interested in the size of that space , and what things it contains , we can't completely  evaluate the kind of spaces we want to use it on  ourselves  , since if we could we wouldn't need the optimization process.
  So we will have to reason in abstract  about the system and all the posible things it can affect , (more on that later).

  This becomes more important the more optimization pressure we put in the system , meaning how much the optimization process searches the space , and how efficiently.
  When talking about that we are referring to the third factor.

      3.How it optimizes it.

   A space can be searched in multiple ways , randomly , gradient descent ,hill climbing or something more weird and complicated.


  Situations like some kinds of time loops only have two possible values for any point of the space ,  0 or maximum value , and stop after finding a point whith different value.


  So in sumary  an optimization process is something that searches an space in some way to maximize some variable , or in some cases jut find some that fits some condition(though this last thing  is streching the definition a bit ).
  Now lets see how most people usually fail when consciously or unconsciously considering this 3 questions about their system and how can we try  do better.



  Feel free to leave feedback or ask questions even if I hadnt answered them in this part yet ,it will help me order my ideas to continue.
  ```

---

