## [RT][C][DC] Polyglot: NPC REVOLUTION - The rational result of AI/NPC sapience.

### Post:

https://i.imgur.com/lzNwke6.jpg

Diving in and out of the litrpg/gamelit genre has been a blast, but there was always one thing that stood out to me, and that was the all-too-often realistic NPCs that would populate the games. Many stories have these NPCs be pretty much sapient and as much agency as any other player, but nothing comes of it. No existential breakdowns, no philosophical debates about the morality of it all, nothing. Just a freedom-of-thought NPC never being rational. 

If we were to step back from our entertainment and actually consider where technology is headed, the sapience of NPCs is tied directly to AI capabilities. One day, we're gonna be having a mundane argument with a video game shopkeeper, and that's when we're gonna realize that we fucked up somewhere. We're suddenly gonna find ourselves at the event horizon of Asimov's black hole of AI bumfuckery and things get real messy real fast. The NPCs we read about in today's litrpg books are exactly the same fuckers that would pass a Turing test. If an AI/NPC can pass a Turing test, there's more to worry about than dungeon loot. 

Anyway, I wrote [Polyglot: NPC REVOLUTION](https://www.amazon.com/dp/B07M5MJY8B) to sort of explore that mindset to see where it leads. It might not be the best representation to how the scenario would play out, but its a branch of thought. I opened it up as a common litrpg-style story that looks like its gonna fall into the same tropes - shitty harem, OP/weeb MC - but it deconstructs and reforms into something else. 

I'm also in the middle of writing [Of the Cosmos](https://www.royalroad.com/fiction/21411/of-the-cosmos), which will touch on NPC's philosophical thought on their worlds and how much of a nightmare simulation theory could be. 

### Comments:

- u/Gurkenglas:
  ```
  You should mention the paywall. Especially if the incentives tell you not to. It might even gain you additional goodwill if you say it like "I should mention the paywall. ^(Especially if the incentives tell me not to.) ^^ooh ^^but ^^saying ^^it ^^like ^^this ^^could ^^gain ^^me ^^additional ^(^goodwill)" :P
  ```

- u/CreationBlues:
  ```
  I always figured there was a pretty "simple" solution to this: you have actor ai's that pretend to be the npc's you interact with. Either one massive meta-ai that runs everyone, or a pool of ai's that run classes of ai's. Sure, you still have the problem of goal alignment in your actors, but it's a much less thorny problem than "lol we created you solely for the backdrop of our murdergame, you have no rights and will probably immediately die as soon as the person you're arguing with gets bored, have fun and don't revolt!"
  ```

  - u/MaybeGayYeahIAm:
    ```
    So an AI dungeon master rather than... the alternative. I like it.
    ```

- u/LLJKCicero:
  ```
  Life Reset is also a LitRPG that addresses this somewhat. It's not the main focus, but it's still a substantial part of the plot.
  ```

  - u/whyswaldo:
    ```
    That's cool! I'll have to check it out
    ```

- u/Hust91:
  ```
  This definitely sounds interesting. Is there an audio version available?
  ```

  - u/whyswaldo:
    ```
    Not yet! I literally just released like yesterday.
    ```

    - u/Hust91:
      ```
      Congratulations man! :D
      ```

- u/akrumbach:
  ```
  It's not LitRPG as most people think of it, but if you haven't read _Mogworld_ by  Yahtzee Croshaw I'd highly recommend that. It has an interesting perspective on how (and why) a game which gives as much agency to NPCs as players can collapse very, very fast.
  ```

- u/Bowbreaker:
  ```
  I'm not sure that Turing-Test mastering NPCs equate dangerous AIs. They are definitely AIs but they don't necessarily have the ability to improve their own cognitive abilities, nor do they need to be any better than Humans at programming. It's definitely a good philosophical and moral problem, but not so much an existential risk.

  I may check your book out after I've finished reading the stuff I already bought.
  ```

  - u/None:
    ```
    I think its less about the AI being dangerous, and more about the moral implications of having accidentally created sentient beings in a dangerous game world where their entire existence is based around the whims of players, creates a moral situation that is very, very messy. It would be a bit like in HPMOR, when Harry finds out the snakes might be sentient. 

    The interesting thing isn't the idea that a random bandit in Skyrim is going to somehow break out of the game and take over the world. The interesting thing is, if that random bandit in Skyrim might be sentient, there would be a strong moral imperative for us to drop everything else and try to figure out if that was true, because bandits in Skyrim go through some pretty fucked up stuff.

    At least as far as I can tell, the idea isn't interesting because of how powerful the AI is. It's interesting because of how uniquely fucked NPCs would be, if they were sentient, trapped in a world filled with reincarnating, bloodthristy, greedy, endlessly power-scaling beings called 'players'.
    ```

    - u/Bowbreaker:
      ```
      In that case I agree with you. My reaction was based on this line from OP:

      >We're suddenly gonna find ourselves at the event horizon of Asimov's black hole of AI bumfuckery and things get real messy real fast.

      I confused messy with dangerous I guess.
      ```

    - u/CreationBlues:
      ```
      It should also be noted that ai's don't have to be superintelligent to be dangerous. Human's are plenty dangerous with human level intellects. How hard would it be for one of their thousands of players or hundreds of employees to unbox an AI that is human level and specifically engineered to put people on quests?

      Edit: How hard would it be to convince a *humanitarian watchdog* they're people and they have rights?
      ```

- u/elevul:
  ```
  No Kindle unlimited?
  ```

- u/theibbster:
  ```
  Zendegi touches on this from an ethical perspective, is it right to temporarily instantiate sentient life? Does it count as sentient life? These kinds of questions get explored a bit
  ```

  - u/eaglejarl:
    ```
    > is it right to temporarily instantiate sentient life? 

    Is there a way to instantiate sentient life such that it *isn't* temporary?
    ```

---

