## [Q]Why is a copy of you still you?

### Post:

Destructive mind uploading, essentially creates a copy of you in a computer, and destroys your original mind. I mean its great and all that a copy of you still loves on, but the original you still dies. You still died, what's so great about that? I mean if I died I wouldn't care if I had a copy or not because I would be dead. So why would you guys say that a copy of you is still you?

### Comments:

- u/Transfuturist:
  ```
  For the cautious, like myself, there is a different procedure to follow under the Ship of Theseus. It's called the Moravec procedure [(Gradual Replacement on Wikipedia)](https://en.wikipedia.org/wiki/Mind_uploading), and it's designed to effect digital upload with no discontinuity in consciousness or awareness. The brain is gradually eaten by nanotechnology, and the parts that are consumed are simulated by a computer and interact with the remainder of your organic brain while it is being consumed.

  You function entirely normally throughout the procedure, and in the end you are an entirely digital mind, without ever doing so much as falling asleep or going under anesthetic. Still not something to follow if you believe that "quantum" plays some magical effect in personhood, identity, consciousness, or whatever the hell people call the soul nowadays, but it is sufficient to cover the objection you lay out in the OP.

  This is borne out of a concern for some special internal reference frame. I consider copies to be the same as the original in every respect from the outside (barring actual technical differences in the behavior of the mind), but I have never left my brain (besides my dissolution under anesthetic and *maybe* during sleep), so I am still somewhat concerned about leaving it within a discontinuity. The only times I've considered discontinuous upload for myself, I was more suicidal than less, so at the very least it is something I would have to change my intuition on, and I don't have enough evidence about discontinuities that already happen (general anesthesia, *maybe* sleep) to convince myself on that point.
  ```

  - u/pizzahotdoglover:
    ```
    I like this idea. My view is that "you" are a ball of electricity running in a certain pattern, bouncing around a brain. If that is extinguished, you are dead. Your description would be a way to carefully transfer the continuous ball of electricity over to a computer without interrupting its pattern or turning it off. The interesting question is what happens if you are cryopreserved. I guess according to my own definition, you would die, and a copy of you would wake up in your body. So if souls exist, your original soul would stay in the afterlife and another soul would animate your body, instead of your original soul being transferred back into your body.
    ```

    - u/Gurkenglas:
      ```
      Churn infinite saved souls into heaven by oscillating the pope between barely alive and barely dead?
      ```

      - u/GaBeRockKing:
        ```
        There's a relevant SMBC where they discover that, since beings are ensouled at conception, arbitrarily large amounts of souls may be generated by continuously dividing and joining zygotes and egg. The society in question then sells the souls to lucifer in return for immortality.
        ```

        - u/puesyomero:
          ```
          one of my favorites in fact!
          ```

      - u/None:
        ```
        Ah, /r/rational. You say the funniest things.
        ```

        - u/Gurkenglas:
          ```
          It's like the plan to activate all the slayers by making Buffy spin in/out her grave.
          ```

      - u/psychothumbs:
        ```
        If he agreed to it then it's suicide and they're all going to hell. If he didn't agree to it then that's fucked up.
        ```

        - u/Transfuturist:
          ```
          Shut up and calculate, we need to fill this uncountable infinity somehow!
          ```

    - u/Geminii27:
      ```
      It's complicated by the ball of electricity being shaped and maintained by the physical brain. You are able to fall asleep, fall into a coma, and even die for short periods, but barring physical/chemical damage, your brain is able to reform your pattern much as a switched-off computer can fire up and and proceed to automatically reload your preferred operating system and personal environment.

      The question then becomes: does cryopreservation preserve sufficient information to allow a future reconstruction process to build a platform which would result in booting up a mindstate *sufficiently close to the original* that it would be considered an instance of You-the-original?

      From an internal perspective, the mind (assuming it was healthy and functioning) would have the original's memories and personality, and perceive the discontinuity as nothing more than a long sleep or coma.

      From an external perspective, there would probably be a lot of legal issues, because current legal systems do not recognize transferral or copying of mindstates from the original substrate (admittedly, this is mostly because there has never really been a call for it yet). Identity is currently mostly based on physical markers - fingerprints, DNA matches, visual traits such as facial appearance. Your new body (assuming you had one and were not being run on software) would be considered a separate identity by default under modern systems.

      You could get around this with some preparation - setting up a (probably nonprofit) corporate entity whose day-to-day maintenance is handled by lawyers, and whose corporate rules include something along the lines of "In the absence of designated source of CEO-level directives, CEO-level directives may be issued by any source which holds the passphrase." Your could then go to the lawyers, give the passphrase, and install your identity (if you had one) as the new CEO, both as your original self and after coming back from cryo. Have the corporation own all your personal resources in the first place, and you don't need to worry about them being dispersed if your original self dies.

      The next major legal problem is attaining a legal identity if you are not corporeal. A little easier in countries where corporations are able to obtain citizenship status, but still difficult to be recognized globally as a human unless you are walking around in (or at least tele-operating) a meat body. The main problem is gaining identity for a body which was not 'born' in the conventional manner. Unless you have the resources to own and operate an orphanage, hospital, or other facility capable of processing paperwork for teenagers or adults who have 'lost their memory' and need new government-approved identities to operate in society, you are going to have problems.

      (I presume there is at least some process for issuing new identity documents to adult civilians whose previous identities cannot be determined, but it would not surprise me if it required intervention and/or pressure from medical organizations. And gaining identity can itself be different from gaining citizenship.)
      ```

      - u/Transfuturist:
        ```
        > your brain is able to reform your pattern

        Have we ever observed recovery from brain-death? I don't believe anyone's ever recovered from loss of electrical activity in the brain.
        ```

        - u/aperrien:
          ```
          We use induced hypothermia in open heart surgery pretty routinely nowadays. There are also instances of people recovering from extreme hypothermia where no brain activity can be detected. So, I'd have to tentatively say yes, there have been instances of recovery from loss of electrical activity in the brain before.
          ```

        - u/None:
          ```
          [deleted]
          ```

          - u/Transfuturist:
            ```
            I'd like to see the ethics review boards for *those* experiments.
            ```

            - u/sole21000:
              ```
              http://embed.gyazo.com/ebd4b168de40662070fcaed02343ca1b.png
              ```

  - u/kaukamieli:
    ```
    Î”
    ```

- u/chaosmosis:
  ```
  I think the traditional arguments on this notion that can be found elsewhere are strong, but if they have not persuaded you it might help you to think about it from this different perspective instead: I don't care about avoiding death per se so much as I 1. care about avoiding the painful and existentially unpleasant process of dying, and 2. care about getting to experience the enjoyable process of living. I can't see any sense in which death or nonexistence is bad that doesn't fall into one of those two categories. If that's so, then destructive uploading is no big deal. Do you see any third reason death is bad that I have missed here?
  ```

  - u/Articanine:
    ```
    Well, this may come across as a bit selfish, but honestly I really don't care what happens after my death. I mean if there's a copy of me running around after I die that's great and all but it makes no difference to me because I am still dead.
    ```

    - u/chaosmosis:
      ```
      You're saying that you don't think destructive uploading satisfies 2. It causes a copy of you to experience the enjoyable process of living, but not you yourself to experience that process. I didn't anticipate this as a possible response, honestly. Maybe going into more detail will help get the intuition across better.

      Under normal circumstances, when a human dies, they still exist as a dead body. Do you think that you would enjoy existing as a dead body? Likely not. Likely, you believe that personal identity in a moral sense is not found in the simple physical fact that mass and energy are conserved. Instead, you believe that your identity lies within the content within your mind. This is about information.

      Similarly, like you, I care about my own experiences, not someone else's. But what makes an experience "mine"? I think that an experience is mine if external circumstances interact with my thoughts and feelings and memories. That is, if they interact with a particular pattern of information.

      What is an "experience" in the first place? A certain kind of information.

      If identity is information, then it does not make sense to say that information can be identical without identity being identical. To deny the equivalency is to say that identity is not information. For the reasons given in the above paragraphs, it seems like your value system commits you to the view that identity is indeed found within information.

      Does this make more sense? If you disagree with the idea that identity is found within information, where would you place it instead? What additional pieces would you add to metaethics, and why are they necessary?
      ```

    - u/nicholaslaux:
      ```
      >because I am still dead

      Your initial question was effectively asking people to explain what they think of as their self-identity, but this seems to be indicating that you already have an answer (your self-identity is your current physical body, rather than, say, your collection of memories, or your thought processes, or something else) and aren't especially interested in other opinions on it.

      It's possible that's just how I'm reading this post and that's not what you meant, but that is how it comes across to me.
      ```

- u/None:
  ```
  [deleted]
  ```

  - u/Articanine:
    ```
    Are you sure about that, if you cease to exist then why do you have dreams? Additionally, I read an article somewhere that stated that even when sleeping you still have a minimal level of consciousness in order to experience dreams. So really, the only time you cease to exist is when you die, I don't think your mind can restart after a shut down,however, if you have evidence on the contrary can you please link it.
    ```

    - u/alexanderwales:
      ```
      We also have comas where people do not dream, which people are capable of recovering from.

      I guess I don't really think of dream consciousness to be the same as waking consciousness anyway. It's more like dream consciousness is just a side effect of your brain undergoing a defrag process, while waking consciousness is a side effect of normal brain operation. There's a potential bridge between them, in the form of lucid dreaming, but ... it's tough for me to say "oh yeah, that's me" when talking about dreams, simply because the dream version of myself behaves in ways that are far different from what I would expect of even an imperfect clone of myself.
      ```

    - u/Frommerman:
      ```
      Dreaming only usually happens during REM sleep, which is the shortest phase of sleep. You are not dreaming at all for several hours each night, and sleep studies show that your higher brain functions run radically differently during deep sleep as well, indicating a lack of consciousness.
      ```

    - u/None:
      ```
      [deleted]
      ```

      - u/Transfuturist:
        ```
        >Would you want to live in a state of constant dreaming, unable to interact with the outside world, unable to realize that you're dreaming, constantly forgetting what you just dreamt?

        The quality of the sensory experience does not have any special consideration for its existence. You are conscious while you're dreaming. I don't think you can even say for certain that experience is interrupted even in the case of anesthetic or comas, as there is still brain activity, and you might simply not *remember* any experience you do observe. That is massively internal, and we need further research to say anything on the subject.
        ```

  - u/RMcD94:
    ```
    And if you take this to the conclusion every nanosecond your brain stops and starts. The universe isn't infinitely fidelity and your brain certainly doesn't operate on the lowest level anyway.
    ```

    - u/Geminii27:
      ```
      Precisely. The mind-pattern which exists after one nanosecond, or after an eight-hour sleep, is merely the *closest match* to the previous pattern, to the point where average human senses can't tell the difference.

      And even then, we can usually tell when someone's just woken up and when they're halfway through their day. We just lump it all under a group of states we consider to be sufficiently "that person".
      ```

- u/EliezerYudkowsky:
  ```
  http://lesswrong.com/lw/qx/timeless_identity/
  ```

  - u/LiteralHeadCannon:
    ```
    I agree with your stance on cryonics - but with respect to deconstructive-reconstructive teleporters, would this prediction pay its rent?  Would you actually enter such a teleporter?  Telling me that the copy created on the other end is me does little to calm me, given that the "original" destroyed on this end is *also* me.  So, even given the fact that the copy is me - a point that you do make well - 50% of all mes die every time I enter the teleporter.  It's a game of Russian Roulette, even if it doesn't look like it from the outside - and "the outside" includes previous teleporter users, because the ones you're talking to are obviously the survivors.
    ```

    - u/FeepingCreature:
      ```
      Just modify yourself to only care about at least one copy of your pattern continuing to exist. It's saner in the long run.

      The "just-a-copy" intuition is tempting, but it's physically unsustainable - you end up having to "tag" a particular configuration of particles as "you" and in the next breath say that another, physically identical configuration is "not you". Which is literally not possible without dualism - the tag is almost by definition superphysical (since if it was physical, we could duplicate it.)

      Oh, you might say, but the tag is just an abstraction - it's just part of my model of the universe. But then I say, exactly what _physical properties_ is that abstraction based on? It can't be something you _perceive_ - all your senses are physical. So the forced conclusion is that "I" is physically arbitrary, or indexical. But if it's indexical, you're forced to admit that you "one second in the future" is a different person than "you now".

      Then you get into continuity. But _the transporter clone has continuity too_.

      By the way, this is why dualists-in-denial like to take refuge in quantum, since it offers some "promising" (if you're trying to cling to a single consciousness) claims about noncopyability. Unfortunately, our brains almost certainly aren't quantum computers.
      ```

      - u/None:
        ```
        > Oh, you might say, but the tag is just an abstraction - it's just part of my model of the universe. But then I say, exactly what physical properties is that abstraction based on? It can't be something you perceive - all your senses are physical. So the forced conclusion is that "I" is physically arbitrary, or indexical. But if it's indexical, you're forced to admit that you "one second in the future" is a different person than "you now".

        Welllll... sorry, but I've been starting into analysis and topology, so this now bugs me.

        That is, I could just say, sure, "one second into the future" *is* different from me.  But it's only a *continuous* change.  I could easily charge that there are some *discrete* changes which may be physical continuations of "me", but don't have the same "personal identity" (for all that such is a meaningful, rigorous concept, which is not much).
        ```

        - u/Chronophilia:
          ```
          Bringing continuity questions into physics is a bit iffy. On the one hand, *all* physical changes are continuous, since every particle in the universe moves along differentiable, slower-than-light paths.

          On the other hand, we have some unanswered questions about time and space at the smallest scales, and calculus concerns itself with *infinitely* small scales.
          ```

          - u/Sceptically:
            ```
            > On the one hand, all physical changes are continuous, since every particle in the universe moves along differentiable, slower-than-light paths.

            Quantum tunnelling.
            ```

      - u/LiteralHeadCannon:
        ```
        I'm not saying the version on the other end *isn't me*.  I'm saying the version on this end *is me*.  If I accept that the version on the other end is me, which I do, then 50% of mes die when the teleportation event occurs.  It's directly equivalent to flipping a coin that kills you when it comes up heads - an activity that also "leaves at least one copy of your pattern continuing to exist".

        You either accept quantum immortality (which has some really weird and interesting implications, but it's not scientifically provable and I'd prefer all things considered not to test it myself, because humans are survival-seeking mechanisms) or you accept that entering a teleporter is equivalent to the "I shoot you if the coin comes up heads" game I described.
        ```

        - u/Transfuturist:
          ```
          I really hope quantum immortality is true, or some other form of solipsistic immortality, because that gets me a way *out* of this dying universe.

          I imagine some really trippy and horrible mind-modifying effects would come about when your brain is being destroyed. Quantum immortality doesn't mean guaranteed humanity, wholeness, or mental health. It just means that you never stop observing. Ever.
          ```

- u/Geminii27:
  ```
  It's partially a language problem. "You" is used to mean your individual self, but also used to mean "The organism which exhibits all the characteristics of yourself". As these tend to refer to the same thing pretty much 100% of the time outside of very specific SF works, there's never really been a need to separate the meanings, which is why it's easy to pose identity-based questions which are ambiguous about what they're talking about.

  I find that a good analogy is to expand the idea of self to encompass a group or team of individual instances. We see this today in the form of companies - a company representative can be referred to as if they are the company, in many circumstances: "Oh, we had a meeting with BigCorp the other day" (i.e. we had a meeting with a *individual representative of BigCorp*).

  So imagine the corporation of Alice. There might be two individuals, there might be a hundred. All are considered sufficiently Alice-like to be considered part of Alice. Any individual Alice-instance can be considered as their own person, but also in the context of them being an Alice.

  In the case you mention, there is no confusion - the original Alice-instance is destroyed in a manner where they do not experience post-destruction continuity. The new Alice-instance is not the old one, but they are still *an* Alice - and from an external perspective they are probably sufficiently Alice-like that they inherit the Alice relationships in existence.

  Think of a major corporation which changes CEOs - the original CEO could be retired, or doing something else, or dead, but the corporation they helmed is still in existence and maintains all its legal agreements, resources, debts, contracts etc. From an external perspective, it hasn't changed.
  ```

- u/None:
  ```
  [My reply, last time this came up](https://www.reddit.com/r/rational/comments/39xqpi/rrationals_view_on_the_continuity_of/cs7fq15)
  ```

  - u/traverseda:
    ```
    Did you delete that account?
    ```

    - u/Geminii27:
      ```
      His original self died; this is a copy. :)
      ```

- u/lsparrish:
  ```
  In a certain sense, the "you" from each instant vanishes without any trace other than the "you" from subsequent instants. Call these p1 and p2. How are they related?

  There are two fundamental connections we can identify here. One is the similarity: p1 and p2 have many very similar attributes including most past memories. The other is the causal connection: p2 would (with high probability) not exist unless p1 first existed.

  A high fidelity copy of you meets both of these criteria. Two such copies, or 100 such copies, would meet this criteria equally well in terms of their relationship to the original. The copies would have only the similarity relationship to each other, however.
  ```

- u/MugaSofer:
  ```
  Nobody actually knows, it's just a guess.

  These things get reasonably complicated once you have multiple copies of a person and have to decide whether the death of one of them matters as much as the death of someone else.

  There are just a few standard "solutions" (guesses) as to the answer - 

  * just this copy (but how do you distinguish "this" copy in certain edge cases?)

  * as long as one copy survives (but would you really be OK with dying just because a copy somewhere else lives?)

  * as long as one copy "descended" from this one survives (implies odd shifts over as your fellow copies are merely "descended" from past!you, no current!you)

  * radical rejection of "identity" (almost impossible for humans, leads to people rejecting death-is-bad because it's "illogical")

  Stuff like that.
  ```

- u/None:
  ```
  A second copy of me is still me for all the reasons the first copy ever was.

  I'm sad that a first copy was destructively uploaded, because it means there's not two of me, which I would vastly prefer. But once I'm uploaded I can't imagine there being much of a barrier to making more copies. Even if I do keep them in stasis as backups.
  ```

  - u/Transfuturist:
    ```
    > there's not two of me, which I would vastly prefer

    You're on the list of reproductive hazards now.
    ```

    - u/None:
      ```
      Just for that? I vastly prefer there to be a second copy of you as well.
      ```

---

