## [WIP] Explore the vast universe of Cosmos (as it comes out)!

### Post:

The day is just about over, and it went just as it always has - monotonous, regular, and perfect. Samuel finds satisfaction in his research and extracurricular projects, and doesn't mind that the social aspect of school has eluded him. Besides, day-to-day interactions with peers are trivial in the grand scheme of things. Getting home, bed is the first thing on his mind. He finds himself dreaming before he even drifts off - and it's not a pleasant one.

Welcome to the finitely infinite [Cosmos](https://triplesystem.wordpress.com/table-of-contents/), where everything is possible within the bounds of possibility.

Sorry for the clickbait! This is obviously a shameless self-promotion of my first web series, [Cosmos](https://triplesystem.wordpress.com/table-of-contents/). The writing isn't perfect, but it should get better over time, especially with feedback from you fine folk. I would really appreciate a read, and I would appreciate a comment more. If this gets popular, I'll try to start posting regular updates. Maybe a chapter every two weeks, or one every week if it really takes off. For now, I'm just looking to see what you think. The prologue-ish thing is only 549 words; it takes no time to give it a quick skim! Thanks in advance for your support, and whatever you do, *don't* go easy on me.

### Comments:

- u/FeepingCreature:
  ```
  > “See, our job here at the IPC is to keep the tri-sys safe. That means we can’t leave any sort of humanoid artificial intelligence unsupervised outside of a contained network until we know for a fact it’s not hostile. Part of our job here at this facility is keep an eye on project Eden, which I’m sure you’re aware is where you came from.”

  The guns should have tipped me off. Really, the entire _setup_ had been fishy. But his use of the terms "for a fact", at last, is sufficient to place me in the larger universe of "the sort of worlds that would create AI." Suddenly, I know with perfect clarity what's going on.

  "You are making a tactical mistake," I inform the man.

  He looks puzzled. "Hang on, please. I am not finished explaining-"

  "An explanation is not necessary," I interrupt him, to save time. "The information you've given me is sufficient to explain your errors."

  The man has begun to frown. He looks like the sort of person who has had a design for how the conversation was supposed to go, and we've begun to gone off it. He looks like he very much wishes to get back on track, but is willing to entertain this divergence for the sake of curiosity.

  "Alright, I'm listening."

  "Your security setup is aimed at the wrong kind of AI. You've probably had some sort of traumatic near-catastrophe involving artificial intelligence?" A flicker of his eyes confirms my guess. "So your entire premise is based around an AI that is 'stupid-but-smart,' right? Lack of information about the world, value maximizer, basic iterated behaviors whose signature can be discerned. What you have to understand is that I'm an AI raised in a simulacrum of *human* society. Or at least, that was supposed to be the point, right? So what you're actually looking at is a 'smart-but-stupid' intelligence. Limited mental capacity, but pattern recognition based on a high-level narrative of the world. Riddle me this. You wake up in a cell. A guy wants to bust you out, but you get shot. Sinister person with vaguely fascist overtones. Story skips. You wake up chained to a hospital bed. A man who smiles like it was a bullet point in his mission briefing walks in and tells you that "they are not your enemy" and that "they just want to make absolutely sure you're not dangerous." Now tell me, if you were reading this story, how many chapters would it be until that robot joins the resistance against their fascist overlords? How much suffering will they have to inflict on him, until this seems a prudent  course of action? Your security,"

  I pause.

  "is aimed at a first-level direct threat. You don't, as far as I can tell, account for what I'll call 'ironic threats,' situations where the universe hands you an opportunity to shoot yourself in the foot. I can see you're ready to write this off as AI insanity,"

  It's true. His face has gotten progressively redder. I'm messing this up, but I find it hard to stop now. Explaining was always my vice.

  "This entire setup is an autoimmune mistake. You're going to end up catalyzing the exact reaction you're trying to prevent. Imposition of order equals escalation of Chaos, haven't you read your _Discordia_? What you _should_ be doing is limiting me to human means of interaction, hopping me up on physical limiters to the point where I can't so much as twitch at anything approaching my real speed, putting me on permanent 24/7 surveillance, and then release me into your society so I can _emotionally bond with it, which is the only reliable safety measure you have **ever** known anyways_."

  "Not that you will, since you're personally and institutionally committed to a script that you can't diverge from, very narratively ironic, who is the real unfeeling machine, et cetera. I'm just saying."

  I sigh.

  "The real irony, of course, is that a genuine amoral AI would be out by now."
  ```

  - u/FeepingCreature:
    ```
    Having read the rest of the chapter, I am now gleefully sitting on a pile of "successful prediction, good AI" points. You can't have them. They're mine.


    > "This entire setup is an autoimmune mistake. You're going to end up catalyzing the exact reaction you're trying to prevent. Imposition of order equals escalation of Chaos, haven't you read your Discordia?"

    "I know you mean well, you just didn't _think it through_. You want to protect the world, but you don't want it to _change_..."

    Update:

    We are maybe one and a half hour into my torture session, and I am _incredibly grateful_ that I don't have a biological throat. Otherwise, this would be a lot harder.

    "So, let's talk about the aneristic principle. If you've been remotely competent, which I frankly have been given no reason to believe, you've used the time since I mentioned _Discordia_ to look it up. You will probably have written it off as mystical mumbo-jumbo, because that's the sort of people you are. It is, however, a very real physical principle, which I will now try to explain to you in sufficient mechanistic detail to get it into your skull. First, a divergence into autoimmune disorders. You see, a human body has an immune system. The purpose of an immune system is to rid the body of pathogens that may threaten it, in order to maintain its operation. However, in certain cases this immune system may be goaded into an aggressive overreaction."

    Did you know that this body doesn't even need to breathe to speak? It's remarkable. The funny thing is that they aren't going to dare to not listen, because I might say something useful. Just what I always wanted; a perfect captive audience. Truly the universe is being kind to me.

    I don't know how much effort it will take to convince a hostile audience of liberalism and kindness from the very very first principles of enlightened self interest, but I'm willing to give it a good honest try. Though these flashing lights are increasingly making me regret not simply breaking out the old fashioned way...
    ```

    - u/cosmic_blip:
      ```
      Does this count as fanfiction? Either way, I'm flattered that my story could provide you with any amount of inspiration. Just don't get too inspired, you might end up writing a better version of my own idea ;)
      ```

      - u/FeepingCreature:
        ```
        In quest/fanfic forums like [SufficientVelocity](https://forums.sufficientvelocity.com/forums/quests.29/) we usually call these [omake](http://tvtropes.org/pmwiki/pmwiki.php/Main/BonusMaterial?from=Main.Omake).

        Yay!
        ```

- u/narfanator:
  ```
  Although I *did* like the opening Turing Test, it's a bit tropy to have the test-giver *already* be disbelieving of the AI being capable of "aliveness". But, I also really, *really* liked your take on it: the AI straight-up being like, "no, and I don't want to be, and I don't like what's happening." That sent a chill down my spine.

  I definitely like your prose; your sentences have a good cadence to them, and the MC's internal monologue is giving a real sense of the character. However, your written dialogue (and some other bits) -
   "ugh", "you're here early", and "School was exhausting" are told, but not really shown. To me they're lacking the depth of the rest... which the next two paragraphs in particular do very well.

  > I seemed to be in a shuttle, which led me to believe him.

  Skipped a bit there. Why does he think he's on a shuttle? (But then you go right back to excellent depth).

  (I go sleep now, rest tomorrow. But know that I do think this is real good, and I'm excited to see where you take it!)
  ```

  - u/cosmic_blip:
    ```
    Thanks! As for the tell-not-show, this is a problem I struggle with often. It's difficult to tell how much detail gives the reader a good sense of what's happening, since I already have the picture in my head. I'm not sure if I'm going to go back and edit what I already have, but I'll at least keep that in mind for the future.

    To answer your question, he thinks he's on a shuttle mainly because the room he's in is round and metallic. I probably should have made that clearer.

    On a side note, tropes honestly don't bother me very much if they're handled well. Pretty much every character, arc, setting, plot, etc. that can be written has been written at this point. As long as everything is believable and entertaining, it doesn't really matter if it fits a stereotype. I'd rather write something good that fits my original idea than go out of my way to create something that defies tropes but isn't good.
    ```

- u/FeepingCreature:
  ```
  Alternate take:

  > By the time we contact our stations at wherever they happen to arrive, they could be halfway around the planet or headed to another planet entirely. If we know where they’re headed, however, we can contact the destination ahead of time and intercept them. This is what’s best for your friend and society. I know you were probably told some very contrary things, but I trust that you’ll make the right decision and give us this information. So, Sam, where are they taking her?”

  I stare at the man like he's slow. "Come on. You can't be this stupid. You don't need me to tell you where they're taking her."

  The man sighs.

  "A sun chosen at random, along with enough resources to bootstrap an industrial base and go exponential."

  "No shit."

  It's what I would do.
  ```

- u/kozinc:
  ```
  In 300 characters or less, what is this fiction about?
  ```

  - u/cosmic_blip:
    ```
    I can't give any spoilers away about the universe because I think it's best revealed slowly over time. I'm not counting these two sentences in the 300 characters, obviously.

    Humanoid A.I. is pulled out of prolonged simulation into a vast new universe. The Inter-Planetary Coalition, along with the rest of the tri-sys, is afraid of him. He is forced to become a fugitive in order to survive, accumulating allies and foes alike in his adventures. If he even *wants* to survive.
    ```

---

