## [Q] What can a rationalist do with a time-looping scenario (such as Groundhog Day) besides simply educating themselves to incredible levels?

### Post:

I'm having trouble thinking of ways to exploit something like that if the only thing you bring with you per reset is the contents of your skull.

### Comments:

- u/None:
  ```
  Sounds like it's time to start experimenting.

  I'd start by inserting a small harmless object, say a coin, into my ear.
  I'd also give myself a small cut.  If, like in Groundhog day, all exterior damage is repaired, then it would allow me to experiment further.  Where is the boundary for what gets carried over?  The state of my neural net is a physical state, so there must be a physical boundary between what is brought over and what is not.  I should be able to find it and use it.

  If I can bring over objects by performing minor surgery on my person, then small computers could allow me to perform an Oracle test, for starters.

  EDITs for clarity.
  ```

  - u/UnfortunatelyEvil:
    ```
    On the one hand, I would say it's a complete reset. Whatever you had when you woke up the first time is what you have the next infinite times.

    However, we are adding the carrying of memories, emotional state, and [muscle memories](http://en.wikipedia.org/wiki/Muscle_memory#Muscle_memory_encoding). All of these are unfortunately in the brain. I was hoping muscle memory was encoded in the muscles, but according to a quick Wikipedia search, there is evidence that it may not be.  

    So to carry something over, I would think it would need to be a state change of certain parts of the brain. Thus, my reckoning, would be that when the reset happens, the brain cells reorganize into the new pattern. If we go with that, then foreign objects would not be able to be passed to the next cycle (where would the excess silicon come from [no jokes]).

    In my conclusion, I'd think that you'd have to find a way to scan the cells in your brain to determine their state, and have that be an encoding that can be 'uploaded' to a computer via scanning, and opened via .zip... then you can do your work, compress it at the end of the day, and 'download' it into your brain cells again. Though, I personally don't know if we have a way of purposefully rearranging portions of brain cells without causing more damage. Likewise, the storage space will still be limited (let's not compare brain masses), without interfering with other necessary portions of the brain.

    However, if any of my assumptions are wrong, and there's a field with an 'inside' and 'outside' and everything in the inside gets replaced by the insides of the next cycle, then yeah, we can probably smuggle some things in~

    **tl;dr** I imagine that the new cycle state starts from the base from the first morning, then reorganizes pieces of particular cells of the brain to get the effect, rather than porting in any material that didn't exist in that space beforehand.
    ```

    - u/GeeJo:
      ```
      The problem being that trauma can quite easily rearrange brain cells in ways you probably wouldn't want to carry over. Even in the original movie, I doubt that driving into the quarry left the guy's head intact for the next reset, yet he isn't a drooling zombie.
      ```

    - u/autowikibot:
      ```
      #####&#009;

      ######&#009;

      ####&#009;
      Section 6. [**Muscle memory encoding**](https://en.wikipedia.org/wiki/Muscle_memory#Muscle_memory_encoding) of article  [**Muscle memory**](https://en.wikipedia.org/wiki/Muscle%20memory): [](#sfw) 

      ---

      >

      >The [neuroanatomy of memory](https://en.wikipedia.org/wiki/Neuroanatomy_of_memory) is widespread throughout the [brain](https://en.wikipedia.org/wiki/Brain); however, the pathways important to motor memory are separate from the medial [temporal lobe](https://en.wikipedia.org/wiki/Temporal_lobe) pathways associated with [declarative memory](https://en.wikipedia.org/wiki/Declarative_memory).  As with declarative memory, motor memory is theorized to have two stages: a short-term [memory encoding](https://en.wikipedia.org/wiki/Memory_encoding) stage, which is fragile and susceptible to damage, and a long-term [memory consolidation](https://en.wikipedia.org/wiki/Memory_consolidation) stage, which is more stable. 

      >The memory encoding stage is often referred to as [motor learning](https://en.wikipedia.org/wiki/Motor_learning), and requires an increase in brain activity in motor areas as well as an increase in attention. Brain areas active during motor learning include the motor and somatosensory cortices; however, these areas of activation decrease once the motor skill is learned. The prefrontal and frontal cortices are also active during this stage due to the need for increased attention on the task being learned. 

      >The main area involved in motor learning is the [cerebellum](https://en.wikipedia.org/wiki/Cerebellum). Some models of cerebellar-dependent motor learning, in particular the Marr-Albus model, propose a single plasticity mechanism involving the cerebellar [long-term depression](https://en.wikipedia.org/wiki/Long-term_depression) (LTD) of the parallel fiber synapses onto [Purkinje cells](https://en.wikipedia.org/wiki/Purkinje_cells). These modification in synapse activity would mediate motor input with motor outputs critical to inducing motor learning.  However, conflicting evidence suggests that a single plasticity mechanism is not sufficient and a multiple plasticity mechanism is needed to account for the storage of motor memories over time. Regardless of the mechanism, studies of cerebellar-dependent motor tasks show that cerebral cortical plasticity is crucial for motor learning, even if not necessarily for storage. 

      >

      ---

      ^Interesting: [^Muscle ^Memory](https://en.wikipedia.org/wiki/Muscle_Memory) ^| [^Proprioception](https://en.wikipedia.org/wiki/Proprioception) ^| [^Memory ^Muscle](https://en.wikipedia.org/wiki/Memory_Muscle) ^| [^Muscle ^memory ^\(strength ^training)](https://en.wikipedia.org/wiki/Muscle_memory_\(strength_training\)) 

      ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot NSFW toggle&message=%2Btoggle-nsfw+choduws) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot Deletion&message=%2Bdelete+choduws)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
      ```

- u/alexanderwales:
  ```
  If it's like Groundhog Day, you're limited to gaining more information or more skills. You can run experiments as much as you want, but you're limited to whatever you can do in however much time you have available (usually a day?). The skills won't really help you unless you anticipate getting out of the loop at some point, and the information you could gain would probably be negligible.

  Depending on what year it is, you might be able to contact someone at a national laboratory and get them to run experiments that they can set up in a day, if you have lots of loops to figure out how to short-circuit their disbelief and get them to help you. I have no idea what you'd hope to gain by those experiments besides more knowledge, especially since you wouldn't have any hope of building something like a large hadron collider or something.

  I guess if it were me, after I had exhausted all of the obvious fun things I would set to work improving my memory so that I could take more and more raw information with me in every loop. But if you can't get out of the loop, there doesn't seem to be a point, right?
  ```

  - u/deskglass:
    ```
    >But if you can't get out of the loop, there doesn't seem to be a point, right?

    There'd be no less of a point than usual. In fact, there'd maybe be more of a point since your existence would persist for longer.
    ```

    - u/alexanderwales:
      ```
      I think there'd be less of a point to living if you could never make an impact on the world, and if you only had a day to get to know any person. Eventually you'd have read every book within your reach, and it's not like you'd be able to make art that wasn't extremely temporary (and not any art that takes longer than a day to make and enjoy). In *Groundhog Day* he's effectively trapped inside a town of 7,000, and I have to believe that eventually the completely unchanging nature of the town would grow dull.

      I'm not making a general case against immortality (which I think would be great) but being trapped for thousands of subjective years in a single small town where I can literally make no change that lasts longer than a day sounds utterly terrible. Eventually there would be no challenges left to your half-life and no pleasures that haven't turned to ash in your mouth.
      ```

      - u/deskglass:
        ```
        I had interpreted your post as saying that there would be no point because all records of your actions would disappear. In response, I thought you would still be impacting the world, by making people experience happiness. It's just that the record of you having done so would be lost sooner. 

        I then thought that if records of action affect whether or not there is a point to it all, loop world wins out in the (very) long term because there will always be a record of your actions (you).

        I hadn't thought you meant there would be no point due to boredom.
        ```

        - u/alexanderwales:
          ```
          Ah, so you're arguing that from a utility standpoint there's a purpose because you can make people happy and reduce suffering, even though there's no record of it the next day except what you remember. I guess I can buy that in the abstract, but I really think the psychological toll of "doing the most good" and then waking up to having everything reset would just be too large for me.

          I sort of took for granted that other people in this scenario are essentially not a factor in my motivations, which I guess might say something about me or my philosophical outlook. I'm sort of tempted to say that a day that I'll remember is worth much, much more than a day that someone else won't remember, but I'm not sure that position is tenable. I'd have to think about it more.
          ```

          - u/Pluvialis:
            ```
            This is a moral question that I've been pondering over for a while now, and I haven't reached a conclusion yet.

            My intuition is definitely very strongly that in a Groundhog Day scenario everyone else has no appreciable utility value whatsoever.

            My intuition regards them as mindless automatons. And even though I know they're not mindless, there's something significant about the fact that on any given day you could commit whatever acts of atrocity you could think of upon them and that the next morning and every morning after they'd continue to get up as usual, no trace of your previous acts remaining.

            But when I compare this to my thoughts about temporary intelligences simulated on a computer, I come up with a different response. If you could spawn a new intelligence in a computer simulation, I would be quite upset with you if you didn't look after it, even if you were planning to delete it after the next day.

            I think it's the inevitability of the Groundhog Day scenario, the fact that it's not your fault that they're being respawned every day for 24 hours. If a computer were simulating somebody afresh every day and there was nothing you could do to prevent it, I think the same ennui about their utilitarian value would result.

            EDIT: This starts to get even weirder for me, and completely beyond my ability to come up with an intuitive response, if you consider the following question.

            What is the utility value of a series of saved snapshots of a simulated intelligence?

            Assuming a simulated intelligence has utility, at what point does the utility arise? As it's being calculated? As it's being read from memory? What if you read the snapshots non-chronologically? How would I know if I were a simulation being run non-chronologically? Could I just be a series of snapshots stored in memory? Could I be just a single snapshot? Could I even just be a theoretically possible arrangement of molecules?

            Makes my brain hurt.
            ```

    - u/None:
      ```
      I'd point out that even the protagonist of Groundhog Day found a way out of the loop, albeit in his case accidentally.

      Eventually, your experiments may allow you to determine how you ended up in the loop, and how you might escape it.
      ```

- u/EliezerYudkowsky:
  ```
  Depending on how the memories are transferred, you might eventually be able to turn yourself into a self-improving AI that ran on human neurons.
  ```

- u/DataPacRat:
  ```
  https://www.fanfiction.net/s/5193644/1/Time-Braid

  Sakura starts a Groundhog Day loop sequence, in which all she brings with her are her memories... and then various hijinks ensue, including munchkinry.
  ```

  - u/PeridexisErrant:
    ```
    Seriously, there must be something cool that could be done by someone *otherwise normal* in a loop too.  

    Sakura ends up avoiding a loop reset when her body is atomised because that can't impair her combat abilities.  

    Normals are probably limited to Coil type tricks (from Worm).  We could brute-force Dinah or *maybe* Contessa, but I'd guess some sanity damage would ensue from the time that would take.
    ```

- u/Geminii27:
  ```
  In this scenario, do you have the ability to end the loop, or foreknowledge of when it will end?

  If not, you could postulate that the loop would continue forever. The only thing you'd presumably be able to affect would be the contents of your mind/memory, meaning that eventually you're going to hit a stable loop and just start repeating a sequence of days. (The most likely scenario being that you descend into brain death and spend eternity as a drooling husk.)
  ```

- u/yewchung:
  ```
  The first thing I'd do is figure out exactly how brains work, however many loops that takes. Then, I'd start optimizing.

  First, I'd figure out some way to speed up my brain. Then, I'd find some way to create a body (or VR program) that can respond and move at a similar speed, and transplant my brain into it. Then, I'd keep repeating this process until the rate at which my brain time is multiplying exceeds the rate at which I am running out of time. This may take more than one loop.

  Then, I'd start operating the same procedure on everyone else. Thus, I have created infinite brain time for everyone in a finite time, and the Singularity.

  In the event that I reach a point where my brain will no longer speed up, I hope to be at a point where I can encode the memories of as many people as possible into the strings of my brain, then carry them and replace them next loop. This problem shouldn't be that bad, since there will probably be several thousand/billion subjective years between resets.
  ```

---

