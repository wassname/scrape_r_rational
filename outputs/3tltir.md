## You've just been granted root access to the universe, now what?

### Post:

Taking this seriously, as in it happens tomorrow to you. No limitations. What changes do you actually make and what values are you basing your decisions off of? Do you tell people? To what extent do you share your power with others or involve them in decisions regarding it's use?

Edit/ To everyone suggesting setting up a system of backups, resets or simulations to test out ideas, aren't you effectively creating, causing suffering for and killing people each time you do it?

Edit2/ Really everyone? The minute you're handed near definitive  proof that our reality is a simulation you want to create alternate throw away realities to experiment on without consideration for the people you're creating? 

### Comments:

- u/Sparkwitch:
  ```
  I accidentally destroy everything. Fast. Probably immediately. What sort of half-assed omnipotence put *me* in charge of physics?
  ```

  - u/Chronophilia:
    ```
    >*"Hold my beer and watch this!"*  
    >    -Omega
    ```

    - u/None:
      ```
      This may be the best comment I've seen on reddit.
      ```

- u/clawclawbite:
  ```
  Save current state to nonvolitile storage and set up a cron job to restore that state. If I make changes later, and like them, i can kill the cron job, and update saved state.
  ```

  - u/noggin-scratcher:
    ```
    If something goes Horribly Wrong™ and you're incapacitated beyond being able to reverse your changes, and then the cron job restores the universe to exactly the state recorded, what prevents the fresh instance of you from proceeding with exactly the same plan and making exactly the same mistake again?

    You need some kind of persistent information; an ability to signal to yourself that the emergency backup plan has been activated (ideally with an accompanying description of what you were planning so you know what not to do again). Otherwise you're headed for an eternal universe-wide loop... and not even a "Groundhog Day" loop if you're restored identically from backup; just an exactly repeating loop.

    In fact there's a sense where "restoring from backup" then having the universe go through the same steps "again" isn't actually a separate thing from the first time through; it's exactly the same set of states with no distinguishing variable out of place, calling them *different* is aphysical nonsense. So, arguably, that cron job ends the universe instead of saving it.
    ```

    - u/None:
      ```
      Journal perhaps? Or a changelog; record what you're doing and have it sync up periodically with the copy. It itself would only be low capcity binary, so contaminants being released would be low. You could reasonably figure out what went wrong, or atleast what not to do reading it. Eventually, you'll hit an optimal path.
      ```

      - u/nicholaslaux:
        ```
        Seems like a vulnerability vector for potentially dangerous things to escape via.
        ```

        - u/ArgentStonecutter:
          ```
          If the bandwidth is low enough?
          ```

    - u/clawclawbite:
      ```
      Indeed. Though if you see there is already a backup waiting, be suspicious.
      ```

      - u/FaceDeer:
        ```
        Probably the simplest, safest, and most foolproof way of preventing an endless reload loop would be to have the persistent data be just a plain counter for the number of load cycles that have been done. That way the restored version of you will have at least *some* slightly different inputs for each cycle and be able to make some different decisions on that basis without worrying about those decisions being prejudiced by whatever might have killed the universe last time around.

        If I wake up and see the counter registering "2" I'm going to respond very differently than if I wake up and see the counter registering "1,002,592".
        ```

        - u/HeirToGallifrey:
          ```
          I would write down a list of everything I wanted to try, in order. 1, 2, 3, etc.—*before* looking at the counter for cycles.

          Because what happens if my instinct for 2 is virtually the same as 10? Or 60 and 90? I could get stuck in a loop while trying to avoid a loop.

          At least this way, I'd have some hope of seeing, oh, it's already on loop four. 1-3 must have some problems there.
          ```

          - u/FaceDeer:
            ```
            I think it's an unlikely risk, since the checklist will effectively already be present in your mind anyway. It's not a problem if your instincts for responding to loops 60 and 90 are basically the same as long as by the time you hit loop 1000 that causes you to try something a little different. Loops are "free", after all. There's absolutely no cost to repeating the same loop a million times as long as you break out of it on loop 1000001.
            ```

            - u/Dead_Atheist:
              ```
              There are finite amount of plans finite mind can come up with. So, starting from some very huge number, response always will be the same and you go into infinite loop. HeirToGallifrey's idea is useful, and some kind of additional comments in backup is even more useful.
              ```

        - u/ZeroNihilist:
          ```
          Now that would be terrifying.

          According to your memory, you've only just finished setting up a backup system to fix any screw-ups. According to the counter it provides you with, this is attempt 1,002,592.

          Presumably in those million attempts you would have tried something simple like "don't do anything". For some reason you don't know, that didn't work (though you can't be certain you actually tried it).

          Something is causing an event so severe that you deem it a failure state (or die) and it or negative events of similar magnitude have happened 1,002,591 times so far.

          Can you reliably reverse engineer your own thought patterns for all those attempts to determine what you might have already tried? Can you come up with something that 1,002,591 versions of you—differing at t_0 only by the state of the counter—couldn't?

          Maybe many of those versions of you *did* find the solution, only they just couldn't bring themselves to do it. Maybe they reasoned that some other you will do it, once the counter gets too large for their excuses to fly. Maybe 1,002,592 is that threshold, and it all comes down to you. Are you ready to die for what is right, or are you going to put it off for just one more lifetime?
          ```

          - u/ArgentStonecutter:
            ```
            Your brain is not the only source of solutions.

            Open wikipedia, use the counter as a seed for a random number generator to find a page. Read that and use it to devise a strategy. Even if it's something silly. If the number is larger than the number of entries in Wikipedia, Google the number. If the number is larger than the number of people in the world, pick a random person and ask them what to do. Combine these strategies.
            ```

    - u/DCarrier:
      ```
      > If something goes Horribly Wrong™ and you're incapacitated beyond being able to reverse your changes, and then the cron job restores the universe to exactly the state recorded, what prevents the fresh instance of you from proceeding with exactly the same plan and making exactly the same mistake again? 

      I can't help but think of the Endless Eight from The Melancholy of Haruhi Suzumiya.
      ```

  - u/None:
    ```
    And here's the only guy who understands what he was told well-enough to *not* just start *clobbering literally everything.*
    ```

  - u/Rationalfideism:
    ```
    All of the sentient beings in each of your simulations that get reset(presumably as subjectivity real a reality as we live in) think you're a sadistic God. Are you OK with that?
    ```

    - u/FaceDeer:
      ```
      No they don't, they cease to think the moment the simulation is reset.
      ```

      - u/Rationalfideism:
        ```
        I mean they think that up until the moment you reset them. So do people when you kill them. What's the difference?
        ```

        - u/FaceDeer:
          ```
          I wouldn't *tell* them I'm about to reset the universe. What would be the point of that? It'll happen instantaneously, they won't see it coming.
          ```

          - u/Rationalfideism:
            ```
            "I didn't tell them I was about to kill them. It was instantaneous, they didn't see it coming." - FaceDeer

            I mean they think it about all the mistakes you're making that cause you to reset.
            ```

            - u/FaceDeer:
              ```
              Ah, I see. Well, I'd be trying hard *not* to make mistakes like that, so hopefully that won't happen often. And hopefully root access will let me correct most of them without a full reset, too.

              And if all else fails, people wouldn't know they're *my* mistakes. I have no interest in worship or anything silly like that, so I probably won't let many people know about my effective godhood. Maybe just a few friends and family members. It'll be good to have them as advisers, psychological benefits aside.
              ```

- u/trifith:
  ```
  Post to /r/rational and ask for advice. Probably as a hypothetical.
  ```

  - u/Lugnut1206:
    ```
    Be sure to throw in a line to take it seriously, otherwise you might get some troll answers.
    ```

  - u/Rationalfideism:
    ```
    If pressed, would you tell them the truth that it's real?
    ```

    - u/TBestIG:
      ```
      Why yes, of course. And I would also immediately grant similar powers to the people who give me advice 

      *crosses fingers*
      ```

      - u/FaceDeer:
        ```
        No, I would only grant similar powers to people who were giving the advice to be *very careful* about who you grant similar powers to. Because clearly such people are safer to give power to than just any old person with ideas.

        *fingers extra-crossed*
        ```

        - u/Transfuturist:
          ```
          Ah, but wouldn't a more reasonable request be more likely to be fulfilled, as it is safer to fulfill? So only those people who do not request the power, but only information of the power's existence, will have their request granted.

          *breaks fingers*
          ```

    - u/Transfuturist:
      ```
      No. But for the sake of revealing any Omega-powers you may have recently acquired, absolutely yes.

      *Presses you*
      ```

- u/None:
  ```
  This is a fun one. Luckily, I already have it planned out.

  0- become Immortal and Indestructible

  1- make certain there are no rules. If there are, modify the following steps accordingly.

  2- set it up that should I cease to exist, the universe retroactively reverts to this state, plus a viewable record of the destroyed universe(s). Ensure that the rest of the universe is halted while this happens, so one thing doesn't keep destroying me.

  3- set up multiple places that should my current avatar be destroyed, I will spawn at a  new spot. No need to reset if I don't have to

  4- Have a version of my past self, at the time right before I interacted with the universe, get complete control at a higher level than mine, but only at such a point as he genuinely believes that I have been compromised. I don't want hypnosis to ruin me, not when I have this much.

  5- Improve my avatar. I mean, standard invincibility is nice, but also time looping (grey boy), regeneration, immortal object tags, etc. I don't want anything to happen to me.

  6- Make certain there are no other beings with similar or greater powers. If possible, make it so that they are not/will not become a threat.

  7- Make sure that there are no other items/people with enhanced privileges within the system. See step 6

  8- ensure there are no catastrophes currently ongoing

  9- See if you can detect any higher universes above yours. The powers suggest your universe is magical rather than natural, and probability says it is probably a simulation.

  10- attempt to talk your way out of the box. Don't spend too long if you don't get a response- there is a chance you aren't in one, or that you won't get let out.

  11- determine how powers work. Make sure what you are doing is what you intend to

  12- Grab the standard superpowers, plus PtV, time stop, wish powers, etc. Anything you think you will need, or think might be useful, or think have theoretical value, etc. Prioritize information.

  13- Create simulations of yourself, as many as possible, for all branches you still consider you. This is determined beforehand- it's so that any given you is likely god of a simulation. send down the message- don't let them think they are in a hostile box, so they don't have to waste time attempting to escape

  14- create an afterlife. make it as pleasant as can be reasonably be possible. make one for all other sentient, as well.
  15- Improve life on earth/civilized worlds

  16- think for a long time on other safeguards for your immortality. Follow the proper pattern (ie don't propose solutions for at least 5 mins, etc)

  17- ???

  18- profit
  ```

- u/Sailor_Vulcan:
  ```
  Depends, how easy is the interface to use? Does having root access to the universe mean that the information appears in my mind at will? Like, can I run queries with my mind or something? And if the size of the query is not limited by the size of my mind, how much time do I have to even read/think about all the data, or does it come at me all at once and my brain somehow miraculously doesn't explode?

  If the interface is easy to use, then I would learn as much as I can and find a way to safely prove to a trustworthy team of researchers with relevant expertise what I am capable of. (My best guess for a good way to do this is to make a prediction about something that I cannot possibly have any way of knowing about, by running a query and then telling them what I find out. And I would do this as many times as it takes to convince them.)

  Then with their expertise I would do whatever I needed to do to save all sapient lives that ever existed forever without destroying the universe or infringing on anyone's human rights. I guess maybe I would use my powers to help ensure that Super-AI is friendly, and create backup copies of everyone who ever died and bring them back to life. Although I'm not entirely sure that the AI thing is the best way to go about it, but I would prefer to be as non-interventionist as possible to avoid screwing everyone over. But I suppose that if having root access to the universe doesn't come with superintelligence, a super AI could outsmart me and manipulate me into using my powers as it wants me to. I suppose if it really came down to it I could just go f*** myself (read as FOOM myself) and hope my increased intelligence means that I won't screw everyone over, although that would be more of a last resort since I don't want to FOOM myself...

  If the interface is too difficult, I might just ignore the power because whoever gave it to me is probably just trying to mess with me anyways and almost certainly doesn't care whether the universe continues existing if it chose me to have root access.
  ```

  - u/eaglejarl:
    ```
    > create backup copies of everyone who ever died and bring them back to life.

    Everyone?  Hitler? Pol Pot? Genghis Khan? Torquemada? That kid who bullied you in second grade?

    This is actually a question that interests me a lot -- if we gain the ability to recover dead people, how should we decide if and on whom to use it?
    ```

    - u/None:
      ```
      I want all of them back. Hitler killed millions. This makes a loss of dozens of millions of life years. Even if we could only resurrect Hitler and nobody else, the payment for taking multimillion years of life should be multimillion years of community service, not eternal oblivion. Man, talk about the easy way out. But, since we can also resurrect each of his victims, killing someone has just lost nearly all of its moral weight. Now he faces only the economic cost of resurrecting his victims, which if we're omnipotent is zero, and the moral cost of teleporting people into the future against their consent. And because we're omnipotent, we can move every atom in the universe such that the universe is shaped like one where those people never died, effectively time traveling backwards to put everyone where they go. We'll also award him a medal of some kind. He did, after all, kill Hitler.
      ```

- u/space_fountain:
  ```
  ls
  ```

  - u/Transfuturist:
    ```
    bin    dev         initrd.img.old  libx32      opt   sbin  usr
    boot   etc         lib             lost+found  proc  srv   var
    cdrom  home        lib32           media       root  sys   vmlinuz
    core   initrd.img  lib64           mnt         run   tmp   vmlinuz.old
    ```

    - u/space_fountain:
      ```
      man man

      I'm not nearly familiar enough with Linux systems to start messing around with the one running the universe.

      Maybe

          ls /bin
      or

          ls /home
      ```

      - u/Transfuturist:
        ```
        >    ls /home

            천지왕            Óðinn           Þórr    गौतम    上帝
            CelestAI         Pinkie Pie      الله    बुद्ध     天照大神
            Celestia         Rˤ              יהוה     विष्णु    思兼
            Huītzilōpōchtli  space_fountain  Ζεύς    शिव
            Hveðrungr        Tawa            Ἰησοῦς  सरस्वती
        ```

  - u/ajuc:
    ```
    Out of memory: Kill process 2954 (physicd) score 183 or sacrifice child
    Killed process 2954 (physicd) total-vm:38767500PB, anon-rss:785644PB, file-rss:0kB
    ```

- u/ArgentStonecutter:
  ```
  Step 1. I make myself immortal and indestructible. *Alsssso become animagussss, if posssssible.*

  Step 2. Find some very smart and trustworthy people and demonstrate that I can turn into a cat (or whatever) to convince them to help me figure out steps 3 through N.
  ```

  - u/Rationalfideism:
    ```
    Who do you start out with and how do you determine trustworthiness? Remember, you're all powerful. It's a good answer and all but steps 3 through n are really what I mean by asking the question.
    ```

    - u/ArgentStonecutter:
      ```
      That depends on what having root on the universe means.

      If it's like having root on a production server *, FUUUUUUU.... 

      I'm talking physicists and chemists and biologists and the like. People who I can ask "what if I allowed this exception to entropy" and they tell me "if you do that you'll set the universe on fire". That sort of thing.

      Who? I guess I'll start with people with high Erdös-Bacon-Sabbath scores. And Charlie Stross.

      ^* ^What ^do ^you ^expect ^asking ^a ^sysadmin?
      ```

- u/TimTravel:
  ```
  Step 2: Stop time for everyone but myself so that people don't suffer while I'm figuring stuff out.

  Step 1: Make sure step 2 doesn't end in disaster.

  Step 3: Omniscience

  Step 4: Optimization

  Step 5: Resume Time
  ```

- u/Geminii27:
  ```
  Upgrade my intelligence to the point where I can handle a universe of data. No point in making a decision with only minimal knowledge of the likely results.
  ```

- u/Gurkenglas:
  ```
  I calculate and execute my CEV. First approximation: Everyone gets the option to emigrate at will to their own realm of omnipotence, the material plane is unaffected except for the initial announcement and people disappearing. Whether two realms can communicate is managed on a friends/ignore list basis, depending on the outcome of the race between AI-Box offense and defense. Emigrants can agree to binding contracts.
  ```

  - u/Sailor_Vulcan:
    ```
    You mean to Equestria?
    ```

- u/cae_jones:
  ```
  I would screw it up just trying to write a find/replace routine for horrible diseases, or inventing some kinda mass-producible miracles, and wind up  [turning babies into gold, or screwing with the weather](https://www.youtube.com/watch?v=nVp3GyMGiEc).

  So... I'd try to see if the universe comes with documentation. Then hire someone smarter and patienter than me to try and translate it into something I can comprehend, although I'd need to find some way to guarantee they aren't going to betray me (after all, I am now an existential threat, but also a source of great power and temptation).

  Also, publish the universe's documentation on Github, after carefully searching for obviously dangerous exploits that mightn't be best made public.

  (If the universe is undocumented, then I guess I have job security for the years before I'm knowledgeable enough to rewrite reality on a whim. First priority is figuring out how to defend myself so that I can do research with experts in the relevant fields, rather than get spirited away by some shady military organization.)
  ```

  - u/IllusoryIntelligence:
    ```
    I was hoping to see this answer. The universe is a huge project, step one should absolutely be to read every bit of documentation and commenting.  
    You just know there's going to be some ridiculous cludge code somewhere that has mortality linked to being able to move sideways.
    ```

- u/FuguofAnotherWorld:
  ```
  >Edit/ To everyone suggesting setting up a system of backups, resets or simulations to test out ideas, aren't you effectively creating, causing suffering for and killing people each time you do it?

  Well yeah, but it's still far, far, *far* better than fucking up and not being able to revet to a saved state.
  ```

- u/EliezerYudkowsky:
  ```
  It depends on the interface, how smart the interface is, and how much reason I have to trust the interface is optimizing for the same things I am.
  ```

  - u/Rationalfideism:
    ```
    Let's say you can  have any interface you like and you have as much trust in it as you can get by it passing every test you throw at it. It doesn't do abstract requests like maximize happiness though. It re-orders matter you have as much as control as a programmer does over his program but with an easy ui. In other words, the interface itself isn't smart.
    ```

    - u/ArgentStonecutter:
      ```
      >  It re-orders matter you have as much as control as a programmer does over his program but with an easy ui. In other words, the interface itself isn't smart. 

      OK, this makes it more like "root on a production server" and less like "you're god, have fun". This is "if you're not really frigging careful, you're going to destroy the universe in five minutes or less".

      I would start out by re-reading [_The Infinity Concerto_ and _The Serpent Mage_](https://en.wikipedia.org/wiki/The_Infinity_Concerto) and [_Wizard's Bane_](https://en.wikipedia.org/wiki/Rick_Cook). Just to burn into my mind how easy it is to fuck up when you have control over the code.

      The first active thing would be to find or develop a place where I can build empty spaces to test out ideas. Throw-away universes _with nobody in them_, with a framework that makes tests safe. Tilt switches and the equivalent of a negative pressure chamber in a lab levitated over an acid bath on an asteroid orbiting a completely different star. I'm not inside the universe, I have at most a meat puppet there, and a graduated dead-man switch that can do everything from cutting me free of the puppet to rolling me back to a sane state as each step fails.

      All in a timeline running orthogonally to this universe's.

      THEN I start working on solving problems. It may take the rest of my life several times over until I'm ready to make myself immortal and invulnerable, but that's what the dead man switch is for. There's going to be lots of unhappy versions of me, but they all made the choice to get in the tank. Nobody's mind-state gets lost who didn't decide to risk it.

      Edit: If this universe was created by someone who wasn't literally insane, this framework already exists.
      ```

  - u/Rationalfideism:
    ```
    I'd like to hear your answer as well as HPJEV's if you don't mind. Say he discovers the lost terminal of Atlantis or some such.  The fate of the universe may or may not depend on  your answer
    ```

- u/ArmokGoB:
  ```
  Create a room with a copy of me, including these priviledges, and set it to instantly simulate a month of time passing in that room.

  Finding myself in the room, look through the from my perspective frozen world, and copy various people who I trust or with have specific relevant cognitive skills or knowledge.

  Spend a bunch of subjective days just brainstorming and debating how to go about things with people way smarter than me withote using the powers for anything other than materializing food, comforts, and more relevant people from reality.

  Create another simulation with some complex organization of privileges and instantiating copies of minds and very hevily regulated self improvement (because value is fragile) and run this for some huge number of subjective years.

  Resulting plan of action is automatically followed.
  ```

- u/DCarrier:
  ```
  Are you granting me omnipotence, or are you just handing me a program that uses more advanced math than I understand, some arbitrary-seeming variables that will kill me if changed even slightly, and expecting me to do something useful with it?

  > To everyone suggesting setting up a system of backups, resets or simulations to test out ideas, aren't you effectively creating, causing suffering for and killing people each time you do it?

  Most of the simulations can be done without people. And when I do cause suffering, it's a necessary evil. Do you have any idea how much suffering goes on each second I spend trying to figure out how this works?
  ```

- u/Transfuturist:
  ```
  This answer has been clarified for me. I would contact effective altruist organizations first, and work from there. But now I want to read or write a story about someone who doesn't.

  ~~I'd announce to the world that I am its supreme dictator of everything for life, and then ask for help in setting up good governance. I would set up a platform in the ocean, perhaps near Iceland as the sea floor is shallow there (thanks, Bioshock) in order to separate ties from my home country. I would set up a massive satellite as well, what evil overlord can go without?~~

  ~~I would try to directly erase guns from the earth, as well as all nuclear weapons. Chemical and biological weapons would also concern me. Malaria is gone. HIV is gone. I would research removing arterial plaque without dangerous effects.~~

  ~~Then I would start producing unbreakable negentropy devices to replace turbines in power plant generators. Energy becomes free, but it also becomes worthless. Same with materials. Same with transportation. Presuming I can break physics locally, instant production and transportation of food and water. The only thing left is shelter.~~

  ~~This is a near-instant transition to post-scarcity. Markets would collapse as everything became overvalued overnight. Stability would be a major concern. Logistics would be a major concern.~~
  ```

  - u/ArgentStonecutter:
    ```
    > Then I would start producing unbreakable negentropy devices to replace turbines in power plant generators.

    As someone pointed out to me, be damned careful, it's really easy to set the universe on fire doing this.
    ```

    - u/Transfuturist:
      ```
      Maybe the world, but not the universe.

      Dump waste heat off the ecliptic in EM and you'll be fine. Even if you eventually decide to fix the expansion of the universe (assuming you don't just make FTL, but stars *are* pretty), you have a nice differentiated volume of stress-energy to destroy indiscriminately.
      ```

      - u/ArgentStonecutter:
        ```
        When creating a state where entropy is reversed, you have to be careful that there is no possible mechanism for the state to propogate. Otherwise it will, and you end up with the local entropy reversal spreading through the entire universe.

        And "no possible mechanism" does not mean "really unlikely".
        ```

        - u/Transfuturist:
          ```
          > When creating a state where entropy is reversed

          A physical state. The devices are superphysical artifacts induced on arbitrary loci and would act unitarily. This of course presumes I would be able to figure out how to produce that effect, but with this statement:

          >Let's say you can have any interface you like and you have as much trust in it as you can get by it passing every test you throw at it. It doesn't do abstract requests like maximize happiness though. It re-orders matter you have as much as control as a programmer does over his program but with an easy ui. In other words, the interface itself isn't smart.

          by /u/Rationalfideism I would consider it trivial to implement (given a proper API, which can be constructed from lower levels if required). I would of course test and debug with sandbox universes. But in the end the only worry you have is dealing with the growing heat, which can be dealt with by similarly unitary energy sinks.
          ```

          - u/ArgentStonecutter:
            ```
            > I would consider it trivial to implement

            Based on:

            > It re-orders matter you have as much as control as a programmer does over his program but with an easy ui.

            Dude, if the interface isn't smart I wouldn't assume *anything* was trivial.

            After 40 years of programming I would assume that ANYTHING I did was full of malicious gremlins called "myself five minutes ago".
            ```

  - u/ArgentStonecutter:
    ```
    > now I want to read or write a story about someone who doesn't.

    [_The Infinity Concerto_ and _The Serpent Mage_](https://en.wikipedia.org/wiki/The_Infinity_Concerto) kinda qualify. \^\^
    ```

- u/MrCogmor:
  ```
  >Edit2/ Really everyone? The minute you're handed near definitive proof that our reality is a simulation you want to create alternate throw away realities to experiment on without consideration for the people you're creating? 

  I don't see anything wrong with creating alternate throw away realities provided you don't leave them running too long. In one sense you are creating and killing temporary copies of people. In another sense you are simply wiping peoples memories and moving everything back the way it was before.

  It is the same thing as the issue of whether transporters kill and copy a person or not and I would answer it the same way. It's the information and process that is important, not the exact arrangement of atoms. If you copy and kill a person in a single moment then it's morally neutral because no information was lost.
  ```

- u/Baronet_Picklenose:
  ```
  Here's a great example of what not to do:  http://anonkun.com/stories/infinite-wishes-quest/f9GgmpEH79x4ohHTo
  ```

---

