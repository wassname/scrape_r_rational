## How would you prevent a Gray Goo crisis?

### Post:

What kind of safeguards would you put into self replicating nano machines to prevent a Gray Goo crisis?

Ideas so far:

1) Make the nanobots require exotic material (ex: Technetium) to create other nanobots.

2) Program an automatic shut down in response to a predetermined signal.

3) Standardize the set of commands to run the nanobots.

4) Program nanobots to avoid self-modification.

5) Program nanobots to prefer consuming each other once a certain 'population' marker is reached.

6) Program nanobots to prefer to consume mutated nanobots.

7) Encrypt the nanobots' code so mutations of it result in gibberish.

8) Program the nanobots to require an ATP equivalent without them having mitochondria equivalent.

9) Make them edible by existing organic organisms and inherently unable to survive acidic environments.

10) Require each nanobot to have a unique IPv4/6 address. 

11) Program nanobots to constantly broadcast a signal which tells other nanobots to reproduce. If a nanobot does not receive this signal in a certain amount of time, they self destruct.

12) At random, a small fraction of nanobots emit signals that are transmitted across the colony. Transmition requires energy that could be used for replication, slowing growth. The signals are designed so they can pass through layers of nanobots, but rapidly drop off in power as they do so. Receiving a weakened signal primes the nanobots to cannibalize their neighbors in the direction of the signal's source, and receiving a full strength version of the signal cancels this command. If a nanite only detects the weakened form of the signal, this indicates that one of its neighbors one layer up has failed to transmit, causing it to be cannibalized. The more nanobots are in a colony, the more of these signals are being transmitted, causing the replication rate to drop and policing of non-transmitting mutants to increase.

13) Program nanobots to emit a signal when they properly shut down which overwrites the code of any nearby nanobots to shut them down immediately.

14) Program nanobots not to interact with a certain material and use that material as a case for any nanobot based device.

15) Design nanobots to be flammable.

16) Design nanobots to only work at cryogenic temperatures.

17) Design nanobots to "run hot". 

### Comments:

- u/faul_sname:
  ```
  Make them require several atoms of Technetium per nanobot. It's cheap, and not found in nature, so growing more is easy and limiting growth is as simple as cutting of the Technetium supply.

  You'd want to make sure that the function of these nanobots relied on some property unique to Technetium, of course -- the [binary metal oxide it forms](http://en.wikipedia.org/wiki/Technetium\(VII\)_oxide) would probably give the central Oxygen some fairly unique properties (180 degree bond angle), so that might work. 

  Edit: formatting
  ```

  - u/sephlington:
    ```
    You need to put a "\" in between the VII and the close parenthesis, so the markdown doesn't think you're closing the link there. Like:(http://en.wikipedia.org/wiki/Technetium(VII\)_oxide)
    ```

  - u/scruiser:
    ```
    You are missing a parenthesis on your link, of rather, I think the markdown code is having problems with the parenthesis inside of the link.
    ```

- u/Sceptically:
  ```
  Colour them pink instead of gray?
  ```

  - u/None:
    ```
    Problem solved!
    ```

- u/xamueljones:
  ```
  1) Have it automatically shut-down in response to a pre-determined signal as a last resort. It'd be hard to keep some criminal from potentially hacking it, but that's what the field of cryptography is for.

  2) Standardize the set of programs/commands to run the nano-machines such as 'Break down 5 units' or 'Move 25 nanometers'. This way with a series of simple commands where no combinations of can lead to a run-away reaction, they can be limited. Don't allow a system where anyone can tell the nano-machines to do anything. If there needs to be a different command, then it goes through rigorous trials and testing. This is very limiting, but if nano-machines are powerful enough to cause a Grey Goo scenario, this is necessary.

  3) Don't allow them to be self-modifying.
  ```

  - u/nevinera:
    ```
    >Have it automatically shut-down in response to a pre-determined signal as a last resort.

    Have it automatically shut down if a pre-determined signal *stops* being supplied.
    ```

    - u/None:
      ```
      This actually makes the whole, "Mooks drop dead from lack of ontological inertia when the boss monster dies" thing in video games and movies make a whole lot more sense.
      ```

  - u/Turniper:
    ```
    This is a good start, but just looking at the problem from a standard software security perspective, there are several more obvious holes.  You would need to include a mechanism to prevent the modification of the command set, such as building the commands into the hardware itself.  Additionally, whatever mechanism is used to prevent self modification needs to be robust or intrinsic enough that one nano-bot cannot be easily modified by hand to modify others to circumvent this restriction.  On top of that, there would need to be some sort of major precautions against reverse engineering.

    Basically, all safeguards need to be implemented at such an absurdly low level that it would literally be easier to create gray goo from scratch than it would be to use your nanobots as a starting point.  Honestly though, the best solution is avoid self-replicating machines.  Factory setups avoid this whole risk, and it's not like we've ever felt the need to build self-replicating devices on a macro-scale.  Factory modules are easier from both an engineering and a security standpoint.
    ```

  - u/DCarrier:
    ```
    My version of 2: don't give them enough computational power to make self-replication possible. They are given a series of commands when they need to replicate. If whatever is sending the commands gets eaten, they'll stop.
    ```

- u/Farmerbob1:
  ```
  Make them irresistibly drawn to consuming each other once population density reaches a certain point.

  Create a requirement for esoteric materials that cannot be easily acquired.

  Give them an immune system response to any mutations so that anything created that is different from the others is destroyed/consumed by the normal ones.  For instance, units created without the esoteric materials mentioned above.

  Organic creatures are self-replicating machines.  Mimic nature.
  ```

- u/ArmokGoB:
  ```
  Don't design any digestion/respiration system, so they requires a continuous supply of chemical energy in a format they can't make themselves. Basically an ATP equivalent, and they don have mitochondria-equivalents.
  ```

- u/nevinera:
  ```
  Don't make self-replicating nano machines. I would go so far as to say that you should instead make trillions of policebots whose only function is to *destroy self-replicating nano machines*.
  ```

  - u/nevinera:
    ```
    Remember, the machines you make will exist in *massive* numbers. Machines in nature get damaged, altered, infected - like viruses or bacteria, you should *plan* for them to evolve their behavior toward maximum self-replication.

    The existential threat outweighs the efficiency gains you can achieve by making them make themselves.
    ```

- u/None:
  ```
  [Require each one to have a unique IPv4 address.](http://xkcd.com/865/)
  ```

- u/ArmokGoB:
  ```
  Make them edible by existing living organisms, and intrinsically incapable of surviving acidic conditions.
  ```

- u/Zeikos:
  ```
  Be carefull about possible incidents , make an abundant number of detector.

  Don't bother further , it's way more likely that the grey goo scenario comes from a person than from an accident. The person would make nanobots **with the purpose** to create grey goo , so the only truly "safe" way is using "police nanobots" , or using nanobots to alter the consciosness of every living human being to follow base ethics.
  ```

- u/DCarrier:
  ```
  Encrypt their code so that any mutations would result in gibberish.
  ```

- u/None:
  ```
  Mostly, [we don't have to](http://rationalwiki.org/wiki/Gray_goo).

  >Shockingly, the grey goo scenario has in fact happened in the past. A self-starting and self-replicating nanobot plague covered the Earth! This event is commonly refered to as "life." A later disaster befell most of the life when blue-green algae filled the air with oxygen; this is known as the Great Oxygenation Event[wp].
  ```

  - u/None:
    ```
    I don't understand. Self-replicating atoms happened once in the past and it worked out fine, so we don't need to worry about any other kinds of self-replicating atoms in the future? I don't think that quite follows.
    ```

    - u/None:
      ```
      It means most of the ecological niches with "desirable" thermodynamic and material properties are already taken, and it's hard for *very simple* self-replicators to take over the world *again* because the world got very, very complicated.
      ```

      - u/None:
        ```
        I suppose that argument is sufficient when talking about naturally occurring self-replicators, but I thought it was somewhat obvious that intentional human design represents an entirely different sphere of concern. Explosions can occur naturally on Earth, but nuclear weapons still represent a significant issue. That sort of thing.
        ```

        - u/None:
          ```
          > I thought it was somewhat obvious that intentional human design represents an entirely different sphere of concern.

          Intentional human designs still have to actually out-compete naturally evolved organisms for energy and materials.  You would need a whole *ecosystem* of designed "goo", that wouldn't always work together properly, which would be subject to evolutionary pressures and would exert evolutionary pressures on regular life to adapt and compete... and at that point you've basically just recreated regular, old life.

          I mean, hey, go read the link about how Eric Drexler, Mr. Nanotechnology Will Totally Work Real Soon Now, now thinks gray goo wouldn't work.
          ```

          - u/scruiser:
            ```
            > out-compete naturally evolved organisms for energy and materials. 

            If the design is able to take advantage of properties or mechanisms that evolution didn't have a gradual path to evolve towards, then it could out-compete existing life.  Hmmm... I can't think of any obvious and plausible examples.  For an implausible example... biological cold fusion for energy would allow artificial organism to out-compete existing life.  

            If the design is able to take advantage of resources or materials that weren't common in the evolutionary environment but are common in the modern world, it could out compete existing life.  For example, if you had nanomachines colonies designed to draw from energy from electrical sources, you could get grey goo that siphons energy from power lines, as that is a niche that didn't originally exist for life to evolve to take advantage of.  I think consuming oil for energy is another big one.  Metals in refined forms (i.e. non-oxidized) are also pretty uncommon in nature... Artificial bacteria that consume iron and leaves rust could be pretty destructive.  Same thing for plastics.  None of these are quite in the destroy the world overnight category, but they could cause economic losses that would be significantly disruptive.
            ```

- u/chaosmosis:
  ```
  I initially interpreted this title as asking what we'd do to deal with a Gray Goo crisis if the flawed nanobots had already been built. Does anyone have ideas about what someone might do in that situation? The best idea I can think of is to evacuate the planet.
  ```

  - u/Chronophilia:
    ```
    Build a second grey goo entity with better safeguards and have it eat the first one.

    More generally, it depends on whether the goo has any exploitable weaknesses. If it was released by accident, it won't be perfect, so there's bound to be something we can use against it. Nuke it for the EMP and the radiation. Contaminate its food supply with chemicals similar to what it normally eats, but different enough to fatally damage any replicators built out of them. Move to a different continent and hope it can't cross the Atlantic.
    ```

  - u/BadGoyWithAGun:
    ```
    Depends on the scale of the outbreak, and the construction of the machines themselves. It stands to reason they wouldn't be able to survive all of burning, acid, oxygen deprivation, exposure to high doses of ionising radiation, etc. Find out which it is and drown the outbreak area with appropriate substances.
    ```

  - u/Galap:
    ```
    Heat. Matter can only have a chemical existence up to a certain temperature, and that temperature isn't very hot. A moat of lava would be sufficient to keep nanomachines from creeping in over the ground.
    ```

---

