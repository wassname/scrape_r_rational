## [Biweekly Challenge] Immortality

### Post:

## Last Time

[Last time,](https://www.reddit.com/r/rational/comments/3yuejk/biweekly_challenge_paperclipper/?sort=confidence) the prompt was "Paperclipper". /u/ZeroNihilist is the winner with their story [Satisfaction](https://www.reddit.com/r/rational/comments/3yuejk/biweekly_challenge_paperclipper/cyj6t42), edging out a close field (close enough that reddit's imprecise vote totals made me refresh the page three times to be sure). Congratulations /u/ZeroNihilist! You are now tied with /u/Kishoto for most all-time wins!

##### This Time

the challenge will be "Immortality", one of the transhumanist goals and also one of those things that popular media tends to frown upon. It's a wide open field that ranges from Dorian Grey to the Fountain of Youth, emulated minds on fully redundant systems to angsty vampires. Remember, prompts are to inspire, not to limit.

The winner will be decided **Wednesday, January 27th.** You have until then to post your reply and start accumulating upvotes. It is strongly suggested that you get your entry in as quickly as possible once this thread goes up; this is part of the reason that prompts are given in advance. Like reading? It's suggested that you come back to the thread after a few days have passed to see what's popped up. The reddit "save" button is handy for this.

##### Rules

* 300 word minimum, no maximum. Post as a link to Google Docs, pastebin, Dropbox, etc. **This is mandatory.**

* No plagiarism, but you're welcome to recycle and revamp your own ideas you've used in the past.

* Think before you downvote.

* Winner will be determined by "best" sorting.

* Winner gets reddit gold, special winner flair, and bragging rights.

* All top-level replies to this thread should be submissions. Non-submissions (including questions, comments, etc.) belong in the companion thread, and will be aggressively removed from here.

* Top-level replies must be a link to Google Docs, a PDF, your personal website, etc. It is suggested that you include a word count and a title when you're linking to somewhere else.

* In the interest of keeping the playing field level, please refrain from cross-posting to other places until after the winner has been decided.

* No idea what rational fiction is? [Read the wiki!](http://www.reddit.com/r/rational/wiki/index)

##### Meta

If you think you have a good prompt for a challenge, [add it to the list](https://docs.google.com/spreadsheets/d/1B6HaZc8FYkr6l6Q4cwBc9_-Yq1g0f_HmdHK5L1tbEbA/edit?usp=sharing) (remember that [a good prompt is not a recipe](http://www.reddit.com/r/WritingPrompts/wiki/prompts?src=RECIPE)). Also, if you want a quick index of past challenges, I've [posted them on the wiki](https://www.reddit.com/r/rational/wiki/weeklychallenge).

##### Next Time

Next time, by special request (and in honor of the new movie coming out) the challenge theme will be "Star Wars". It's your choice of Light Side or Dark Side, original trilogy or Old Republic era, Jabba or Jar-Jar. Please use spoiler tags appropriately, especially if you're using anything from the newest movie.

**Next challenge's thread will go up on 1/27.** Please private message me with any questions or comments, as the beloved meta thread is now archived. [The companion thread](https://www.reddit.com/r/rational/comments/40uy7j/challenge_companion_immortality/) is also open for any discussion of other works or this week's theme.

### Comments:

- u/eniteris:
  ```
  [The Immortality of Anthony Weever](http://eniteris.com/immortal)

  2777 words
  ```

  - u/gabbalis:
    ```
    >"Thanks. I'll keep in touch."

    >I haven't seen him since.

    Dammit Anthony!
    ```

  - u/Chronophilia:
    ```
    > "Let me ask you a question. How many neurons are there in the human brain?"
    > 
    > "Uhh. Ten billion?"
    > 
    > "Close. Eighty-six billion, but let's round that to a hundred. Ten to the eleven. And how many different ways are there to network those neurons?"
    > 
    > My head began to spin. "I have no fucking idea. Wait, it's a graph problem, right? A hundred billion nodes, and each node can connect to any other. So for every pair of nodes, you have two possibilities, so it's...two to the power of a hundred billion choose two?"
    > 
    > "Yup. About two to the two-hundred ten. And that's what's stored on there."

    You've dropped an exponent somewhere. A hundred billion nodes, 10^(11). Square that for the number of connections - so, 10^22 connections. And each one can be on or off, so we need 10^22 bits *to store a single brain*.

    Storing every possible and impossible brain is actually closer to 2^10^22 bits.
    ```

    - u/eniteris:
      ```
      I've royally messed up my power rules. It's 2^[10^(22)], not (2^(10))^22.

      Actual calculations show you need 10^20 yottabytes, or about a googlol^4 bytes.

      Not like I was going into the implications of cheap memory storage anyways.
      ```

      - u/DCarrier:
        ```
        That method goes completely overboard though. You're not going to have each neuron connect to 50 billion others.
        ```

        - u/Chronophilia:
          ```
          It's an upper bound. The size of the human brain is probably somewhere between a terabyte and a petabyte, depending on how you estimate it.
          ```

          - u/DCarrier:
            ```
            > It's an upper bound.

            So is Graham's number. That doesn't make it relevant when talking about the actual value.
            ```

  - u/MultipartiteMind:
    ```
    [Thoughts/Questions:  ](#s "Connections aside, what about the connection strengths?  Levels of accounted-for complexity aside, a more pertinent question:  if every mind with any self-identification password (of any number of bits, subject to memorisation ability) can have that chunk of its connections replaced with a different chunk corresponding to any other password, then what meaning is there in checking a specific password?  Do graphs of minds with passwords only exist if those minds would have organically chosen that password themselves based on their previous experiences?")
    ```

    - u/eniteris:
      ```
      [Reply: ](#s "There are actually so many problems with my story; I'm not sure where to start.")

      [Neurons: ](#s "Connection strength is one thing, although I'm very unsure how that actually applies in biology, as all neurons have multiple inputs and a single output. Strength is probably related to internal state, as neurons can be sensitized/desensitized to various stimuli (number of receptors on the surface). Additionally, neurons have subclasses based off their neurotransmitter expressions (dopaminergic, etc.), so a lot of the internal information is lost, (internal states, information in transit, etc.). This model assumes that none of that matters, and we really don't know how much of it is necessary for consciousness.")

      [Passwords: ](#s "An earlier draft used to have a passphrase (easier to remember); even with 2^210 possibilities, that's about ten random English words. The password is a confirmation of experience; only those who experienced creating the password would have the correct password. After that it's just a crapshoot; the human has to match as much real world experience to the graph's memories to confirm that it's the right one.")

      [Other thoughts: ](#s "What else can you do with cheap storage with adequate read speed? A lot, actually. You make lookup tables for everything; encryption becomes a pain because there are rainbow tables for everything, I haven't thought of the full implications of zero-cost storage with low read/lower write speeds, but there's probably a few societal upheavals that I haven't thought up of. DNA storage is very low read/write speeds, but it's mostly being developed for archival purposes now.")
      ```

      - u/MultipartiteMind:
        ```
        (Each input synapse has its own strength, its own local receptor density, handling the 'weighting' of different inputs.)
        ```

      - u/philip1201:
        ```
        The password concept is fundamentally flawed. If it is randomly generated, then there will be brains in the collection for every single outcome of the random generation, because it contains all brains that ever could be. If it is not randomly generated, at best it's a stand-in for life experience questions, and at worst, it's dummy information because of human's inability to be random.

        To specify one exact brain among all possible brains, you need exactly the information the brain contains. Passwords replace some of that information, but say little or nothing about the part you care about. (What is said is, for example, 'chose to memorise an x length password').
        ```

- u/Sailor_Vulcan:
  ```
  This is the Origin Story of the World's Most Normal Superhero: YOU.

  [Twenty-Two](https://www.dropbox.com/s/2slwl064cbbpmx2/Twenty-Two%2C%20by%20Sailor_Vulcan.doc?dl=0 "Twenty-Two")

  1824 words

  I was inspired to write this after binge-reading "Strong Female Protagonist" for a few days. Enjoy!
  ```

- u/None:
  ```
  [deleted]
  ```

  - u/TennisMaster2:
    ```
    [Great pacing; really well done.](#s " I'm curious as to the general means by which she's approaching his resurrection.")
    ```

    - u/None:
      ```
      [deleted]
      ```

  - u/MultipartiteMind:
    ```
    Poignant!

    [Noticing confusion:  ](#s "Living-He said that automatons last longer with more memories because some of the source of magic is transferred along with memories; however, she said that she transferred memories without any of her source of magic.  If none of her source of magic was transferred, how is doll-he able to move at all?  More practically, is there anything stopping her from transferring lots of memories and magic from different wild animals into the same doll, until there's enough for it to not run down (and be a helper for her)?  (More so, why couldn't they do that for doll-her before living-he died so that she could reciprocate the ritual?)")
    ```

    - u/None:
      ```
      [deleted]
      ```

      - u/MultipartiteMind:
        ```
        [](#s " <nods> When thinking about it I noticed the phrasing 'source of' implying that one could have it without the source.  I wasn't sure at first which question you were going to answer, so I also played with concepts of different sources being incompatible, or conflicting memories unacceptably existentially diluting a person.")

        [](#s "Hmm.  If I understand correctly, then, he--brought to life as a rough simulacrum of someone with an incredibly strong drive to live and not die--can be prevented from dying through using human sources of magic (potentially just a little from many people, to avoid unconciousness) from residents of the now-nearby village, with the main obstacle being her fear of what he could potentially do in future.  I find myself curious about if he's going to have the chance to realise this before he dies, and if so what sort of conversation or actions are going to result.  (And, even if not him, potentially a later doll similar to him.)")
        ```

  - u/Revisional_Sin:
    ```
    That was incredible.
    ```

- u/Calamitizer:
  ```
  [Holes in Sheaves.](https://docs.google.com/document/d/19_KhQjt95s6OTOxFxXc-bqNRTfFHZ810SqbT09jjq3Q/edit)

  2048 words.

  TW: suicide.
  ```

  - u/Kishoto:
    ```
    This story confuses me a bit. I don't understand, how is our protagonist immortal? I get that he built some machine that would kill him rapidly. I just....don't really understand how his consciousness persisted. Scratch that, I understand very little. *Period*. Author, mind giving me an abbreviated, layman's version of what's going on? :P
    ```

    - u/electrace:
      ```
      Suppose you set up a device so that after a quantum event, there is a 1/2 chance of you being killed.

      In the multiple worlds interpretation, both (you being killed, and you not being killed) happen. 

      Then (the living you) runs the experiment again. The dead you does nothing... he's dead. After this experiment, two of y'all (that's the correct plural form of "you" right?) have died (the death from the first experiment, and the death from the second experiment). Only one out of the three of y'all have lived (the one who survived the first and second experiment).

      It continues from there.... Each time you run the experiment, there is another universe where you die, and another universe where you live. This happens *regardless of how many times you run the experiment.* So, even if you run it 1000 times, and your "probability of surviving" is only 1/2^1000 , you're still guaranteed to survive (as well as die a 1000 times in different universes).

      There will *always* be someone who survives the experiment, and from their perspective, they're un-killable. 

      It's like "The Prestige." Every time he makes a clone, he has an equal chance of being the drowning clone, or being the transported clone, but *there's always a transported clone who doesn't drown.* The transported clone *feels* like they're invincible (or really lucky), but there was no other option. Their existence was inevitable.
      ```

- u/hoja_nasredin:
  ```
  [Beautiful Oasis](http://pastebin.com/44M5Bh3d)


  666 words
  ```

- u/jkwrites:
  ```
  [The Archive](http://pastebin.com/S0aWmYsL)

  1248 words.
  ```

- u/MultipartiteMind:
  ```
  [The Formulator](http://pastebin.com/3CZaSi2w)

  2098 words.
  ```

---

