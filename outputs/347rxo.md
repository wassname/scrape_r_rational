## How to know if you're right, when everyone around you thinks you're wrong? [D]

### Post:

Ok, we can agree that public opinion is often wrong. It's debatebly easy to sway crowds. As they say, a person is smart, people are stupid. Mob mentality. Etc. 

That being said, it's also not rational to hold onto an opinion if the rest of the world thinks it's wrong. Now, reality is reality. The sky's blue (usually). You drop a ball, it will fall to the ground. But it gets harder to identify fact from fiction when the issues get more complex, and I just want to know, is there any good, general techniques to ensure that, even if everyone in the room is telling you that you're wrong, you can be assured you're right? Simply having an unpopular opinion doesn't make it incorrect. 

Sorry if I'm not very clear with my question! Also, I ask this here, because I find there seems to be a lot of intelligent people on this subreddit. :)

### Comments:

- u/nevinera:
  ```
  No. If everyone in the room is telling you that you're wrong, you can occasionally be *fairly confident* that you're right, but you certainly shouldn't be 'assured'.

  Maintain the belief that you *could be wrong*. More importantly, learn to hold beliefs with varying levels of confidence - if everyone in the room thinks you're wrong, and you logically 'proven' to yourself that you are not.. you should have some significant doubt, especially if you can't point out a clear reason *why* everyone would believe that untruth.

  Now, to address what I think you're really after.. if you for some reason need to determine your correctness *suddenly* - immediate consequences, basis for a time-limited decision, etc - then you should find someone willing and able to have a rational discussion about *why* they hold the opinion they do, and *truly attempt to understand*. This is not an exercise in figuring out 'how they were wrong', you need to be able to imagine circumstances in which you would also believe that thing. If you can't easily/safely discuss the topic.. you're stuck. Treat your belief as non-confident to some degree.

  In reality, that doesn't come up much. More often, you are asked to commit socially to an opinion, but there is no real fallout from *not committing*, or from expressing a lack of certainty. Express and maintain that lack of certainty, until you can consult someone who *ought to know better than you* on the topic (not somebody from your community, or someone who will just agree with you, someone who has specific experience or expertise in the topic in question). 

  Edit: above all, be aware that humans (even ones who really should know better) are *terrible* about updating their beliefs. Do *not* commit to one and pretend you're going to come back and reassess later.

  Edit: clarified leading sentence slightly.
  ```

  - u/None:
    ```
    > Maintain the belief that you could be wrong. More importantly, learn to hold beliefs with varying levels of confidence - if everyone in the room thinks you're wrong, and you logically 'proven' to yourself that you are not.. you should have some significant doubt, especially if you can't point out a clear reason why everyone would believe that untruth.

    Also, formal logic is a very leaky abstraction for dealing with things that aren't ontologically basic (ie: most things), so you should trust apparent empirical evidence over "logical" argumentation.  Look at the way the world seems to be, rather than what it sounds like in your head.
    ```

    - u/nevinera:
      ```
      One of my favorite techniques: figure out a way for their 'incorrect' belief to allow someone to generate profit. Then determine if anyone actually is generating a profit in that way.
      ```

      - u/ulyssessword:
        ```
        [Relevant XKCD](https://xkcd.com/808/)
        ```

        - u/xkcd_transcriber:
          ```
          [Image](http://imgs.xkcd.com/comics/the_economic_argument.png)

          **Title:** The Economic Argument

          **Title-text:** Not to be confused with 'making money selling this stuff to OTHER people who think it works', which corporate accountants and actuaries have zero problems with.

          [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/808#Explanation)

          **Stats:** This comic has been referenced 100 times, representing 0.1624% of referenced xkcds.

          ---
          ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&subject=ignore%20me&message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&subject=delete&message=delete%20t1_cqs6tpe)
          ```

  - u/nevinera:
    ```
    In addition, you should avoid having strong beliefs about very complicated systems: social systems, real economies, individual human minds, 'the future of AI', and political policy are all excellent examples. 

    No matter how much of an expert you are on any of those topics, you do not *grok* them, and you cannot make dependably accurate predictions about them. If someone else seems to be offering a high degree of confidence about anything like that, they are exaggerating - look for a motive (conscious or unconscious).
    ```

  - u/nevinera:
    ```
    In some sense *logic* is a tool specifically for that - try to express your assumptions and definitions clearly to yourself.
    ```

    - u/Uncaffeinated:
      ```
      You have to be careful, since logic is also very good at letting people reinforce incorrect beliefs.
      ```

      - u/nevinera:
        ```
        Yes, but if anything can help you determine your own correctness in a vacuum, it'll have to be the process of defining your belief and assumptions and then examining your own logic a link at a time.
        ```

- u/blazinghand:
  ```
  This sounds worthy and thoughtful, and I wish you the best of luck. There are many places to turn to learn and to find resources about how to disagree and what it means to know you're right when others thing you're wrong. It might be worth checking out /r/lesswrong (or /r/lesswronglounge ?), which is a subreddit related to the Less Wrong rationalist community. Other places to check out include the comments section of the blog [Slate Star Codex](http://slatestarcodex.com/) which is full of people who are trying to become well-versed in all manner of things.

  What you're describing is interesting, and I guess the underlying question here is how much other people's opinions should matter. The problem isn’t people disagreeing with you, the problem is being wrong, and there are many correct facts that people agree on. It's also annoying and difficult to have an opinion many people disagree with. Having an unpopular opinion has negative consequences that I'll address later. For now let's focus on being right when people are wrong without losing your ability to adopt people's correct opinions.

  ### Being right when people are wrong

  So, my usual strategy is to only trust people to be right about certain things. There's a large class of subjects that I expect almost everyone in my life to agree on and be mostly correct about. Examples include basic arithmetic, common-use definitions of American English words, and everyday skill knowledge like cooking, operating consumer electronics and machines at a basic level, writing, reading, and so on. On these things, if I have confusion, I usually bring it up but don't cling to it if most people disagree with me. 

  In domains where knowledge is specialised or difficult to acquire in an unbiased fashion (politics, automobile repair, organic chemistry, religion, laws of a specific country or city, microelectronics, local geography of suburban town, martial arts or combat training, etc),  I do not automatically defer to those around me. Instead, I defer to them on subjects that I judge them to be likely to know about. If I'm in a room full of lawyers from India, and there's a lively discussion happening about the best way to travel between two cities in India, and I have an opinion they disagree with, I'll generally assume I'm wrong and they're right. On the other hand, if we get into a discussion of microelectronics and I have an opinion and they all disagree with it, I see no reason to thing they are right while I am wrong. 

  My father is a domain expert in real estate, european literature, German, Farsi, and French. If I'm hanging out with him and his real estate agent friends and I have a certain opinion about whether or not it's possible to legally sell a home in a certain way, and they all disagree, I'm almost certainly wrong. We run into an interesting case though if I express an opinion about real estate politics ("we should have more high density housing in SF!") and they disagree. When we run into issues where people have a motivation to have a certain belief, we have to counterbalance expertise with motive. If I'm hanging out with my dad's Persian friends and try to talk about Iran, things get even worse. They may not have motivation about a particular answer, but there will be all kinds of identity politics gumming up the works of discussion. If they all think Rouhani is a swell dude and the clerics need to butt out, and that would help Iran's economy, that's fine. Still, I have to think about the fact that that might be an expression of their distaste for Islamism and not an expression of their thoughts on the best policies for the management of the Iranian state. If I express some disbelief in Rouhani's economic policies, their subsequent attack won't be an expression of their thoughts on the price controls placed on staple goods, but rather a way of defying the theocracy that plagues the Iranian government. 

  So, if people are disagreeing with you, and you want to factor this into your decision about whether or not to change your opinion, you need to think about why they're disagreeing with you, and how much they know about a subject matter, and whether they have other thoughts on their mind. My roommate hates techy culture, despite being a techy person, because of past experiences with the dark side of Silicon Valley tech norms. An expression of distaste for a hackathon isn't necessarily a swipe against pizza, beer, and crappy code, but could be a swipe against negative past experiences. When the rightist branch of my family expresses distaste for my leftism, that doesn't tell me anything about the truth. My family would be annoyed by leftist thoughts whether or not these thoughts are correct. 

  Choose which groups you discuss things with carefully. The opposite problem is actually much more common. It's really really easy to notice when you disagree with most people. They'll let you know. If you're wrong, and you disagree with everyone, I am absolutely certain that people will let you know you're wrong. The much more dangerous scenario is being wrong when everyone else is wrong. This isn't something that is easily noticed. 

  Being right when everyone else (in the room with you) is wrong is unsettling. I don't really know that I've been in a situation where I've felt seriously threatened by disagreeing with people, though. This is probably the largest amount of thought I've put down about what it's like to disagree with people, because for me it's fairly natural. I'm extraordinarily stubborn (and nobody will tell me otherwise! hueheuhue) when it comes to people, but not when it comes to facts. Take your time and learn what you want to learn

  ### Dealing with consequences of disagreemnt

  So, I've been rambling a lot and probably have gotten off message here. My usual strat is to not tell people I disagree with them! :D
  ```

  - u/DaystarEld:
    ```
    Very well put. Other than the nebulous "how smart/rational is person X," the two most important factors in determining how seriously I take their views is their expertise on the topic and their motives.

    Sometimes it comes off to others as an ad hominem to dismiss arguments for these reasons. While most reasonably intelligent people accept that if they have not studied biology or computers their beliefs on the topics are ill informed, when it comes to political or social or economic issues, everyone has an opinion and few appreciate having their lack of credibility pointed out.

    In the ideal world, arguments are judged on their own merits, and who says them is completely immaterial. But when an argument literally *can't* be judged on its own merits, because we don't possess the necessary, hard to acquire information related to it, or if the ultimate truth of the statement is impossible to verify, or if the justification for the argument relies on a difference of values, then focusing on the person is a useful shortcut for determining how much stock to put in what they say.

    Also,

    >If I'm hanging out with my dad's Persian friends and try to talk about Iran, things get even worse... their subsequent attack won't be an expression of their thoughts on the price controls placed on staple goods, but rather a way of defying the theocracy that plagues the Iranian government.

    Son of another Iranian immigrant here. Can confirm.
    ```

- u/None:
  ```
  That's basically, like, the entire task of rationality.  The first step is to be unsure, and the second is to let yourself be moved by external facts about the world that *aren't* generated by people.
  ```

- u/rationalidurr:
  ```
  Reality can't be bought, it cant be bullied, it cant be reasoned with and it cant be negotiated with. 
  Reality just wants the world to turn.

  So find a way for reality to point out the right of way. A test to see if proposition X, yields result Y.

  Also get some sort of area of effect weapons like a flame thrower, to keep away mobs of people who want to ignore your arguments and argue pointlessly.
  ```

- u/Nepene:
  ```
  You know whether you're right or wrong by the evidence.

  So, if someone advances an opinion or several people advance an opinion it doesn't mean much. Whenever you hold a piece of knowledge you should ask yourself "How do I know what I know" (i.e. what evidence is there for it) and "What is the majority consenus of actual experts who have studied the matter?"

  The two questions normally go together because experts tend to know things based on evidence.

  You don't have to agree with the experts, but you have to agree with the evidence. What studies do they have to support their view, what analysis, what experiences? You should know these about whatever issue so you know how strong the evidence is in favor of whatever view.

  A lot of popular culture views aren't amendable to evidence. We should ban gay/ interracial marriage because it will destroy traditional marriage? How do we know it will destroy traditional marriage? How quickly will it destroy traditional marriage? What countries has it successfully destroyed gay marriage in, how unhappy are relationships in that country? Those who advance views like the above don't tend to have a good answer to such questions and so it being a popular view doesn't mean much.

  Or for a previous question you asked, how successful is x diet plan. How large was the study used to test its success? How much weight was lost on average? How well did people adhere to the diet? Did they prove their point metabolically?

  Stuff like that. If you want to know you're right you have to have numerical answers to questions like that which can reliably predict the future.
  ```

- u/ishaan123:
  ```
  I think "How to know *whether* you are right, without resorting to popular consensus" is a better way to put this. (Because we want to actually *be* right, not prove that our opinion *was* right)

  >Now, reality is reality.

  Not really. If you're thinking in a philosophical sense, you can't ever know. Your methods of calculating truth are just a result of your brain's hardware, and at bottom there's no final justification for any of it other than that's what *you think*. It is analogous to morality in that way. 

  Practically speaking, it depends. If the question is not philosophical but a complex empirical issue, you go to places like this http://scholar.google.com/ and this http://www.ncbi.nlm.nih.gov/pubmed
   and so on and take stock of the evidence.
  ```

- u/EliezerYudkowsky:
  ```
  Find cases where you will find out in the foreseeable future if you were right.  Set numerical probabilities.  Bet, if they'll let you.  That is how you practice and calibrate any abilities you think you have to update well on other people or disagree with them well.
  ```

  - u/Kishoto:
    ```
    How would you suggest doing this with complex issues? I can't say if the Baltimore riots will help with any racism issues in America, and I'm fairly certain that, if they do, the effects will be subtle, and over a prolonged period of time, with a number of other mitigating factors. Not something I can really predict.
    ```

- u/Igigigif:
  ```
  Great question. I'd also recommend posting questions like this on [lesswrong] (http://lesswrong.com/)'s discussion broads.
  ```

---

