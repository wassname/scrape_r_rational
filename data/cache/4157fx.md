## Is this a LessWrong sub?

### Post:

I definitely #do not# like the LessWrong worldview, but I enjoy many aspects of "rationalist" literature. I want to know if this subs users always promote atheism and transhumanism or if there's any discussion challenging basic ideas of the LessWrong movement as opposed to arguing within the worldview.


What I'm saying is: will I like the discussion in this sub if I'm not a proponent of immortality, effective altruism, or other new atheist and transhumanist platforms?



Edit: I've decided to stop replying to this thread due to the amount of conversations I had to keep up in. Thank you!


"Whereas some brahmans and contemplatives, living off food given in faith, are addicted to debates such as these — 'You understand this doctrine and discipline? I'm the one who understands this doctrine and discipline. How could you understand this doctrine and discipline? You're practicing wrongly. I'm practicing rightly. I'm being consistent. You're not. What should be said first you said last. What should be said last you said first. What you took so long to think out has been refuted. Your doctrine has been overthrown. You're defeated. Go and try to salvage your doctrine; extricate yourself if you can!' — he abstains from debates such as these. This, too, is part of his virtue."


### Comments:

- u/alexanderwales:
  ```
  I think you'll be fine with the discussion. I'm not a True Believer and don't write like one, and I think I more or less fit in with the community. I don't necessarily *disagree* with immortality, atheism, transhumanism, etc. But I'm not about to proselytize or present those views in an unexamined way (speaking as though you are Right is one of those things that I find annoying no matter who's saying it and about what).
  ```

  - u/AmeteurOpinions:
    ```
    Dude, until Eliezer starts writing again, you *are* the community.
    ```

    - u/None:
      ```
      [deleted]
      ```

      - u/AKhou:
        ```
        Almost completely done with Worm. By my beard, this one is monumental. It compels me to write a story of my own.
        ```

    - u/rhaps0dy4:
      ```
      How about FarmerBob, Kishoto and as the sibling comment says, Wildbow?
      ```

    - u/chaosmosis:
      ```
      Animorphs tho
      ```

- u/rational_rob:
  ```
  I had a post here, but I've edited it for the sake of clarity:

  A lot of people that read HPMOR also read and absorbed the sequences at LessWrong, as well as a disproportionate number of authors. They not only have evidence for what they believe, but are used to justifying it to people who are disenfranchised. So, no, it's not a LessWrong subreddit, but don't expect to say "I disagree with immortality" on this subreddit and not get dog-piled. It might be a vocal minority, or a vocal majority, but they are vocal and they have incentive to argue.

  This isn't a statement of belief, it's just generally how rationalists act; there's no room to "agree to disagree" in the philosophy.
  ```

  - u/Fresh_C:
    ```
    I think there is room to disagree when it becomes clear that a person's values and end goals are different than yours.

    I don't mean when debating concrete facts. I mean when talking about what course of actions should be taken and describing things as "Moral" or "Ethical".

    Basically a person can be perfectly rational and believe that it's okay for them to steal from other people as long as they don't get caught becuase their value system only involves improving their own lives and they care little for other human beings.

    As long as they're reasonably certain they'll never be caught or held responsible and they're stealing in such a manner that doesn't significantly hurt humanity as whole, you can't rationally say that their reasoning for stealing is wrong based on their intended goals. 

    You can only say that you disagree with their end goal.
    ```

- u/ArgentStonecutter:
  ```
  I'm not a fan of LessWrong, and don't see it as being primarily about atheism or transhumanism. That's a side issue to the set of mental tools and practices that EY pushes.
  ```

  - u/traverseda:
    ```
    Would you say you don't like the whole bayesian thing, or just lesswrong in particular?

    Because I don't hear enough reasonable criticism of the whole bayesian thing.
    ```

    - u/ArgentStonecutter:
      ```
      I think they way overstate the usefulness of Bayes Theorem. They seem to think that it's the best way to evaluate situations even if you pull random numbers out of the air to fill in the gaps.
      ```

      - u/traverseda:
        ```
        Probabilistic thinking probably doesn't seem like something profound because you're already practicing it, but a lot of people coming from the atheist/skeptic movements got stuck in boolean logic.

        It's also very useful for working in groups. Like a mini prediction market.

        The trick with lesswrong is that it seems profound at the time, then a few years later you look back and wonder what all the fuss was about. It codified a lot of thoughts that 17 year old traverseda didn't have the words to explain. I would have gotten there eventually, but it certainly sped things up a bit.
        ```

        - u/andor3333:
          ```
          That is what I liked about it. It laid out good definitions for things I wouldn't otherwise have had an easy reference concept for.
          ```

      - u/DCarrier:
        ```
        I'd say that in principle it's the best, but in practice it's generally better to find something resilient than something with a good theoretical basis. You don't want to be wrong forever because you picked bad priors.

        But I do think it's important to learn the theoretical basis behind things. And to know *exactly* what evidence is.
        ```

    - u/None:
      ```
      >Because I don't hear enough reasonable criticism of the whole bayesian thing.

      Coming up with good priors is hard.  Even good priors don't really encode information *unless they are from empirical data*, they're regularization methods.  Posterior distributions can rarely be actually evaluated numerically, usually just sampled-from.

      In short, it's a shining example of taking a normative theory and representing it as applicable to the real world while failing to mention that applying it to the real world is really, really, *really* hard.
      ```

- u/Sailor_Vulcan:
  ```
  Welcome!

  The reason most people in this community don't question the nonexistence of any gods is probably for the same reason that they don't question the nonexistence of Middle Earth. They've already done the questioning, found the evidence to be fairly conclusive that deities don't exist, and moved on to more interesting topics.

  If you have found any evidence that a deity or deities exist, I'm sure many of us would love to hear it and discuss it with you. Just because most of us came to the same conclusions doesn't mean that none of us are open to discussion.

  As for transhumanism and immortality, my understanding is that they are more of a value, something to strive for, not necessarily a belief that they are likely to happen. In this respect, google dictionary probably gets it wrong.

  What exactly are your objections to effective altruism?


  The reason that most people in this community agree on those specific three things: 1. that people should be allowed to live as long as they want, 2. that god(s) don't exist, and 3. that some charities are *significantly* better at helping people and helping more people than other charities is because:

  (1.) We like to be unusually honest and consistent with ourselves (so if one of us ever said that immortality was bad, we wouldn't contradict ourselves by saying that living forever in an afterlife was good.) 
  And (2. and 3.) We each evaluated the evidence and came to our own conclusions.

  NOT because of mob mentality.

  Also, I just want to make this clear just in case you don't understand and get offended, when we disagree with or contradict other people's opinions, we're NOT claiming any superiority over them nor trying to establish ourselves as dominant over them in any way whatsoever. Many of us are genuinely *glad* when we are proven wrong about something.

  That being said, the rational fiction subreddit specifically is more about rational writing and literature, and not all of it focuses on those particular three subjects. You should be able to find a decent amount of rational fiction to read and enjoy which doesn't focus on atheism, transhumanism or effective altruism.

  Some examples I would recommend include:

  -Mother of Learning

  -Worm

  -Hogwarts Battle School

  -The Martian (yes the same one that the movie was based on!)

  -Forging the Sword

  -Shadows of the Limelight

  -Dungeon Keeper Ami

  -What if Sg-1 Weren't Stupid (it's a lot better and funnier than it sounds. Must read if you're a stargate fan!)

  -Stargate Physics 101

  -Interview with a System Lord

  -Twisted: the Untold Story of a Royal Vizier (okay, this one is kinda transhumanist, but it's a musical retelling of Disney's Aladdin, performed by Starkid, the same people who did a Very Potter Musical! Totally worth it even if you don't agree with transhumanism.

  Enjoy!
  ```

  - u/portodhamma:
    ```
    First of all, thank you for your suggestions! They should be very helpful, as I've already read and liked some of them.


    Secondly, I was not trying to question atheism as a position, but on the internet, there's quite a bit of ideological baggage that comes with many atheist communities.


    I also don't wish to remove any options for people to extend their lives, that's practically murder. However, I don't think eternal life is a good thing, and striving towards it is an unhealthy choice(clearly I mean spiritually, not physically.)


    Also my objections to effective altruism are more along the lines of my inclination to virtue ethics as opposed to utilitarian. I can't save the world but I can act like a good person and gain contentedness from that.
    ```

    - u/traverseda:
      ```
      > I was not trying to question atheism as a position, but on the internet, there's quite a bit of ideological baggage that comes with many atheist communities.

      You object to the atheist tribe, which is reasonable. A lot of people object to the lesswrong tribe, but they're still the best resources we have for a lot of skills. Some people from the Center for Applied Rationality are dissociating those skills from lesswrong as a tribe.

      On the whole, we try to discourage tribalism here, so hopefully you won't have a hard time of it. People might need to be gently reminded occasionally though. Tribalism runs strong in humans.

      That's actually one of the bigger complaints about lesswrong, that they encouraged tribalism for the sake of strength and unity, but that that gets in the way of other things we value like discussion and lack of tribe related bias.
      ```

      - u/portodhamma:
        ```
        Thank you for understanding what I meant and interpreting my words charitably. I had heard that kind of thing about LessWrong and I'm glad I'm not seeing it here.
        ```

        - u/traverseda:
          ```
          I like this community for exactly that reason. There's been a few actual arguments, but this and the general rationalist community are probably the most understanding communities around. Because that's sort of our thing, trying to understand.
          ```

- u/traverseda:
  ```
  Please remember not to downvote based on opinion.
  ```

- u/traverseda:
  ```
  Do you like debating immortality, effective altruism, or other new atheist and transhumanist platforms?

  If so, I'm sure you'll like the discussion on this board ;p
  ```

- u/rineSample:
  ```
  Just curious, what are your reasons for opposing those things?
  ```

  - u/portodhamma:
    ```
    Well I think that life is primarily a negative experience and people deserve to die and move on to the next life to reap their karma. It's not a scientific perspective, but one I formulated through study of religion and personal experience. And I believe that ethics can only be determined through philosophical insight, I think that the Is/Ought barrier is pretty strong.
    ```

    - u/Roxolan:
      ```
      Please do not downvote /u/portodhamma just because you disagree with the honest answer *she gave to the on-topic question she was asked.
      ```

      - u/portodhamma:
        ```
        Thank you, and I go by "she" for future reference.
        ```

    - u/traverseda:
      ```
      Would you make that choice for them?

      The general thought around here tends to be preference utilitarianism. That is, if you'd prefer to die you deserve to be given that option. Some would qualify that saying that you should at least make an honest effort to enjoy your life so that others aren't sad about your passing.

      But many people do strongly want to live. They should be allowed to, indefinitely if they want.

      As for ethics being only determinable through philosophical thought, well most people here and on lesswrong would actually agree with you, more or less.

      Rationality is a tool for accomplishing your goals, but your goals themselves can't be decided "rationally". There's no "rational" axioms, no rational reason to want to be happy.

      But rationality can help you notice contradictions in your goals, help you figure out what you really want, and when your goals truly do conflict they help you decide which ones to pursue.
      ```

      - u/portodhamma:
        ```
        I would think that justifying an *obligation* to refrain from immortality or to never have kids is a far tougher prospect than saying that it isn't virtuous behavior. This is coming from a virtue ethics standpoint, of course. I would regard veganism as virtuous,but I would only extend obligation to refraining from actually hurting animals yourself.
        ```

        - u/traverseda:
          ```
          Ahh, well there's your problem. Virtue ethics.

          In all seriousness though, why virtue ethics?

          ---

          A rationalist-ish take on the whole veganism thing could look like [this](http://slatestarcodex.com/2015/09/23/vegetarianism-for-meat-eaters/).

          TL:DR

          >This argument is so simple I feel dumb for not thinking of it myself; instead, I take it from Julia Galef and Brian Tomasik. Suppose I get about a third of my daily calorie requirement from meat; that adds up to 250,000 calories of meat a year. Further suppose that it’s split evenly between 125,000 calories of beef and 125,000 calories of chicken.

          >The average cow is very big and makes 405,000 calories of beef; the average chicken is very small and makes 3000 calories worth of chicken. So each year, I kill about 0.3 cows and about 42 chickens, for a total of 42.3 animals killed.

          >Suppose that I stop eating chicken and switch entirely to beef. Now I am killing about 0.6 cows and 0 chickens, for a total of 0.6 animals killed. By this step alone, I have decreased the number of animals I am killing from 42.3/year to 0.6/year, a 98% improvement.

          As an example of the general approach. The question then becomes one of whether you value cows more then chickens, and if so how much.
          ```

          - u/portodhamma:
            ```
            &gt;Why virtue ethics?


            Largely because of two things: I believe motive matters in determining the goodness of an action, and deontology and consequentialism were ruled out.


            To elaborate: I find it impossible to conceive of a set of maxims that apply to every situation and I find it horrifying to assign ethical culpability when the consequences of an action can be ridiculously, insanely hard to predict with surety.


            EDIT: I could really go into things like metaethics and epistemology but I'm on mobile and it's cold so I won't.
            ```

            - u/traverseda:
              ```
              I think motives are important, but they're not at the layer of ethics, they're at the layer of game theory or politics.

              The goodness of an action doesn't change based on motive, but how you treat the person doing the action still should, if that makes sense?

              Likewise, someone can be a good person, and not have much of an affect on the world. Someone can be a horrible person and do great things.

              You're using ethics to judge yourself, but I think you should be using it to judge the world.

              Virtue ethics is an alright shim to deal with all the complicated game theory bullshit, because it let's you predict future actions. An evil person who does one great thing isn't "better" (in the sense that you should associate with and reward them) then a good person who doesn't get a lot done. because that evil person is willing to do evil. On the whole, the good person will end up being better.

              There's also the layer where we don't want to implement anything like the churches "indulgence" system. There are all kinds of social reasons why we don't want people to be able to buy off their sins.

              I'm describing it poorly I know.

              The point I'm trying to get at is that something that looks a lot like virtue ethics is that natural result of social structures and preference utilitarianism, but that I see it as just another tool to help us work towards preference utilitarianism.  I view it as a social tool in service of good ethics instead of as good ethics itself.

              ---

              > I find it horrifying to assign ethical culpability when the consequences of an action can be ridiculously, insanely hard to predict with surety

              Lesswrong says is pretty abrasively, but I'm inclined to agree.

              >You know what? This isn't about your feelings. A human life, with all its joys and all its pains, adding up over the course of decades, is worth far more than your brain's feelings of comfort or discomfort with a plan. Does computing the expected utility feel too cold-blooded for your taste? Well, that feeling isn't even a feather in the scales, when a life is at stake. Just shut up and multiply.

              To put it a bit nicer, I consider preference utilitarianism to be a virtue, and I'm more inclined to help out those that I consider to be virtuous, as a policy. I like virtuous people more then evil people.

              If I help out people with that virtue, and they help other people with that particular virtue, more bednets are likely to be distributed to africa, more people get to live happy full lives, etc.

              That's what virtue is for, determining what people/corporation you should like and therefore help out.

              But how you decide what is a virtue is in the realm of preference utilitarianism and game theory.

              Sorry, that was a bit rambly, but hopefully I've got my point across.
              ```

              - u/portodhamma:
                ```
                I think most of the differences between ethical systems aren't necessarily the conclusions but the reasoning leading to said conclusions. With certain, important, exceptions of course.
                ```

                - u/traverseda:
                  ```
                  I think that preference utilitarianism results in more bednets getting sent to africa, which is a pretty important difference. Well, to me anyway. It seems like something that's obviously ethical.
                  ```

                  - u/portodhamma:
                    ```
                    If you count compassion, charity, or benevolence as virtues it leads to bed nets being sent.
                    ```

                    - u/traverseda:
                      ```
                      Less of them though. There are plenty of causes to be charitable or compassionate about.

                      The society for curing rare diseases in cute puppies as an example.

                      How do you choose what causes are important? The virtues of compassion and charity don't seem to provide any particular guidelines. Is it more compassionate to send your money to the society for cute diseases in rare puppies, or to send bednets in africa?
                      ```

                    - u/None:
                      ```
                      Yeah, it leads to bed nets being sent, but it also leads to more donations to charities that don't actually use their money and resources to help anyone, or use less money to help someone than they could.
                      ```

        - u/narfanator:
          ```
          I'm confused. Do you have a justification for why refraining from immortality is virtuous? 

          (It sounds like you do not have a justification for an obligation from immortality)
          ```

        - u/DCarrier:
          ```
          So you shouldn't hurt animals, but paying someone to hurt them is okay? That seems pretty arbitrary. If I don't like someone and I punch them in the face, that would be wrong. If I try to get around this by paying someone else to punch them in the face, it would be just as wrong.
          ```

      - u/None:
        ```
        >As for ethics being only determinable through philosophical thought, well most people here and on lesswrong would actually agree with you, more or less.

        [BLAM heresy BLAM](http://static.tvtropes.org/pmwiki/pub/images/imagesCA5KD61T_2953.jpg)
        ```

    - u/None:
      ```
      [deleted]
      ```

      - u/portodhamma:
        ```
        I ask myself this a lot. I'm in the most intensive therapy program I can get in all of America. I don't kill myself because I don't think it will end things.
        ```

        - u/None:
          ```
          [deleted]
          ```

          - u/portodhamma:
            ```
            Thanks for the sentiment.
            ```

    - u/narfanator:
      ```
      You do not experience the same reality as I do. That said, I somewhat subscribe to the idea that we can share an experience set and means of interaction but without "sharing" a reality.

      If this is life, then, I guess, you'd call the series of reincarnations as meta-life? 

      With that word-usage - Why do you expect this life to be a primarily negative experience for all people, but (to put words in your mouth) the meta-life to be a primarily positive experience for all people?
      ```

    - u/Nighzmarquls:
      ```
      Hmmm, I have a friend who is a nihilist via philosophical insight I'm inclined to want to introduce you too him. But I admit it's mostly out of a desire to watch what fireworks come of it.
      ```

      - u/portodhamma:
        ```
        Haha! I'm just a Buddhist anti-natalist. I do have a strong belief in the realism of morality, I just don't think the *continuation of life* is moral.


        EDIT: Moral *in itself*
        ```

        - u/None:
          ```
          That's a really fucked up interpretation of Buddhism, mate. 

          When the Buddha said that "life is suffering", he specifically referred to "want in life" is suffering, and that you end your suffering by ending you want. 

          Correct me if I'm wrong, but you comments in this thread have lead me to understand that you see death as the ending of that want and suffering, on the assumption that there is some metaphysical life and karma cycle to wade through posthumously. 

          This is incorrect for a number of reasons. Firstly, "end of want" is a goal to reach through meditation and study, and is supposed to end you up at "working for more, content with that I've got". 

          It's the origin of the phrase "Before enlightenment, chop wood and carry water. After enlightenment, carry water and chop wood." 

          Secondly, you can't enter into a rational discussion of the universe and bring metaphysical anything into it.  For the purposes of rational conversation, introducing an inherently irrational element disrupts the whole thing, and invalidates your side. What sort of proof can you present for this karmic cycle and these next lived you mention?
          ```

          - u/MugaSofer:
            ```
            >That's a really fucked up interpretation of Buddhism, mate.

            Considering Buddhism advocates "escaping" the karmic cycle of rebirth as a central tenet, I'm not sure that's true.

            >Secondly, you can't enter into a rational discussion of the universe and bring metaphysical anything into it. For the purposes of rational conversation, introducing an inherently irrational element disrupts the whole thing, and invalidates your side.

            Nothing is *inherently* irrational, surely.
            ```

            - u/None:
              ```
              It depends on the school of Buddhism you study. Like the monotheistic religions, there are a lot of sects. 

              On the grounds of rational agents, I'm labeling religious beliefs as inherently irrational due to that fact that they claim both dominion over and authority on information states that exist outside of reality. If we want to discuss extra-reality, then we may do. So, but we can't claim that our discussion will be rational within the boundaries of our reality. 

              An example of inherently irrational agents would be discussing classic fantasy magic. In our universe, rationality dictates that a human may not draw on natural energy unassisted, force it through a huge occult phase or state conversion and then release it as directed energy or matter, but a classic mage can summon a fireball and call up a golem without much issue. 

              In our universe, this is irrational, because the axioms that govern our existence show it to be impossible. As such, attempting to hold a conversation with someone who posits that such acts are possible in out reality contains an inherently irrational element, and is thus inherently irrational.
              ```

          - u/portodhamma:
            ```
            Ok first of all, it means that being trapped in Samsara means you will experience dukkha, which *can* be translated as suffering and is the translation I prefer.  I don't think death leads to escape from Samsara, but I do believe death comes for us all and isn't the worst thing possible. The only way to escape Samsara is through he Eightfold Path. 


            And you should read Kant's *Critique of Pure Reason.* It really goes into metaphysics and its importance.
            ```

            - u/None:
              ```
              You keep using that word, "believe".

              Unfortunately, "believe" isn't usually an acceptable scientific proof. Do you have some sort of reproducible evidence that pointed you to this world view? 

              How are you determining that we are "trapped" in samsara? How are you so certain we aren't living in Midgard, or that this isn't the actual afterlife where we pay for our per-comitted sins, or that we aren't wandering around the river lathe and hallucinating, or any number of other, similarly ridiculous religious hokum?
              ```

        - u/Nighzmarquls:
          ```
          I'm not sure if there is a solid word for me so I often just go with I am pragmatic/practical about things.
          However from my general understanding I'd predict you to view the existence of life to be moral? As per an example that a future with some life in it is better the one without it?
          ```

          - u/portodhamma:
            ```
            I would not view any form of existence to be moral, only actions to be. The action of accepting death and impermanence is moral to me, as is the action of refraining from bringing life into the world.
            ```

            - u/JackStargazer:
              ```
              I actually find this belief system interesting. Though I have a few questions, if you wouldn't mind.

              What is your position on life-saving medical treatment? If the point is to accept death and impermanence, should life be fought for at all?

              Is the 'next life' in your conception a sort of Dharma wheel of reincarnation into a better life in this world, or a progression to a steadily better world ending in the Buddhist Nirvana? Do your actions effect this at all (does virtuous action lead to virtuous reward?)

              Doesn't that kind of belief necessarily remove itself over time from existence? 

              If you bar both reproduction and continuation of life, and are a non-missionary faith as Buddhism is, the spread of the idea is necessarily limited. Unless it is vastly more persuasive than any other idea, or there is some huge external pressure, its proponents will fade away rapidly as they die and not be replaced by new believers.

              It's sort of like the extropian argument against people who are Pro-Death for religious reasons, only it happens much faster, because they aren't reproducing or accepting any life extension.
              ```

              - u/portodhamma:
                ```
                Ok first, life-extending treatment is just that, life-extending.  That is a fundamentally different goal than immortality. Accepting death should be on your own terms, though, anything less is murder and a removal of any choice.


                And rebirth does not necessarily lead to better conditions. Bad karma is called bad for a reason. Good karma itself will not lead to enlightenment, though, only detachment from craving and aversion will.


                And yes it will die out, even though *it is* a missionary religion. As it said to have died out before. But it will be rediscovered (In the same way,even if civilization is destroyed, people will still rediscover calculus in time,it's a fundamental fact of the universe) and the cycle goes on. Buddhism is about the personal, and doesn't concern itself with effecting all of humanity.
                ```

                - u/narfanator:
                  ```
                  One of the major points that Yudkowsky uses to argue for here-and-now immortality is that desiring, or expecting, some continued chain of afterlives (or a chain that terminates in a "forever") still *is* immortality, it's just one that doesn't take place in this subset of reality. Now, generally, the LW writings on this are a little... aggressive, but the question's still valid.

                  That said, what I'm hearing from you is that it is not the seeking of immortality that dismays you, but the seeking of permanence....?
                  ```

                  - u/portodhamma:
                    ```
                    Indeed, but Buddhism's very goal is to end immortality. Nirvana is neither existence not non-existence, but it definitely isn't eternal life. Life is suffering, and ending suffering is the reason the Buddha sat under the Bohdi tree.


                    EDIT: All that arises is subject to its eventual dissolution.
                    ```

                    - u/zajhein:
                      ```
                      I was under the impression that Buddhism's ultimate goal is to reach nirvana, a release from suffering and the cycle of death and rebirth. Which can be achieved during life, or death, and does not necessitate the existence of some other realm of being. For example, the Buddha is said to have reached nirvana while still alive, thus he lived without suffering.

                      Becoming immortal sounds quite like that goal, despite your unexplained and repeated objections.
                      ```

                      - u/Bowbreaker:
                        ```
                        If I understood it correctly then many Buddhists believe that once you die after achieving Nirvana you lose your "self" in Nirvana like a drop of water in the ocean. In other words finally and actually dying with nothing akin to an afterlife awaiting you is the *goal*. You can say that adherents of the Abrahamic religions believe they are struggling to attain immortality but Buddhists seem to believe that everyone already has that and that we should try to get rid of it.
                        ```

                - u/Bowbreaker:
                  ```
                  > Ok first, life-extending treatment is just that, life-extending. That is a fundamentally different goal than immortality.

                  So life extension is okay then? Is that regardless of length? If there were a medical procedure to increase the duration of life and health for a hundred years would that still be acceptable in your worldview? What about a thousand or ten thousand years? What about living till the heat death of the universe or beyond it. After all *true* guaranteed immortality is pretty much impossible anyway. There could always be something out there to finally kill you.

                  >And rebirth does not necessarily lead to better conditions.

                  So what about people who are happy and healthy but are aware that they may have accumulated more bad karma than good? They don't necessarily fear death but prefer living a nice life to living a hard one. Wouldn't it be only sensible for them to try to extend their current life for as much as possible?

                  And I know that any life in any world is suffering due to wanting and craving things but in my own life experience I have more joy and positive emotions than I have pain or negative emotions. So you may understand that even Nirvana itself does not seem like something to strive for to me as it would mean an and to all of these experiences that I rather enjoy experiencing. Why would it be the moral thing to do to give all of that up anyway? Who do I help? What moral good do I advance by doing so?
                  ```

    - u/Bowbreaker:
      ```
      > and move on to the next life to reap their karma.

      But what if it turns out that there is no next life? Would everyone still deserve to die?
      ```

    - u/metalknight:
      ```
      What's your empirical basis for the existence of "karma", and subsequently, what's your empirical basis for believing that the concept of "karma" will be visited upon them after death?
      ```

    - u/None:
      ```
      > Well I think that life is primarily a negative experience

      Hmmm...  I'm not sure about "primarily", but I actually partly agree.  Life is *currently* a *sufficiently* negative experience that there are great parts of it which I have zero desire to repeat.  *That disturbs me immensely*, and makes me feel as if I must be some unusually emotionally damaged individual, especially for having a materially privileged life, but no, the more other people I meet, the more it turns out that *life just sucks like that*, at least right now.

      [I just don't consider this a universal or eternal truth.](http://meaningness.com/kitsch)  I consider it a local trend of my local space-time, and remind myself that "final truths" and "eternal laws", as actually viewed by humans, have actually tended to change about every one to two generations.  The things I know as "eternal" will completely cease to be by the time I'm middle-aged.  Therefore, I should disregard them and press to make life and the world *better*.

      >and people deserve to die and move on to the next life to reap their karma

      Aside from [telling you there is no next life or karma](http://meaningness.com/atheism-first-step), I fail to understand how this ties in with the first part of your sentence.  If existence is mostly negative, why would it be *right* for people to go on to yet another lifetime of negativity?

      >And I believe that ethics can only be determined through philosophical insight, I think that the Is/Ought barrier is pretty strong.

      Tell us, what's the causal structure of the "philosophical insight" to which you refer?
      ```

- u/MugaSofer:
  ```
  For what it's worth: immortality and effective altruism are not "new atheist and transhumanist platforms". Immortality and charity are major components of many religions. 

  Indeed, opposition to them tends to be from either secular or explicitly atheistic grounds (not that this has any epistemic ramifications WRT whether they're good ideas.)

  In general, this sub is much more effective-altruist and transhumanist than it is atheist. If you dislike those things, I would probably not *recommend* the sub (although that doesn't mean you'd necessarily hate hate it.) There *is* "discussion challenging basic ideas of the LessWrong movement", but it's not a focus, and those ideas *are* often assumed.
  ```

- u/Roxolan:
  ```
  > will I like the discussion in this sub if I'm not a proponent of immortality, effective altruism, or other new atheist and transhumanist platforms?

  Probably not. Most of the stories being shared here, and much of the conversation about them, take the goodness of transhumanism, immortality and effective altruism for granted.
  ```

  - u/JackStargazer:
    ```
    Basically this. Rationalism is about accomplishing your goals, but many of the stories here accept immortality and altruism as the main goals worth achieving.
    ```

    - u/portodhamma:
      ```
      See, that's why I liked Worm. There was an ensemble cast with different goals largely being pursued rationally. I haven't read the Metropolitan, but I doubt many people here would side with *Lex Luthor* over Superman unless the characterization is completely changed, but people here seem to love it.


      I just want to be able to discuss some of the ideas presented in linked articles without hostility being thrown my way. Tbh, even the people who said I wouldn't like it here have been pretty polite and respectful so I'll probably be just fine.
      ```

      - u/RMcD94:
        ```
        Worm isn't widely accepted as a rational story I don't think, at least I've seen a lot of discussion over whether or not it even fits.

        > I haven't read the Metropolitan, but I doubt many people here would side with Lex Luthor over Superman unless the characterization is completely changed, but people here seem to love it.

        wat, if you haven't read it of course you have no idea why people might side with Lex Luthor in the story... That's like saying you haven't read history but have no idea why people could not like Hitler since he was such a charismatic guy.

        > will I like the discussion in this sub if I'm not a proponent of immortality, effective altruism, or other new atheist and transhumanist platforms?

        Depends what threads you read, most of the discussion is on the stories posted, and not all of them are immediately about those three things.
        ```

        - u/Bowbreaker:
          ```
          > Worm isn't widely accepted as a rational story

          I always thought that it was accepted as mostly rational but not as rational*ist*.
          ```

        - u/portodhamma:
          ```
          I do appreciate moral complexity in stories, regardless of the protagonist's beliefs. To often we see fiction with no examination of why someone thinks they're right and their enemies are wrong. I'm glad *The Metropolitan* has that more than the usual Superman tale. And you were right about me making assumptions on a work I never read.
          ```

      - u/traverseda:
        ```
        Would you feel comfortable if *one* man had unilateral control over the worlds nuclear arsenal, no matter how sane and reasonable he is?

        There is definitely room to be sympathetic to Lex Luthor. I suspect a lot of people here have less tribalism then average. You don't need to side with Lex Luthor to appreciate his competence, and you don't have to be against superman to realize that he's a potential world-ending catastrophe.

        We don't tend to side with people. There's plenty of criticism for both Lex Luthor and superman in the discussions around it.
        ```

      - u/Roxolan:
        ```
        > I doubt many people here would side with Lex Luthor over Superman unless the characterization is completely changed

        [(Broad analysis of The Metropolitan Man, not really a spoiler)](#s "It is an open question whether Lex Luthor is, on the whole, the hero of The Metropolitan Man. IIRC there have been people in /r/rational on both sides of the fence. But in rationalfics, heroes aren't necessarily nice, naive, or virtue ethicists, so that isn't incompatible with his comic book characterisation.")
        ```

        - u/Transfuturist:
          ```
          My biggest problem with canon Lex Luthor is that he declared nemesis because Superman accidentally made him go bald.
          ```

      - u/lehyde:
        ```
        I just want to have a subreddit where I can say "I don't like death" and not be attacked (the way it is in most other subreddits). I want a subreddit where atheism is taken for granted and I can discuss literature. And that is this subreddit.
        ```

        - u/BadGoyWithAGun:
          ```
          >I just want to have a subreddit where I can say "I don't like death" and not be attacked

          I agree with the general sentiment, but I don't think it's worth pursuing. Instrumental rationality overrides virtue signalling, no?

          >I want a subreddit where atheism is taken for granted

          The epistemic belief, or the accompanying ideological garbage? The former I share, the latter I reject and oppose - as a matter of fact, due to their conflation, I don't like associating with "atheism" at all.
          ```

          - u/FeepingCreature:
            ```
            > I agree with the general sentiment, but I don't think it's worth pursuing. Instrumental rationality overrides virtue signalling, no?

            It's a fuzzy, not a util. Fuzzies are important too, and the market for this one is small.
            ```

        - u/portodhamma:
          ```
          The funny thing is, I don't believe in any gods either, and I believe my stance on immortality is harder to justify than yours. There's a lot of baggage that comes with many atheists regarding scientism that I don't want to be attacked over not sharing like I would be in /r/atheism.


          You guys have been really respectful of my beliefs, so I think I might stick around.
          ```

          - u/Empiricist_or_not:
            ```
            Don't worry generally this is a place where defensible belief or honest skepticism are not attacked.
            ```

            - u/metalknight:
              ```
              It would be nice if /u/portodhamma would actually present either of those two things you mentioned.
              ```

          - u/None:
            ```
            Gonna be real here, if you bring up the word "scientism" in here you should probably expect people to call you out on it.

            If you don't, though, then we can all pretend there's no problems and talk about stories.
            ```

          - u/None:
            ```
            Holy crap, not here too. 

            Seriously, scientism isn't a thing. You cannot seriously claim to hold a rational viewpoint and still insist that there exist things outside the sphere of rational definition by the physical sciences.
            ```

            - u/FeepingCreature:
              ```
              _hugs_
              ```

            - u/None:
              ```
              > Seriously, scientism isn't a thing.

              Let me put this in Bayesian terms.  There is a *vast* difference between stating what the posterior distribution *is*, stating a predictive distribution that marginalizes out the latent variables (ie: the parameters or causal structure being inferred), and just standing there yelling that everyone needs to shut up and accept that maximum a posteriori estimator as The Truth Because Science/Bayes.

              That last thing is what sometimes gets called "scientism", and as you can see from the statements above, it's a genuine error.

              But unfortunately, the actual word "scientism" is usually just used for "the natural sciences need to stop encroaching on my field's reserved turf."
              ```

      - u/MugaSofer:
        ```
        >I haven't read the Metropolitan, but I doubt many people here would side with Lex Luthor over Superman unless the characterization is completely changed, but people here seem to love it.

        *Metropolitan Man* does feel quietly critical of many Rationalist beliefs and tropes, although it's very much internal, self-reflective criticism.

        >I just want to be able to discuss some of the ideas presented in linked articles without hostility being thrown my way. Tbh, even the people who said I wouldn't like it here have been pretty polite and respectful so I'll probably be just fine.

        Hmm. Maybe. 

        The overwhelming majority should be fine, but I do remember some people jumping down the throats of religious commenters during discussion of a fic with religious themes (*Ginny Weasley an the Sealed Intelligence*).
        ```

- u/blazinghand:
  ```
  I'm not a proponent of immortality, EA, new atheism or transhumanism and I find it fine here. Mostly we discuss works of fiction. In OT threads we typically discuss news, life strategies, personal stuff, and so on.
  ```

- u/glowingfibre:
  ```
  India isn't really a Hindu nation / America isn't a Christian nation but most of it's citizens are - as in, there's a deeply embedded  social norms against attacking non-conformers despite a majority consensus concerning belief. (But certainly no barrier to aggressively criticizing non-conforming ideas without targeting the human behind them) 

  I'd say it's roughly the same relationship of /r/rational's relationship to transhumanist/atheist/effective altruist/ lesswrongish ideologies.
  ```

- u/eaglejarl:
  ```
  A few comments for you:

  1. This sub is for discussion of fiction. This post is off-topic, despite the fact that one of our mods was polite enough to respond. 
  1. The answer to your question was in the sidebar -- the sub is about discussing fiction, not the philosophy of any particular group. 
  1. In programming circles, the response to a question like this would usually be "TIAS", meaning "Try It And See."  In other words, instead of posting this question, you would be far better served to just read some of the stories and see if you like them. 
  1. Your question eseentially boils down to "no matter how good a story is, I do not want to read it if it will expose me to certain ideas."  Given that fact, the fact that you did not read the sidebar, and your unwillingness to TIAS, I've got a fairly high prior that no, you will not enjoy this sub. I hope you will try it anyway and then tell me that I'm wrong and you actually do enjoy the fiction and community here, but that's not what I would expect to happen.
  ```

  - u/portodhamma:
    ```
    I'm actually fine with those "certain ideas" but I was wondering if every story took them as an unchallenged good.
    ```

- u/narfanator:
  ```
  I am interested on your take on why I want immortality:

  I want immortality because it seems like a pre-requisite for "fork-and-merge". That is, I want to make both choices, experience both outcomes, and then return to being a single individual. Ideally, I would like to do this without regards to time - fork myself sometime in the past, and meet them throughout the resulting "timeline".

  For example, if I'd gone with the other choice for college. Or, being pursuing two different careers.
  ```

  - u/portodhamma:
    ```
    I don't really follow. Wouldn't you need to be able to upload your consciousness also? Or do you think that immortality is the only way you can live long enough to see the aforementioned upload.
    ```

- u/mhd-hbd:
  ```
  I think a lot of the works of fiction presented on this sub has themes of:

  * Technological utopianism: the human condition can and should be improved upon with technology.
  * Transhumanism: technology can augment and improve human experience and capability.
  * Anti-deathism: death is neither necessary nor inevitable.
  * High stakes: it's about saving all of humanity's future.

  It is not always apparent, but I suspect most stories will have an end-game utopia incorporating those themes.

  Anecdotally, I would think that most people come for the litterature first, and the themes second, but this is a sub for the specific genre of fiction — sure, we have the necessary  description in the sidebar, but there is also a ‘culture’ surrounding ratfic.
  ```

- u/OutOfNiceUsernames:
  ```
  I wouldn’t like associating atheism and transhumanism with LW just as much as doing it with rationalism in general for the same reason that I don’t like EY’s influence too.

  That being said, it’s hard to make a good story in this genre if the plot\protagonists ignore things like atheism (unless it’s [flat earth atheism](http://tvtropes.org/pmwiki/pmwiki.php/Main/FlatEarthAtheist) — which, interestingly enough, was [Hariezer Yudotter’s](http://i.imgur.com/xn4cYl4.png) reaction to souls) and transhumanism. 

  Many of the stories I’ve noticed here so far also frequently deal with munchkining, loophole abuse, deconstruction of classic genres or works, and (sometimes) exploration of paradoxes and philosophical concepts.
  ```

- u/FeepingCreature:
  ```
  Having read the rest of your comments in this thread, let me start a new one.

  There's a common belief on LessWrong that beliefs require justification. That is, a complicated belief should be supplemented by a correspondingly large amount of evidence.

  Do you have evidence for your beliefs commensurate with their complexity? If not, why do you hold them and not others?
  ```

  - u/ayrvin:
    ```
    um... is posting about a 'common belief on LessWrong' a good way to respond to the original post?
    ```

    - u/FeepingCreature:
      ```
      Well, I'm sort of obliquely inviting the parent to challenge that belief if they want.
      ```

---

