## [BST] Several Ideas

### Post:

Hi r/rational! I (like many others, I imagine) have started thinking about writing rational fic as a result of HPMOR coming to an end. I'm not *particularly* likely to actually go and do it, but no harm thinking about it, right? Here are several things I'd like to see (be it from myself or others).

**Watchmen**
I would really like to see a rationalfic for Watchmen. This is challenging, partly because Watchmen is already a more-realistic take on the superhero genre, with a hero/villain who turns out to be doing whatever it takes to save the world. The most strikingly stupid-for-the-plot's-sake character is Dr. Manhattan. A version where he actually cares and gets creative would be practically unwritable, since he can do almost whatever he likes... unless others gained his powers as well.

**Dune**
Dune is ripe with possibility. The Bene Gesserit mind training could be replaced with CFAR-like techniques. The mentats, too, although I am imagining a somewhat different sort of training for the. Dune is littered with actual precognition. I'm imagining this being replaced with predictive skill, both by trained humans and by superhuman. I would like the mentats to secretly be "cheating" by coordinating their predictions without communication between them. In other words, mentats make surprisingly good predictions in part because they advise the nobility and they can predict what others with mentat training will advise. They understand advanced decision theory similar to TDT.

**A Moloch Tale**
This one would be in an original setting. I just really want to see a story directly about Moloch as described by Slate Star Codex, along with the whole pantheon of pseudo-deities in that mythos. I've got an outline of the lessons the protagonist faces, but I don't have a firm setting or real plot. The protagonist would ideally be up against the inherent disorganizing forces of the society/universe, rather than against a human villain.

== **Edit** ==
Also, feel free to ask me leading questions [word-of-god](http://www.reddit.com/r/rational/comments/2yjc41/metabst_ideas_are_cheap_writing_is_hard_can_we/) style.

### Comments:

- u/darvistad:
  ```
  The Dune one seems really interesting. Acausal agreements between mentats would be an excellent way to enforce the prohibition on thinking machines. 

  What role, if any, would melange play in this setting? Prescience, extended life, and metamorphosis into a freaky fish guy seem like an odd suite of effects, but maybe they all have a common cause. Melange could cause cells to dedifferentiate, creating a greater pool of adult stem cells and increased cell proliferation (somehow without causing cancer in the process - hence its value). Take a little, and you reverse the aging process. 

  Take more, and the proliferation of new neuronal stem cells leads to dramatically increased brain plasticity. Your brain's pattern recognition improves, but on a pre-conscious level. The result is intuitive predictions that are often uncannily accurate, but can't be verified through others' reasoning. (This isn't to say that there's a hokey conflict between reason and intuition here. Experienced melange users learn to attach confidence intervals to their strange visions, and to make sure to consciously frame problems in such a way that their [Type 1 thinking](http://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow#Two_systems) doesn't fall prey to cognitive biases.)

  Take even more melange, for a long enough period, and so much new cellular proliferation occurs that you barely even look like a human being -- or think like one. Your brain begins to resemble a powerful but untrained neural network. Trained in isolation, in an environment consisting entirely of astrophysical data and Holtzman Effect equations, you will develop an intuitive aptitude for plotting a course through foldspace.
  ```

  - u/autowikibot:
    ```
    #####&#009;

    ######&#009;

    ####&#009;
    Section 2. [**Two systems**](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow#Two_systems) of article  [**Thinking, Fast and Slow**](https://en.wikipedia.org/wiki/Thinking,%20Fast%20and%20Slow): [](#sfw) 

    ---

    >

    >In the book's first section, Kahneman describes two different ways the brain forms thoughts:

    >


    >* __System 1:__ Fast, automatic, frequent, emotional, stereotypic, subconscious

    >* __System 2:__ Slow, effortful, infrequent, logical, calculating, conscious

    >Kahneman covers a number of experiments which purport to highlight the differences between these two thought processes, and how they arrive at different results even given the same inputs. Terms and concepts include coherence, attention, laziness, association, jumping to conclusions and how one forms judgments.

    >--

    >

    ---

    ^Interesting: [^Daniel ^Kahneman](https://en.wikipedia.org/wiki/Daniel_Kahneman) ^| [^Hypocrisy](https://en.wikipedia.org/wiki/Hypocrisy) ^| [^Injustice](https://en.wikipedia.org/wiki/Injustice) ^| [^Less-is-better ^effect](https://en.wikipedia.org/wiki/Less-is-better_effect) 

    ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&subject=AutoWikibot NSFW toggle&message=%2Btoggle-nsfw+cpbz4xj) ^or[](#or) [^delete](/message/compose?to=autowikibot&subject=AutoWikibot Deletion&message=%2Bdelete+cpbz4xj)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
    ```

  - u/Quillwraith:
    ```
    This makes a lot of sense, actually. Increased brain plasticity... maybe that'd explain Juice of Sapho, too.
    ```

- u/qznc:
  ```
  Dune has the most potential imho. Watchmen is too rational already. Moloch is somewhere between reality and Lovecraft. It needs to become a lot more interesting and story-worthy somehow.
  ```

  - u/abramdemski:
    ```
    Agreed. Another big item for revision in a Dune rationalfic would be the Harkonnen. Rationalfic should not have that sort of villain.
    ```

    - u/None:
      ```
      Why not?  The Harkonnens aren't generically, bwahaha *TEH EVULZ*.  They're a combination of greedy and petty, wanting to just wring their planetary holdings for profits with maximum efficiency and not caring if they make people miserable in the process.
      ```

- u/Tiranasta:
  ```
  Personally, I'd very much like to see a take on Dr. Manhattan's vision of the future that actually makes sense.
  ```

  - u/ocassionallyaduck:
    ```
    I feel that if Dr. Manhattan was a very high level rationalist before his change, the kinds of changes we talk about here might, *might*, be possible, maybe. But his freedom to take action is constantly in question. He himself believes in predestination from the beginning.

    Very broadly speaking, with his stream of consciousness being essentially stretched over countless simultaneous moments in time, there is no possible way he could be the omnipotent figure he's often expected to be, at least at first. Decent summary from wikia:

    "Jon is not omniscient; he remains reliant on his intellect and sensory experience to reach conclusions, but his range of sensory data has been abruptly extended, "

    By the time he realizes the reach of his control, and decides to take action for the sake of someone else, regardless of his own feelings towards predestination, he has already both observed and experienced many of the results of his own actions and inactions. We are given no strict bounds for his experience, it is possible he is rippling this throughout all time even, and not just his own semi-local experience we observe. But even bound only to his own local timeline, his actions up to this point in his "life" become a singularity, as he is bound by his own observations of their results. Everything to him, is in the present. He is in the past, but he is also in the now.

    People thinking Dr. Manhattan stupid or ineffectual don't properly process the quantum nature his mental state is said to be in after the incident. He is moving forward, in his own perception of "time", but that is simultaneous and disconnected from ours. Imagine each of your eyes seeing a different image, but you still must command your body to walk in each of these places you see.

    Were he to start incredibly rational, perhaps he may have been able to take some extreme actions earlier once comprehending his new nature. This still would require "time". However he wasn't stupid, he was simply content with his existing view of predestination and his new feeling of disconnection from the human race only amplifying that. He saw his own relationship's end coming, and could not avoid it, because he didn't know how because he cannot relate to specific moments the same way any longer. However the same bounds of cognition would apply to even a skilled rationalist, and we have no idea how long even a rational mind would take to comprehend it's new nature of being. So the entire events of Watchmen could very well have unfolded just the same, only with more experimental physics on Mars perhaps. Or perhaps unconstrained by time and equally divorced from humanity, a rationalist could end the universe for the much much "greater good" we could not perceive.
    ```

- u/Quillwraith:
  ```
  Dune does seem almost perfectly suited. Mentats, strategic and political plotting, a science fiction setting without scientist in it... the possibility of UFAI would be a better justification for the 'no computers' rule than the reasons presented in the series.

  Oh, as far as rationalist Mentats, check [this](http://www.ludism.org/mentat/) out.

  How far from the original plot are you thinking? Would you be following Paul Atreides? How would he have become a rationalist?
  ```

  - u/abramdemski:
    ```
    Confession: *I am only just now reading Dune,* although I know a lot about it from years of not avoiding spoilers. I'm presently excited about it since I'm reading it, but, I don't actually know all the details.

    Yea, that link is the kind of thing I'm looking for. Because a large part of rationalist-fic is characters knowing and applying specific techniques, I'm sort of compiling different "camps" of mental/behavioral training or philosophy about people's behavior. So far:

    * Lesswrong/CFAR style rationality
    * Robin Hanson (everything is signaling!)
    * Memory Sport (memory techniques and training)
    * Mentalism (this is about cold reading and misdirection)
    * Neurolinguistic Programming
    * Nonviolent Communication
    * Behaviorism (everything is about conditioning behavior!)
    * Econ (everything is about incentive structure!)

    Some of these are questionable as schools of thought, but regardless, provide frameworks which specific characters or groups might see the world through - and generally, have techniques which those characters/groups could train in and apply in situations.

    This will allow me to have Bene Gesserit and Mentat mental training be highly distinct. Bene Gesserit would include more of the mentalism type skills, to fit with the witch image (this replaces The Voice) and discuss actual methods of cold reading. They would also have something resembling the CFAR skillset of dialog between system 1 and system 2, which would be associated with their predictive skill. Mentats would focus more on memory, mental math, and (lesswrong-style) formal rationality.

    >How far from the original plot are you thinking? Would you be following Paul Atreides? How would he have become a rationalist?

    I think it's somewhat about Paul combining different camps, rather than being really uniquely rationalist (being trained as both a mentat and a Bene Gesserit, despite prohibitions).  I think House Harkonnen needs a large redesign, being not well-suited for a rationalfic, and therefore things wouldn't be too close to the original plot.
    ```

    - u/Quillwraith:
      ```
      Yes! Different types of mental skills is definitely something I'd like to see more of; for all that I love the rationalist community, it can be a bit insular about that, at times. And it fits with the plot, too. 

      The scientific method might deserve a mention separate from Lesswrong/CFAR style rationality. Notably, it seems to be barely present in 

      You're probably giving more time to Paul's training before the plot starts per se, yes? 

      Any ideas re: Harkonnen redesign? I think [this](http://www.reddit.com/r/rational/comments/2yo1jc/bst_several_ideas/cpceu2d) take on it has some potential, though there might be more interesting options.

      This is going to be awesome. Would you happen to be interested in a proofreader/editor?
      ```

- u/None:
  ```
  >Dune Dune is ripe with possibility. The Bene Gesserit mind training could be replaced with CFAR-like techniques. The mentats, too, although I am imagining a somewhat different sort of training for the. Dune is littered with actual precognition. I'm imagining this being replaced with predictive skill, both by trained humans and by superhuman. I would like the mentats to secretly be "cheating" by coordinating their predictions without communication between them. In other words, mentats make surprisingly good predictions in part because they advise the nobility and they can predict what others with mentat training will advise. They understand advanced decision theory similar to TDT.

  Ok, personal opinion and info-dump time.

  "TDT doesn't reals."  This is why Eliezer had such a damned hard time trying to naturalize it, and why it was scrapped in favor of UDT.  Even UDT, I think, will have to be scrapped in favor of something that accounts better for logical/computational uncertainty and limited information.  *However*, TDT and UDT work very well in a setting like that of *Dune*, where precognition, and therefore "timelessness", is *actually a thing* -- FTL/wormhole-y information transmission *actually works*.

  Another thing is that *Dune* started off with a genuinely passable notion of uncertainty *about* prescient vision.  I think you should keep this: do something like *Hitchhiker's Guide to the Galaxy* and treat probability as a *dimension* in its log-odds form, with the "origin" point being 50/50 odds (maximum uncertainty) and increasingly "real" and "unreal" universes/timelines extending out towards the positive and negative infinities.  This then allows you to treat predictive probability theory as an *actual theory of prescience*, with both stochastic and computational information-gain allowing you to further and further constrain the region you're in on the Possibility/Probability of Timelines axis of the Whole Sort of General Mish-Mash.

  Of course, *Dune* is also full of all kinds of sociological fucked-upness and scheming bastardry, which doesn't appeal to me personally now that I notice it, but rationalizing how and why it all *lasts*, despite not usually working in real life, could be great fun for you.
  ```

---

