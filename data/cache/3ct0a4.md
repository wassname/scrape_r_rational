## [D] Friday Off-Topic Thread

### Post:

Welcome to the Friday Off-Topic Thread! Is there something that you want to talk about with /r/rational, but which isn't rational fiction, or doesn't otherwise belong as a top-level post? This is the place to post it. The idea is that while reddit is a large place, with lots of special little niches, sometimes you just want to talk with a certain group of people about certain sorts of things that aren't related to why you're all here. It's totally understandable that you might want to talk about Japanese game shows with /r/rational instead of going over to /r/japanesegameshows, but it's hopefully also understandable that this isn't really the place for that sort of thing.

So do you want to talk about how your life has been going? Non-rational and/or non-fictional stuff you've been reading? The recent album from your favourite German pop singer? The politics of Southern India? The sexual preferences of the chairman of the Ukrainian soccer league? Different ways to plot meteorological data? The cost of living in Portugal? Corner cases for siteswap notation? All these things and more could possibly be found in the comments below!

### Comments:

- u/Colonel_Fedora:
  ```
  So... I'm currently dealing with depression and am also one of those trans youths that live with but are not out to their parents. I've been thinking of asking for advice here for awhile, I know that that has nothing to do with the purpose of this community but the trans subreddits just... I don't know. I just feel like I actually have a philosophy in common with the people here and I need original thoughts and not the standard template of hotlines and assurances. Honestly this is one of the main reasons I wanted to start an irc, to talk about things with this group that are not just rational fic. I'm not even sure what I'm asking for here, I just really need some acknowledgement right now. Also, are there any other trans regulars or at least lurkers?
  ```

  - u/IWantUsToMerge:
    ```
    Sounds like you want freenode::#lw-support. There may actually be a few trans rationalists there already IIRC. Supportive queer rationalists, for sure, if not trans ones.
    ```

- u/Magodo:
  ```
  I'll bite, who else wants to discuss the politics of southern India?  

  Jk, but here's a rather excellent [article](http://www.nytimes.com/2015/07/05/magazine/what-happens-when-a-state-is-run-by-movie-stars.html?_r=0) on one of the most powerful politicians of India. She was recently acquitted of having disproportionate assets despite being clearly guilty.  

  Here's another excellent [post](https://www.reddit.com/r/india/comments/2ywjv0/a_tale_of_an_old_man_fiery_writer_his_mega_actor/) on another influential politician.  

  Since we're on the topic, how many of you like Bollywood movies? (mandatory plug to r/BollywoodRealism)
  ```

  - u/redrach:
    ```
    Fascinating stuff. I haven't lived in India for nearly 7 years now, it's somewhat depressing how disassociated I've become from it.
    ```

  - u/Harkins:
    ```
    I do. I've also been hearing a lot about [Salman Kahn getting bail](http://www.ibtimes.com/salman-khan-bollywood-actor-granted-bail-5-year-jail-sentence-suspended-1913814) incredibly fast while on appeal. Also been hearing about how it took [24 years to fire](http://www.independent.co.uk/news/business/news/indian-civil-servant-sacked-after-failing-to-turn-up-to-work-for-25-years-9965488.html) a government employee for absenteeism. Modi has instituted a public biometric [attendance log](http://www.attendance.gov.in).

    The common thread in all these stories is corruption, which seems a pernicious waste in India. I know there's been a lot of research into moving from low trust in institutions to high trust, but now how that's gone or what implementation looks like. That'd be a good topic for /r/rational...
    ```

    - u/Magodo:
      ```
      > research into moving from low trust in institutions to high trust

      I haven't heard of anything like this, but it's more likely I missed your point, so please elaborate.
      ```

      - u/Harkins:
        ```
        Sorry, I didn't mean to be jargony, let me unpack that.

        By "low trust" I mean the general expectation of institutions like courts, police officers, and other government offices is that the individuals inside will abuse their power to extract bribes, protect the politically powerful, and otherwise fail to execute their duties in a just and impartial manner.

        By "high trust" I mean the reverse, that the society considers it an unusual exception for civil servants and law enforcement to accept bribes or use their position in a self-serving way rather than execute the bureaucracy or laws they are expected to enforce.

        The environments are self-perpetutating. In a low-trust environment ndividuals are incentivized to pay bribes or break rules for the powerful, but the overall society would be much more successful if no one did. If the expectation is that officials are not corrupt, there are plenty of resources available to punish the few who defect.

        I have heard of tactics like [worthless bills](http://www.economist.com/news/international/21591198-increasingly-popular-weapon-fight-against-corruption-fake-money-small-change) to shame/intimidate officials who try to extract bribes as part of trying to move from a low-trust equilibrium to a high-trust one. I know there's much more out there from folks who've worked on and thought about this, but I haven't researched it. This seems like a topic /r/rational might really dig into.
        ```

- u/None:
  ```
  [deleted]
  ```

  - u/Kishoto:
    ```
    As someone who read it, I can massively agree. I think one of the most interesting parts about it was how it broke down the culture of each nation and inserted a man-sized dose of realism into the entire thing. His take on how spirituality affects their world was also really good. I preferred it more than the canon portrayal of spirituality in AtLA because, let's be honest, based on the things the spirits in AtlA could accomplish, they would definitely be more than a footnote in their respective cultures (as they are in AtlA, the Water Tribe being the exception)

    Edit: Also. The realistic take on Aang's character [](#s "you know, him throwing people into polar waters in armor, him tossing people off mountains in tanks, him being terribly ethnocentric, this one not being his fault, per se, and more a result of him not having the required training in the other nations that most Avatars get since he's, ya know, TWELVE") was AWESOME.
    ```

  - u/ToaKraka:
    ```
    I thought it was pretty cool the first time I read it--but, the second time I checked it out, I got bogged down halfway through by all the OCs, about whom I couldn't bring myself to care. Still, I may try it again, one of these days.
    ```

    - u/Kishoto:
      ```
      Yea. It really can be OC central, but I find he characterized all of them pretty well. And I still feel like the canon characters got the majority of the screentime.
      ```

- u/gabbalis:
  ```
  Does anybody else try firing energy blasts from their hands from time to time just in case?

  I mean sure rationally the odds of it actually working are infinitesimal, but I can't help thinking... maybe, just maybe, this time...

  I'm a bit concerned shonen anime tropes might be leaking into my unconscious biases.
  ```

  - u/blazinghand:
    ```
    I used to, but the wall repair expenses have gotten too high to continue testing.
    ```

    - u/fortycakes:
      ```
      Well, the username checks out.
      ```

  - u/EliezerYudkowsky:
    ```
    I took the Wizard's Oath, but that doesn't count because everyone does that.
    ```

  - u/JackStargazer:
    ```
    I will admit to reciting [Dragon Slave](http://kanzaka.wikia.com/wiki/Dragon_Slave) a few times.

    And not in situations where it would be good for it to actually work either.
    ```

    - u/None:
      ```
      When other people would make the Yao Ming "fuck that!" meme face, my girlfriend and I recite the Dragon Slave.  She wants to be Lina Inverse when she grows up.

      I have my own custom incantation for the spell.  Given how customized Dragon Slaves tend to go, everyone really ought to be very, very afraid.
      ```

  - u/jgf1123:
    ```
    I once had a dream that I could do telekinesis a la *Matilda*. And since I never remember my dreams, I thought it must be real. Then my door didn't open when I willed it.

    In my defense, I was still half-asleep.
    ```

  - u/TimTravel:
    ```
    I attempt telekinesis ever once in a while. It would be damn convenient.
    ```

  - u/Kishoto:
    ```
    The amount of extraordinary things I've tried includes (but is not limited to):


    - Naruto Ninjutsu (Katon: Goukakyuu no Jutsu being my favorite, have had the handseals memorized and perfected for about 7 years now)

    - *Hadoken*

    - *Kamehameha*

    - Super Saiyan Transformation

    - Bicycle Kick (Lu Kang, Mortal Kombat)

    - A variety of transformations (usually in which I transform from my normal self into a favored character or creature.)

    - Imagining myself being killed by an unknown supernatural agent and healing *a la* Wolverine (This one's odd because I treat the unknown agent as intelligent, so he keeps learning and trying to surpass my healing factor with a variety of techniques. He's stymied by the fact that he's ultimately imaginary).



    - Flying (inspired by DBZ, Superman and a thousand other things)

    - Corrupted by supernatural demonic energy that's slowly spreading throughout my body (Currently encompasses my entire left arm, both eyes and the part of my chest where my heart is. This corruption is indicated by a variety of imagined runic sigils)

    - The energy above is also counterpart to the energy of my right arm, which is based in nature, specifically derived from wind and wolves (essentially a Werewolf arm)

    - Multiple created personas in my mind (Currently there are two, but over my entire life, there's easily been at least 5 at any one time)



    Point of order: I'm well aware that all of the above is purely fictional and any effects they have are purely induced by the psychological stock I put into them. And even then, they'll have no real effects other than altering my behavior.

    TL;DR: **I'm a weird mofo.**
    ```

    - u/None:
      ```
      > TL;DR: I'm a weird mofo.

      Well yes, you are here.  Tell us something we couldn't guess ;-)!
      ```

      - u/Kishoto:
        ```
        Lmao. I'm weird because I'm here as in on this thread, here as in on this subreddit or am I weird because I'm here on Earth, whereas most other places in the universe can't support our known definition of life, making me a statistical anomaly if we're talking about the general universe (although i sense there's something about the Anthropic Principle I misused here) :P
        ```

        - u/None:
          ```
          All of them above!
          ```

- u/raymestalez:
  ```
  I recently have been reading Ayn Rand's books on writing - The Art of Fiction and The Art of Nonfiction (both are pretty awesome by the way) - and you know what I've realized? I loved HPMOR for many of the same reasons I loved Atlas Shrugged.

  I know that it sounds controversial, and I'm aware that a lot of people here, including Eliezer, dislike Ayn Rand. But hear me out.

  The love for reason/rationality, the idea of trying to understand the world through logic, learning the proper techniques of thinking, the very similar sense of sanity and clear, sharp thinking, attracted me to both books.

  A lot of people criticize AR for, "better than you" "arrogant" attitude from her characters, and I find it funny that many people say the same things about Harry. I'm not sure if "better than you" is a right description though. To me it sounds more like confidence in their own judgement, superior intelligemce, and ability to form their own opinions while disregarding other people's thoughts and social conventions. Or "[Arete](https://en.m.wikipedia.org/wiki/Arete)", that is, characters seeking excellence in themselves and appreciating it in others, while holding those who are lacking it with disdain. To me,  of course, that attitude is very attractive, in both Harry and Rearden.

  Both books also have characters with superhero-like intelligence and will, using their superior mental faculties, fighting morons who are in charge. Many criticize AS for unrealistically perfect heroes, but what they mean to me, is the expression of author's ideals on how humans should think and be like. Which, I think, is the case with Harry as well.

  People say John Galt's speech is too long and "preachy" but, just as Harry's thoughts on death reflecting author's philosophy, I found it one of the best parts of the book.

  The main difference in philosophy that I see, is that AR's characters are egoists, and Harry is an altruist. But you know what? Even though her ideas on selfishness get the most discussion, because they are the most controversial, I think that her main and most important ideas were about rationality and thinking for yourself, relying on your own judgement.

  I have never read anywhere a clear, rational explanation about what is so horrible about AS, from what I can tell it just makes some people angry, while other people immediately fall in love with it. Many intelligent people like hating on AR, or saying that they've "outgrown" her books, and I don't understand why.

  I absolutely loved both HPMOR and AS, both of them have been incredibly influential in my life, and are in my top 2 list of the best books I've ever read. And I was surprised to discover that, as different as they are, I loved them for many similar reasons.

  So I'm interested in your thoughts on the topic.


  P.S.

  There's another, separate thought I would also like to discuss, related to the altruism vs egoism debate.

  I would argue that at least once, Harry behaved irrationally, because of the altruism. When he was fighting against Wizengamot for Hermione, he threatened to sacrifice himself to destroy Azkaban, which got Dumbledor to back down. The alternative was to use a Dementor to fight the members of Wizengamot(maybe he wouldn't even have to kill them, just hold them hostage until he and Hermione escaped).

  If Dumbledor wouldn't cave, Harry would (probably) end up killing himself, when he had an option to fight the Wizengamot. It wasn't hard to predict that his life, even then, was more valuable than the lives of all the members of Wizengamot put together. If he would sacrifice himself instead of Wizengamot, at the end, Quirrelmort would end up winning, not to mention that Harry wouldn't defeat death, thus saving countless lives, and doing who knows how many awesome things he did after the end of the book.

  He acted altruistic and heroic, but no way it was rational to value the lives of Lucius and the like over his own, and if he was less lucky, that choice would lead to a much greater evil than killing a bunch of death eaters and creepy government officials.

  So if anyone has some cool arguments on egoism vs altruism debate, I would like to talk about that too.

  P.P.S.

  The Art of Fiction and The Art of Nonfiction are really great. Available on audible too. I'm learning to write rationalist stories, and it is pretty hard, and these 2 books have a lot of very awesome and helpful ideas.
  ```

  - u/alexanderwales:
    ```
    > I have never read anywhere a clear, rational explanation about what is so horrible about AS, from what I can tell it just makes some people angry, while other people immediately fall in love with it. Many intelligent people like hating on AR, or saying that they've "outgrown" her books, and I don't understand why.

    Using a protagonist and/or a story for spouting off philosophy, especially *political* philosophy, can often seem like cheating. I don't know if you've ever read the *Left Behind* books, but they're an extreme example of the problem that *Atlas Shrugged* and to a lesser extent *HPMOR* have. (Granted, the *Left Behind* series has many problems, some of which almost seem unique in the history of the written word.)

    The problem is that if you're the one writing, you can do whatever you want with the world. If you want to show people that all corporate executives are slimy sub-humans, you can just write one in. Presto, the personification of capitalist evil now exists for you to mock, and he can sputter at the anarchist protagonist giving a long speech on how we need to tear down all systems of control. Or you can make an atheist professor who is completely befuddled by the Christian undergrad who comes into a philosophy course believing that God exists. Because you control both sides of the argument, it's easy for "your side" to come out ahead. You can warp and twist the actions, statements, and motivations so that your side wins. It's like an extended conversation you'd have with yourself in the shower; winning is easy, because you're playing against yourself.

    (There are literary arguments to be made against *Atlas Shrugged*, such as the presence of a lengthy speech in the middle of it, and the ways in which narrative is sacrificed for political dialogue, as well as some of the prose choices and characterizations. But I think those are mostly secondary.)

    A properly written book can enrapture you, so that you don't start questioning it until it's over, and sometimes not even then. When people say that they "outgrew" *Atlas Shrugged*, what they probably mean is that the spell of the book finally wore off, and seen in the light of day ... political philosophy aside, it's not a book that most people will find a multi-year enduring appeal in. For many people, it's a book that curdles in your brain, given time - like the opposite of nostalgia.
    ```

    - u/raymestalez:
      ```
      Well, that is definitely a clear and rational explanation.

      I guess I never had a problem with the philosophy because that is what attracted me to AR's books in the first place. Some books are to entertain, some are to make a point, some are both. The purpose of Atlas Shrugged was to express Ayn Rand's philosophy, and I think she nailed it. She explicitly says that her book is about her philosophy, and that she choses events("concretes") to illustrate it, that was the whole point.

      Because I read AS for the philosophy(although I loved her writing as well), John Galt's speech was one of my favorite parts.

      Also I wouldn't say that it is really *political* philosophy. I mean she obviously talks about politics, but I've read AS as a book about personal philosophy, about thinking clearly, and looking at the world from a different angle than I was brought up with. It was really liberating and made a lot of sense to me.

      Thank you for a thoughtful reply, even though I disagree, I think I understand what you mean.
      ```

  - u/blazinghand:
    ```
    I consider Harry's strong advocacy for EY's personal beliefs in HPMOR to be a negative, rather than a positive. Pointing out that Harry does this, not just John Galt, doesn't make me think better of John Galt. 

    That being said, for all I know *Atlas Shrugged* is an excellent novel. I'm not in the category of people who would benefit from reading it, and have no interest in learning about AR's politics. I think I've figured out what I want to from Libertarian theory and taken the best parts of it into my own beliefs. Doing so did not require reading that novel.
    ```

    - u/whywhisperwhy:
      ```
      Just out of curiosity, why does using a character to advocate the author's beliefs count as a negative for you?

      Much like Atlas Shrugged, HPMoR really exposed me to a lot of beliefs that I had never heard of before and so I really count that part as a plus in addition to the rest of the story. (It did start to seem a bit like a self-insert which makes me take it less seriously but after the first section of HPMoR I felt like he largely got past that.)
      ```

      - u/redrach:
        ```
        I suppose it could come off as preachy, especially if you believe that the antagonists in the story are behaving unrealistically just for the sake of advancing the author's opinion (Not referring to HPMOR specifically here). Like writing a story populated by straw-men.
        ```

        - u/whywhisperwhy:
          ```
          Yeah, I just read AlexanderWales' comment (he goes into some depth about that) and that's a pretty valid concern... Obviously for Atlas Shrugged that *was* a bit of weakness, but I felt like even in that case the ideological battle and deciphering the meaning around characters/actions was interesting enough to compensate for that.
          ```

        - u/IWantUsToMerge:
          ```
          > I suppose it could come off as preachy

          Preach: verb: "publicly proclaim or teach (a religious message or belief)."

          So you don't like when people try to teach you things that they consider to be very important?
          ```

          - u/redrach:
            ```
            If it's via a story I picked up with no intention of seeking such information? I suppose it comes down to whether 

            a) I'm convinced by the arguments the author is making

            b) It doesn't detract from my enjoyment of the story
            ```

- u/Jon_Freebird:
  ```
  I'm intending to start university next year, probably to study psychology but I'm finding myself drawn more and more to machine intelligence research. I'm learning how to code on my own time and I think that coding + psychology is probably a good starting point but I'd love to hear any advice you care to give.
  ```

  - u/blazinghand:
    ```
    Depending on your school, there may be a Cognitive Science or Symbolic Systems major/concentration. Check that out. These fields are pretty much explicitly "coding and psychology/neuroscience" and could be very much what your'e looking for.
    ```

  - u/OffColorCommentary:
    ```
    It's pretty common for people to start with computer science + psychology with the intent of studying machine intelligence.  It's a very normal path.

    I'd recommend computer science + statistics more highly if you really want to push for machine intelligence though.  Statistics deals with uncertainty and large quantities of data.  What machine learning problem doesn't involve either of those?  An already solved one.

    I also recommend computer science and computer science + anything to everyone.  Whatever it is you want to do, you'll get more of it done with a computer.  And be paid more.
    ```

    - u/Calsem:
      ```
      My AI professor would agree with computer science + statistics rather than CS + psych.  

      She made this comparison: the brain research to AI is like the study of bird flight to airplane flight - the fields sound similar but the core techniques are drastically different.
      ```

  - u/raymestalez:
    ```
    I would definitely advise to go with machine intelligence.

    First, the most obvious thing,  is that AI and ML will be more and more valuable over time, these are very "hot" topics that will give you a lot of leverage(and $$). They are also applicable in almost any field, so you will be able to work on solving interesting problems, with almost anything you want - robotics, neuroscience, computer graphics, internet, bio, it's useful everywhere and with arrival of the internet of things and such will be even more so. Psychology - not so much.

    Second, working with AI and ML is one of the best possible ways to influence the world right now. These are rapidly evolving fields, there will be many cool discoveries in the following years. These fields have space for several Einsteins/Teslas/Turings. Will you make some important discovery in psychology? Meh.

    Also, machine intelligence is a real science that will actually make you better at thinking. In my personal opinion psychology is closer to liberal arts than to "real" sciences like math and physics. Neuroscience is important and will make a lot of progress in understanding the nature of thinking and human mind, machine intelligence too. Psychology to neuroscience is what alchemy is to chemistry.
    ```

- u/TaoGaming:
  ```
  OK, here's a somewhat on-topic question:

  I read /u/alexanderwales latest story about the AI box problem, which was interesting. In fact, before discovering /r/rational I wrote a small play on the same scenario (different twist, but nothing too left field).

  So, does everyone write one of those stories at some point?
  ```

  - u/Anderkent:
    ```
    >So, does everyone write one of those stories at some point?

    Nope, haven't written that yet and now will never do just to make sure this answer is true.

    ;)
    ```

  - u/noggin-scratcher:
    ```
    > So, does everyone write one of those stories at some point?

    Yes. Unless they die before doing so. 

    This is true of all humans... and also all non-humans. Although I'm not sure whether it holds for the non-living objects unless you extend "die" to include material destruction in general.
    ```

  - u/None:
    ```
    > So, does everyone write one of those stories at some point?

    No, some people just write a program to do it for them.
    ```

- u/HeirToGallifrey:
  ```
  I've been reading about personality types a lot recently—both MBTI and Enneagram. Does anybody know their own type? I'd be interested to see what the split is between F and T here, as I imagine it'd lean towards T.

  Or maybe nobody here puts any stock in personality types beyond an amusing diversion. If so, why?
  ```

  - u/alexanderwales:
    ```
    I'm INTJ, though I don't put a bunch of stock in it. I mean ... it's a categorization system, so might be useful in certain ways, but I'm not sure that personality typing provides much in the way of useful information to a person. It's sort of like asking if someone is a Zoe or a Zelda; yes, we can divide people up like that, but it's not clear that there's a real point to this (or that we *can* divide people up using simple binaries, since I would assume that many people fall in between extremes). This is something that I've argued with my sister over a number of times.
    ```

    - u/EliAndrewC:
      ```
      > This is something that I've argued with my sister over a number of times.

      Classic Zoe.
      ```

      - u/TaoGaming:
        ```
        Spoken like a true Zelda.

        Edit: In one more week, our long national ... not nightmare, that's too much, and now that I come to think of it, it's not really national ... so, uh, our *medium-duration regional semi-bored ennui* ends, and the second season of Bojack begins.
        ```

    - u/rpwrites:
      ```
      I like the SlateStarCodex post on MBTI: http://slatestarcodex.com/2014/05/27/on-types-of-typologies/

      It doesn't refute or address all the points you made, but it does answer some objections a lot of folks (including me) have against it. Namely, that it's nonscientific, and also that it implies a bimodal distribution for personality traits.
      ```

  - u/DataPacRat:
    ```
    Yet another https://www.reddit.com/r/intj . (And since I'm the third such, LaPlace's Sunrise Formula suggests that, barring other factors, I should be 80% confident that the fourth person to identify their MB personality type here will be the same. :)  )

    Myers-Briggs is, as far as I can tell, somewhat better at trying to gauge personality than through blood type, but less so than looking at a Facebook profile.
    ```

  - u/Chronophilia:
    ```
    INTP here, at least according to online personality tests.
    ```

- u/xamueljones:
  ```
  Does anyone have any advice they would like to tell undergrads applying to graduate school beyond the standard get good grades, join research groups, and get good recommendations?
  ```

  - u/jgf1123:
    ```
    As a grad student in UC Berkeley, I assisted my mentor, who was on the subcommittee for our field (signals and systems, within the Electrical Engineering / Computer Science department).  In short: I filtered out a lot of applicants, we discussed the rest to find a short list, he and other professors came together to decide who to make offers to (including discussing how much funding they had to spare).  That was just for our field, but I think the department/college just checked off what was decided.

    Disclaimer: I served on the committee around the start of the recession.  I was admitted to Berkeley when tech companies and engineering departments were swimming in cash.  I very likely would not have been accepted if I had applied 5 years later.  Ultimately, I found out that research isn't my thing.

    **If you read one paragraph:** know what the department wants.  At Berkeley, it's all about research potential.  I imagine that other research intensive institutions are similar.  People who didn't make our list: the guy who started and ran his own audio speaker company (he's probably better off at Stanford anyway); the person who's main accomplishment was president of the engineering society; the collegiate-level track star, despite his coach saying how hard he worked.  People who did make the cut: people who demonstrated that they have been working toward a career in research for years by working at labs and internships, working on projects, getting their names on papers and posters.  That said, authorship is not required.  We had a fair number of people whose paper was under review; or they worked on a project that would be turned into a poster/paper, but that would occur after their summer was up.  Basically, does the applicant have experience with research and show promise by contributing to a project?  (And by publications, I mean in international peer-reviewed journals, not the Chennai journal for signal processing, sorry.)

    **Recommendation letters:** Let me describe 75% of the recommendations we read.  "X was in my class Y.  He/She earned an A.  He/She seems nice and is interested in grad school.  (Left unsaid: based off a couple short conversations we had while they ingratiated themselves because we never talked before they needed a letter of recommendation.)"  These letters were immediately ignored.  If all of the letters were like this, the student generally was too.  Again, know what the department wants.  If it is a research university, they want to hear from people who supervised the research, what they contributed to the project, how fast they got up to speed, etc.  We read letters from industry with a grain of salt because, unless the manager has a Ph.D., they probably don't know what a Ph.D. program is looking for.  

    **Home institution:** For international institutions, unless the school has a strong established reputation, there is too much uncertainty as to the quality of the students.  Similarly for smaller US schools.  Students can try to argue they are a diamond in the rough, but why does a big name school need to take a risk when there are applicants from prestigious schools that excelled among their peer group?  Does this mean students from an unknown school have no chance?  No, but they have an uphill climb.  They should find an internship at an established lab to show they have the chops for the big leagues.

    **Grades:** If a student has more than a couple B's in their core courses, they'll probably be ignored.  The reasoning is that, if they're not doing that well among their peers, maybe the grad school should be considering those students instead.  Also, students should take enough of the core classes before the grad school application is due.  A transcript where most of the core classes don't have a grade because they're in their senior year indicates the student put off or is slow building toward their supposed intended career.  If your home institution does not have a strong reputation, the bar is even higher.

    **GRE scores:** We mostly ignored these.  Okay, if the applicant had a 600 math, they were eliminated immediately.  But 760-800 math is as common as dirt, so it doesn't differentiate the applicant from others.  Anecdotally, someone told me the reason they were accepted into University Kentucky was because of an 800 logic score, so take my words with a grain of salt.  But realistically, everyone applying to MIT grad school probably has an 800 math, maybe 780 if it was a bad day.  (I was so annoyed by my 780 logic score.)

    **Miscellaneous:** To be honest, we did not read the statement of purpose.  A student can say they want to research, but what is more telling is if they took steps to work toward that goal.

    Things like minority status and extracurriculars added a tilt value, but I don't remember any instance in two years where they moved someone from "no" to "yes."

    There's probably some other stuff I'm forgetting.  If you have questions, let me know.
    ```

    - u/Transfuturist:
      ```
      Well, I'm going to have nightmares for the next few years after this.
      ```

      - u/jgf1123:
        ```
        So something reassuring: My department, at least, did not accept anyone it thought couldn't hack it.  That means if you receive an acceptance letter, it's a vote of confidence that in *N* years they'll be calling you Dr. Transfuturist.  They don't intend to waste years of your time or their time to see if you bear fruit.

        I have heard some schools that accept more Ph.D. candidates than they can take and use the prelim/qual exams to filter them out.  If that concerns you, research what proportion of admissions get Ph.D., masters, or just leave.

        A Ph.D. is about a 6-year commitment during your 20's.  It's not something you do on a whim.  And getting into a big name school is not something you decide to do junior year and spend one summer working on, nor should it be.  But if you're serious, you'll probably spend your undergrad and summers exploring your chosen field, getting to understand what are the big unanswered questions and the tools in your toolbox and getting your hands dirty.  That's basically what I said above: show that you're serious by working toward it and produce something of value.
        ```

        - u/None:
          ```
          Still, I finished my MSc this past year (was never on a PhD track due to being in a system where direct-to-PhD didn't exist) and you've given *me* anxiety and impostor syndrome.

          Oh, no, wait, being a grad-student and realizing I had the wrong advisor and realizing it takes forever for my advisor's research with his students to get published because it's *crap* and realizing I'd missed out on math prereqs and having my papers rejected did that.

          Halp.
          ```

          - u/jgf1123:
            ```
            Digression: about 5-6 years into my Ph.D., when I realized that publish-or-perish academia is not my calling, I realized I still enjoy teaching and making people smarter (which is probably why I'm hanging out on /r/rational).

            Anyway, I took a class on mentoring in higher education.  That class' advice would be to find another mentor.  There is an initial cost to switching advisors (time spent figuring out a new project; department politics akin to dating your ex's roommate).  The plus side: better mental health because the path to your Ph.D. is clearer, maybe graduating faster if your current progress is really slow.  Of course, line up the new advisor before breaking it off with your old one.  Maybe do a project with the new one to see how $X$ year working with them will go.

            Things to look for in an advisor:

            * Clearly, you want them to be open to the question you want to work on.  Failing that, you want one who has a project that interests you.

            * A good working relationship.  This includes things like can you get guidance when you need it and are the deadlines and deliverables reasonable.  (Remember that relationships work both ways, so as you get help and funding, think about what they are getting out of you.)

            * After you graduate, you'll be known as their student, meaning your reputations will reflect upon each other.  It is in both of your interests that you do well after graduation, so having an advisor who can introduce you to key people and help with job placement helps (though if you were like me, graduating was a more immediate concern).

            Take the above with a grain of salt as that was the opinion of one book, written by a professor and student who my class was pretty sure were banging while they wrote the book, which might color their perception of student-mentor relationships.
            ```

- u/None:
  ```
  Well, today I managed to get into a proper Coding Flow at work and bang out some low-level networking API.  W00t!

  I also hypothesized on the train to work that causal-role concepts could be implemented computationally as something like existential types.  The nasty part then, is learning the existential package types themselves, and learning injectors from feature-governed concepts to causal-role concepts.

  I've been getting some practical things done this week, like taxes.  Oh, and actually moving forward with studying real analysis, and starting a speed-read of a textbook in denotational semantics to pick up that one kind of PL semantics I've *not* done before.

  Why?  Because by combining domain theory with probabilistic programming with Calude's anytime algorithm for the halting problem, I started sketching out an actual language design with a friend this week.  If I can manage to lift my ideas for distributions over (total) inductive types into domain-land via Calude's result... we'll have something *really interesting* on our hands.

  I'm really, really hoping this will work.  If it does, it should be, let us speak academese and understate, *publishable*.

  If we don't understate, I actually had a hot-blooded rant prepared -- the kind where you can't tell if that guy's the hero or villain or just fucking crazy.  I just feel like I've been bitten by overstating my results before I've got them too often to go into hot-blooded ranting mode yet.
  ```

  - u/traverseda:
    ```
    Can you explain it using non domain-specific language? Or at least with general non-AI programming level domain knowledge?
    ```

    - u/None:
      ```
      Ok, so.... you've heard of the Halting Problem, right?  [Well the Halting Problem is the reason that proof systems can't self-verify.](http://www.scottaaronson.com/blog/?p=710)  As Aarsonson shows, for a proof system to prove itself sound and consistent would actually involve formally demonstrating, in finite time, that it "knows" exactly which Turing machines halt and don't halt, which is exactly what the Halting Problem says can't be done in finite time.

      This is because verifying that every provable statement is actually true involves proving some statements which are formally encodings of, "So-and-so computer program doesn't halt, it loops forever."  But *formal* proof, by definition, involves a finite axiom schema (set of rules for starting with) and a finite number of proof-steps.

      You might think that, hey, lots of infinite loops can easily be detected by *looking at the code*, so why is this a problem?  Then, after all, you showed that the program doesn't halt in a finite number of proof steps (those involved in formally writing out, "I looked at it and *here* is the loop").  But you've only got a finite axiom schema, which means your formal system only knows a finite number of ways for things to provably loop forever.  But I can also write out all the axioms in your finite axiom schema, look at *those*, and construct an infinite loop that's *more complicated than them*, and which your axiom schema thus cannot detect (this method of proving something is "too large" to be described in a certain-sized set of rules is called ["diagonalization"](https://en.wikipedia.org/wiki/Cantor%27s_diagonal_argument)).  So actually, you can't write a finite piece of code that can "see" *all* the infinite loops -- that would require an *infinite* axiom schema (and where would we get that from?).

      Soooo... the advance Calude made was to provide an actual algorithm by which we can say, "Well, we ran the program for a *really fucking long time* and it *still* hasn't stopped, so we estimate a 1-p *probability* that it's just never going to stop."  This sounds quite intuitive, but actually takes a whole lot of formal machinery to demonstrate that I don't entirely understand yet due to playing catch-up on my math knowledge.

      However, armed with such an algorithm, we can start doing interesting things to it.  For instance, in programming languages theory (which is what this is, mostly), we have *total* languages (in which all programs are required to halt on all inputs), and we have *partial* languages (in which some programs can loop forever).  The kinds of type systems used in languages like ML or Haskell can, when applied to a *total* language, be used to build proof assistants based on [type theory](https://en.wikipedia.org/wiki/Type_theory) -- since every program halts, every program *proves something*.  In "real" languages, we instead have to talk about [domain theory](https://en.wikipedia.org/wiki/Domain_theory), which is basically about sets and types that might contain a special element for "loops forever".

      Notably, one of the very specific things you *can't* write in a total, typed language is the evaluator/interpreter *for that language*.  Even though it's a total language, and every program *will* terminate, it will be impossible to prove at the type-system level that the evaluator/interpreter terminates.  That self-referencing proof is "too large" for the finite axiom schema the language already has.

      But with [Calude's algorithm](https://researchspace.auckland.ac.nz/handle/2292/23906), we get around that by saying, "Hey, if it *does* terminate, we'll find out eventually just by running it long enough.  And if we didn't run it for long enough, we'll get a well-defined *probability* so that we can hedge our bets rather than just guessing and getting it wrong."  This means we should be able to build probabilistic termination checkers.  Since Calude's algorithm *segregates* halting from nonhalting behavior, we should also be able to use it to "lift" results from domains into types: we run a program that has been verified to have a domain (ie: it might return a `T`, or it might loop forever) for a long time, and then we get a well-defined distribution at the end over both the set of possible values in type `T` *and* infinite looping, which we can then lift to the *type* `P(T \/ False)`.

      Since we'll have a probabilistic termination checker, we'll also be able to write a language that puts a sound probability on the correctness of its own interpreter.

      But this is all going to take a lot of further reading and work.  We're not exactly coding anything soon, and it could all turn out to be wrong (because there's actually only a very small new idea here, which requires a lot of text to explain to a layperson).
      ```

- u/jrpguru:
  ```
  Does anybody know a math technique or something like that to generate random numbers in your head without using a computer or dice?   
  I could just pick a number at "random" but I don't think I could make it truly random that way.
  ```

  - u/Izeinwinter:
    ```
    .. No. Seriously, if you need random numbers on a regular basis, keep dice in your pocket, or install a prng on your phone. You can't execute a pseudo-random number generator in your head, and while one could work out a technique to get random numbers from whatever chaotic phenomenon happens to be in view (.. like the clouds.) it would be inferior to just carrying dice.
    ```

- u/RMcD94:
  ```
  So we do tend to live in our own little world here, though I notice a few /r/rational users out in the rest of Reddit, but what is everyone thoughts on the stepping down of Ellen Pao and the reinstatement of Steve and Alexis?
  ```

  - u/Nepene:
    ```
    The relationship between reddit and admins was somewhat poor. The relationship between users and admins has been poorer. This has been true for a long time. I'm a mod in secret mod subreddits, and on those I've seen complaints going back four years. 

    Pao became the target of a lot of that hate, and that was amplified by some poor decisions she made.

    https://www.reddit.com/r/announcements/comments/3cucye/an_old_team_at_reddit/csz2p3i?context=3

    The person responsible for the recent ama incident in question got far less hate.
    ```

  - u/Anderkent:
    ```
    Meh. Just another day of Moloch making everyone unhappy.

    The relationship between admins and mods probably is horrible, and maybe it will improve now. But once the rage machine spun up, it wouldn't be stopped; and the amount of hate expressed towards Pao is... just to be expected, I guess.

    In general, I don't think she had another choice, I don't think she was at fault at all, and I feel somewhat sorry for her.
    ```

  - u/OffColorCommentary:
    ```
    She shut down some vile subreddits, mistakenly tried to post something from her inbox, and was a woman in power.  Somehow this made her Satan.  Basic pattern recognition says that the last of those offenses was the more egregious one.

    The reactionary elements of this website are getting worse, and it worries me that this is a reflection of our society.  The correlation with reddit getting bigger and discussions getting more misogynistic could be explained by wider society having more misogynists than are normally visible, and that worries me.  There are other possible explanations, I just worry about this one.

    Her resignation message hinted that there are aggressive goals for reddit's growth and monetization in the near future.  People will freak out about the monetization part, of course.  I'm more concerned that the board still wants to push for growth in the user base when growth so far has made this place more vile over time.
    ```

    - u/None:
      ```
      [deleted]
      ```

      - u/Anderkent:
        ```
        Warning: this article was basically rewritten after it was published and popularized (http://newsdiffs.org/diff/934341/934454/www.nytimes.com/2015/07/11/technology/ellen-pao-reddit-chief-executive-resignation.html). Not sure which version you read!

        It's plausible that Pao was an easier to hate scapegoat because of her gender and race. Definitely her discrimination suit was a part of it.
        ```

  - u/None:
    ```
    >So we do tend to live in our own little world here,

    Yeah, because when I see outrage-porn, I usually have the discipline to just close the browser tab and move on.
    ```

  - u/-main:
    ```
    The timing is terrible: giving in to tantrums only teaches them that throwing a tantrum *works*. 

    If this was going to happen, it should have been a few months from now when reddit has calmed down a bit. Coming this soon after the /r/fatpeoplehate banning and the sheer volume of hatred that inspired.... I don't like the message that sends. I don't want anyone to think that the abuse that Pao received is an effective or acceptable means of advocating for change. 

    That said, I don't blame her for leaving now. I wouldn't put up with that kind of treatment.
    ```

  - u/MadScientist14159:
    ```
    I'm glad she's gone.

    Not because I thought she was a bad CEO, but because if the board of directors allowed her to resign then that means they no longer have use of her, so there aren't any more unpopular site changes coming.

    Which means maybe reddit will shut up for a while and let me enjoy the content without having to scroll through hundreds of complaints and meta-complaints.
    ```

  - u/ToaKraka:
    ```
    The whole episode (and GamerGate in general) has made me a little more leery of using Reddit; I can't say I can do much about it myself, though. I dared to set up /v/NarutoFanfiction on Voat, but it's even more dead than /r/NarutoFanfiction is, and there obviously isn't a live /v/rational there yet, either.
    ```

---

