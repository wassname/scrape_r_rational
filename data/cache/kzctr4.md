## The Entire Crystal Trilogy is now Free!

### Post:

[Link to content](http://crystal.raelifin.com/download/)

### Comments:

- u/xamueljones:
  ```
  It's also available on [Gumroad](https://gumroad.com/raelifin) as well for those who would prefer it as their source for copies.

  There is a Spanish [translation](https://artifacs.webcindario.com/obras2021.html#cristal1) of Crystal Society written by David (Artifacs) as well. Mentality and Eternity will also be eventually produced in Spanish.

  For those who don't know what the series is about, here's a summary:

  >The year is 2039, and the world is much like ours. Massive automation has disrupted and improved nearly every  industry, putting hundreds of millions of people out of jobs, and  denying upward mobility for the vast majority of humans. Wealth and  technology repair the bodies of the rich while famine and poverty sweep the world. Privately operated ventures carried humans to the moon and beyond, but space stations have become nothing but government trophies and hiding places for extremists. First contact did not bring advanced  culture and wisdom, as the aliens were too strange, lacking even mouths or normal language.  
  >  
  >Face is an artificial intelligence created to understand and gain the adoration of all humans. She and her siblings control the robot named Socrates, using a crystal computer that seems  too advanced to be made by human hands. She is learning and growing every second of every day, but the world and the humans on it are  fragile. Can it survive her destiny?

  It's a story with very well-written AI characters who genuinely come across as being non-human in their thinking and priorities, but are still relatable in spite of their inhumanity. The AIs are reasonably balanced and grow slowly enough to have challenges instead of a FOOM event where the AIs have won and taken over the world within an eye-blink. Oh, and there are some cool aliens as well I guess.
  ```

  - u/VorpalAuroch:
    ```
    > very well-written AI characters

    Debatable. They operate using an internal governance structure that is literally, *mathematically*, impossible, and as soon as they encounter meaningful obstacles (late in the first book) all of them - though also everyone around them - start behaving idiotically for no apparent reason.

    The specific result it violates is a theorem of mechanism design that a nontrivial decision mechanism cannot be incentive-compatible and have a balanced budget, i.e. no currency flows in or out. It is impossible to make a mechanism incentive-compatible if the participants have an incentive to *make the other participants spend more*, and it is impossible to remove that incentive if the mechanism is the only source and sink of currency. You must either have an external subsidizer pumping money in, or an external taxer pumping money out. Crystal instead has the auction be circular; the more strength is spent, the more is distributed to all participants. This means that Face has an incentive to, for example, make Dream pay dearly for the ability to say "Insufficient Data For Meaningful Answer", even though Face does not actually care very much and neither do their other 'siblings'. This breaks the entire structure of their internal mind, principally by entailing that all the personalities are either very stupid or engage in submodeling their sibling personalities to better predict how they will bid.
    ```

    - u/creative_ennui:
      ```
      > The specific result it violates is a theorem of mechanism design that a nontrivial decision mechanism cannot be incentive-compatible and have a balanced budget, i.e. no currency flows in or out

      Could you tell me what the theorem is named? I'd like to read more about it, and my googling isn't helping when i don't know what words to google for.
      ```

      - u/VorpalAuroch:
        ```
        I'm having trouble finding it. The closest thing I've found so far is [Holmstrohm's theorem](https://en.wikipedia.org/wiki/Holmstr%C3%B6m%27s_theorem), but I'm fairly sure there is a narrower result for public choice mechanisms which removes the 'Nash equilibrium' aspect.
        ```

    - u/Argenteus_CG:
      ```
      >This breaks the entire structure of their internal mind, principally by entailing that all the personalities are either very stupid or engage in submodeling their sibling personalities to better predict how they will bid.

      That doesn't seem like a criticism of the writing itself, though. Especially given that they explicitly aren't working as intended, and DO have to spend a fair bit of time on that sort of 'internal politics'.
      ```

      - u/VorpalAuroch:
        ```
        It is a criticism of the characterization, since the characterization is incoherent. If you're trying to write nonhuman minds that arise from odd preconditions, you have to actually think through the preconditions.

        - If the system worked as mechanism design says it must, there would be almost no reason for Face to be created since every component of Socrates's mind would already have a "theory of mind" submodule.

        - It is irrelevant whether they're working as intended, since the incoherent mechanism is *how they believe the system works*. Not how the system was *intended* to work, how it *does* work. And the system *cannot* work that way. If they have not noticed this, despite it being the most crucial and fundamental part of their environment imaginable, they are very, very stupid.

         - Literally, understanding this is the most important thing in the world for them. This is the system that limits their ability to take any action that forwards their utility function.

        - They spend no time on relevant internal politics in the first book. I have not, and probably will not, read the others, but in the first book, none. None of the facets appear to misrepresent themselves to the others at any point, and they appear to take for granted that the others are representing themselves honestly as well. Face certainly does, and Face is the one with the least excuse for failing to model the others, since her entire reason for existence is to model other minds.
        ```

        - u/Argenteus_CG:
          ```
          >If the system worked as mechanism design says it must, there would be almost no reason for Face to be created since every component of Socrates's mind would already have a "theory of mind" submodule.

          It's been awhile since I read it, but it seemed implied to me that the other facets DID have the basic ability to model each other, they just didn't have Face's interest in humans specifically. You could argue the thought processes are similar enough that it should translate, but even if that were the case, there's still enough about humanity that's different for them for it to have arguably been warranted.

          >None of the facets appear to misrepresent themselves to the others at any point, and they appear to take for granted that the others are representing themselves honestly as well.

          Again, it's been awhile since I read it, but I seem to recall at least some degree of hiding of goals.

          >Face certainly does, and Face is the one with the least excuse for failing to model the others, since her entire reason for existence is to model other minds.

          Face explicitly only cares about modelling and impressing humans, not minds in general, as revealed when dealing with the aliens towards the end of the first book. This could also explain the lack of attention to the internal politics, as if I recall, Face doesn't care much about the other facets except insofar as they're relevant to impressing humans, which explains its lack of prevalence in the story since we mostly only see Face's perspective. You could say it should still be a greater priority, but at that point it's less stupidity and more a lack of perfection.
          ```

          - u/VorpalAuroch:
            ```
            It is, again, *literally the most important thing* in their universe. It is the primary constraint on how much they get to take action toward their goals. It is an overridingly-crucial convergent instrumental goal which they all completely ignore.
            ```

            - u/Argenteus_CG:
              ```
              Fair enough, but again, technically we only really know that Face ignores it, since that's the only perspective we really get.
              ```

- u/DaystarEld:
  ```
  Going to chime in to say this trilogy was amazing. Regardless of what you hear about the third book (I also had some issues with it) I'd definitely recommend all three to everyone who even remotely enjoys sci-fi, and even people who don't.
  ```

  - u/MagicWeasel:
    ```
    Agreed, I also recommend the third book. It was the weakest of the series but still an excellent read.
    ```

  - u/Argenteus_CG:
    ```
    I liked the first one, but it really went down in quality towards the end, and the second book really didn't keep my attention at all, to the point where I never finished it.
    ```

- u/Aretii:
  ```
  I liked the first two books of this series very much, but the third lost me quite badly. Looking at Amazon reviews, it seems that others had the same issues I did. 

  Read the first two, then don't bother with Eternity, IMO.
  ```

  - u/None:
    ```
    I'd agree. My main problem was all the human POV. I'm reading the series for the amoral super AIs, not the fleshy meat bags.
    ```

- u/Food_and_Fun:
  ```
  Thanks for the heads up, I listened to the first book available on the methods of rationality podcast, and always meant to read more. 


  [book 1 audiobook ](https://hpmorpodcast.com/?page_id=1958)
  ```

- u/Discordy:
  ```
  One of the best Scifi series of the last decade. I've recommended it to several friends who have all loved it as well.
  ```

---

