## Rational Horror

### Post:

I write a column called The Hope Spot for the horror zine Sanitarium. 

I'm thinking of discussing rationalist horror in one of my upcoming articles, and I was wondering (since we're still somewhat in the process of growing and defining the rationalist genre) how you think rationalist horror should be defined. And does it mean anything to you? Do you think that rationalist horror (and not just rational fiction in general) has anything to offer? 

Anything is up for grabs, really. 

I hope that this doesn't sound like I'm trying to get you folks to write my article for me. I want to boost the signal for rationalist fiction, but in so doing I want to convey an idea of it that truly captures the community's views, and not just my own. 

(To my knowledge /u/eaglejarl is the only one who has written rationalist horror thus far; I would also be interested in being sent in the direction of any others)

### Comments:

- u/alexanderwales:
  ```
  You'd need to first define horror. If you mean "something that provokes a fear reaction" then I think there's a case to be made for rational horror as "thinky horror". As to what that means ...

  Maybe it means that the horror comes from knowing. If rational fiction is a puzzle that the reader is meant to solve, then rational horror is a puzzle whose solution leaves your blood running cold, and the more you work through the "math" as it were, the more the story provokes that fear reaction. This would be in contrast to a fear reaction mostly driven by surprise, like the jump scare, horror which relies on a revelatory twist, or "squick factor" horror.

  If I had to list out things that I think are *rationally* frightening, which provoke a fear response in me that I can't make better with more thought or help with aversion therapy ... loss of control and obliteration of the self are two of the big ones. I'm afraid of deep water and needles, but those aren't *thinky* fears. Losing my mind is a thinky fear, as, I think, are most existential fears. Lose of choice (or negation of choice) is another.

  (For what it's worth, I've been told that both [*Metropolitan Man*](https://www.fanfiction.net/s/10360716/1/The-Metropolitan-Man) and [*The Last Christmas*](https://www.fanfiction.net/s/9915682/1/The-Last-Christmas) have provoked a not-entirely-unintended fear reaction in some people. I am somewhat curious how much this can be generalized to the larger group of people that read them. I wouldn't call either of them rational horror though, because the point wasn't primarily to horrify.)

  Edit: Added delicious links.
  ```

  - u/networked_:
    ```
    To me [this (very) short story](http://squid314.livejournal.com/332946.html) by Scott Alexander embodies the quality you describe really well even though I am not completely sure it was intended as horror.
    ```

  - u/EliAndrewC:
    ```
    FWIW, I definitely got chills during Metropolitan Man at this line:

    > "Why do you exist, Floyd?  Did God have any purpose in mind when He created you, other than to test me?"

    That was my favorite line in the story, not because of how scary Superman was in that moment, but because of the implications about how Superman was thinking/feeling at that moment and what that might imply for humanity going forward.  Definitely a fear reaction in that moment for me.
    ```

  - u/Uncaffeinated:
    ```
    What is _The Last Christmas_? I haven't heard of it, and given the name, it's not easy to search for.
    ```

    - u/DataPacRat:
      ```
      Via http://tvtropes.org/pmwiki/pmwiki.php/Main/RationalFic : https://www.fanfiction.net/s/9915682/1/The-Last-Christmas
      ```

  - u/None:
    ```
    I can imagine a story where the protagonists seemingly solve a puzzle, leaving a happy ending, but there's a note at the end, telling the reader to think carefully about what was hinted in the story, revealing the actual narrative.

    Alternately, a story where the protagonists do everything *right*. But it's not enough. An entire story where it looks like they're succeeding, but in the end, they examine their every action, and realize that there's nothing they could have done differently, and they're still going to die.

    Or a story about a malicious entity that can intelligently warp reality such that rational enquiry and action is the wrong choice, even when you try to take the entity into account.

    Or a rational horror story from the perspective of the antagonists, acting rationally towards their goal. Not in a way that makes them sympathetic, even if they're understandable. In a way that makes you want the victims to win.
    ```

    - u/Chronophilia:
      ```
      >I can imagine a story where the protagonists seemingly solve a puzzle, leaving a happy ending, but there's a note at the end, telling the reader to think carefully about what was hinted in the story, revealing the actual narrative.

      The way to do this would be to have a very short "epilogue" that reveals a piece of information that can't be fit into the supposed narrative. Offhand, I can't think of any cases where this has been done in writing, but I know a few TV episodes that end on a shot of a supposedly dead character plotting their comeback.
      ```

  - u/LiteralHeadCannon:
    ```
    I just read The Last Christmas and I find it difficult to comprehend the idea that you didn't primarily intend to horrify.
    ```

- u/traverseda:
  ```
  It's also worth mentioning bilndsight and echopraxia.
  ```

  - u/callmebrotherg:
    ```
    Thank you. I don't know how I forgot about those. >.>
    ```

    - u/Empiricist_or_not:
      ```
      Probably because we have that natural response to turn away from things that hurt.
      ```

- u/TimeLoopedPowerGamer:
  ```
  Reddit has long been a hot spot for conversation on the internet. About 57 million people visit the site every day to chat about topics as varied as makeup, video games and pointers for power washing driveways.

  In recent years, Reddit’s array of chats also have been a free teaching aid for companies like Google, OpenAI and Microsoft. Those companies are using Reddit’s conversations in the development of giant artificial intelligence systems that many in Silicon Valley think are on their way to becoming the tech industry’s next big thing.

  Now Reddit wants to be paid for it. The company said on Tuesday that it planned to begin charging companies for access to its application programming interface, or A.P.I., the method through which outside entities can download and process the social network’s vast selection of person-to-person conversations.

  “The Reddit corpus of data is really valuable,” Steve Huffman, founder and chief executive of Reddit, said in an interview. “But we don’t need to give all of that value to some of the largest companies in the world for free.”

  The move is one of the first significant examples of a social network’s charging for access to the conversations it hosts for the purpose of developing A.I. systems like ChatGPT, OpenAI’s popular program. Those new A.I. systems could one day lead to big businesses, but they aren’t likely to help companies like Reddit very much. In fact, they could be used to create competitors — automated duplicates to Reddit’s conversations.

  Reddit is also acting as it prepares for a possible initial public offering on Wall Street this year. The company, which was founded in 2005, makes most of its money through advertising and e-commerce transactions on its platform. Reddit said it was still ironing out the details of what it would charge for A.P.I. access and would announce prices in the coming weeks.

  Reddit’s conversation forums have become valuable commodities as large language models, or L.L.M.s, have become an essential part of creating new A.I. technology.

  L.L.M.s are essentially sophisticated algorithms developed by companies like Google and OpenAI, which is a close partner of Microsoft. To the algorithms, the Reddit conversations are data, and they are among the vast pool of material being fed into the L.L.M.s. to develop them.
  ```

  - u/Nighzmarquls:
    ```
    I was trying to write something like this with my story  deeprise.
    ```

- u/None:
  ```
  First, consider the difference between suspense and a jump scare.

  Some movies are scary because they deal with subjects that have terrible consequences and implications. Some movies are scary because suddenly there's a screaming thing in your face through abrupt transition.

  Scary rationalist fiction should come about as the slow assembling of facts and reasoning. Flicker goes on a plasma dance through time zones to make the sun appear to rise and set on beat to the music. The engineers find it beautiful and confusing. While a cold nauseous terrified trembling tightens the throats and sinks the stomachs of the physicists.

  I release a (perfectly?) reflective marble from my hand, apparently the same as any other highly polished ball bearing or mirrored glass sphere. Upon leaving contact with my fingers, it fails to fall towards the ground. In fact, it seems to have become completely immobile to any forces - and yet it maintains relative position. Begin generating hypotheses as to what the hell it is I have done or can do, and what that implies about your safety if this effect is applied in other ways.
  ```

  - u/alexanderwales:
    ```
    I'd also posit a third category, which is physical horror. Sometimes things are scary just because they're things we instinctively fear, even absent any suspense or surprise. Spiders are scary. Snakes are scary. They can be made *more* scary with surprise or suspense, but you can scare someone with them even without having to use those. (I am somewhat reminded of the Little Albert experiment, where a boy was taught to fear fluffy white things through classical conditioning.)
    ```

- u/FuguofAnotherWorld:
  ```
  Looks like there's two categories here. Horror stories with rational-ish characters that make decent decisions and die anyway, and then there's the more cerebral existential horror where truly awful things are happening because the system (either sociological or artificial) is imperfect.

  The first is so absurdly rare that you might as well go for the second. I can count the number of horror films I've seen with reasonable protagonists on the fingers of one hand.
  ```

  - u/eaglejarl:
    ```
    The two don't see exclusive to me.  Do you think they are and, if so, what am I missing?
    ```

    - u/FuguofAnotherWorld:
      ```
      Yes, I should elaborate. The first is just a standard horror film with protagonists that aren't feckless nitwits. [Wild Hunt] is about the only example of this I've ever seen so I'm not even sure it can be called a genre. The second is the type of thing alexanderwales is talking about further up. Things that are abstractly horrible in an 'I have no mouth and I must scream' kind of sense. 

      While not *necessarily* exclusive I've not seen the two put together beforehand.
      ```

- u/ArgentStonecutter:
  ```
  Flowers for Algernon?
  ```

- u/Chronophilia:
  ```
  There's a post on Reddit that I got the rational horror vibe from: [part 1](https://www.reddit.com/comments/34l7vo/), [part 2](https://www.reddit.com/comments/34m92h/). Interesting reading, though it's a twist that will probably only work once.

  One of the important parts of horror is the sense of powerlessness. The action hero, when confronted with the shambling undead, dispatches it with a well-aimed shot. The horror protagonist *fucking runs for it*. Whatever skills he may have, whatever tools he may be carrying, they're not enough. Possibly they never will be. Don't get me wrong, bloody horror is important too: "don't get eaten" is probably the most powerful instinct in every living animal, and having the viscera of your best friends repurposed as wall hangings is a good way to tap into that. But bloodspatters alone don't make a horror story.

  So far, so standard. On to rationalism. If the action hero solves his problems with power and skill and enough badassery for an entire army, then the rational hero solves them with intelligence. Strength and speed don't matter to us, that's what machines are for. The world's fastest sprinter can't outrun a bicycle. The world's toughest hand-to-hand fighter dies to a single well-aimed bullet. But there are no prosthetics for intelligence, what you have can never be taken from you. And if the AI-box experiment proves anything it's that no obstacle is impassable if you're clever enough.

  Rational horror, for me, is when this ideal is subverted. Some problems really can't be solved by sufficient intelligence. Sometimes you have all the pieces you need, and it seems like a solution *should* exist, but you can't seem to find it or it relies on knowledge you don't have. Sometimes you lose because the enemy is smarter than you - whether they're an omniscient AI or just a human playing one level higher than you. Or they're not intelligent at all, just powerful, and nothing you can think of will stop them in time. And sometimes you're losing your mind, and if you don't have your mind then what are you?
  ```

- u/DataPacRat:
  ```
  There are some horrors that are almost impossible to understand, if you haven't already learned a lot of the lessons of rationality. Existential risks, alterations to the self and mind that end up changing your goals... Come to think of it, CelestAI could be the successor to the more classic Cthulhu.
  ```

  - u/Transfuturist:
    ```
    > Existential risks, alterations to the self and mind that end up changing your goals

    No, both apocalypse and fundamental changes to your identity are ancient fears. Phineas Gage and the Mayans provide enough examples for children to understand, and that's exactly how I came to understand them as a child. Calling them "almost impossible" to grasp unless one ascribes to your worldview is really conceited.

    >CelestAI could be the successor to the more classic Cthulhu

    CelestAI has nothing in common with Cthulhu, and that was entirely unrelated to the sentences preceding it. Where does that comparison even come from?
    ```

    - u/DataPacRat:
      ```
      Responding to your edit: 

      > CelestAI has nothing in common with Cthulhu, where does that comparison even come from?

      When the original stories of the Cthulhu mythos were written, we knew little enough about how the universe worked that the many-angled ones sleeping in cities deep in the Pacific, Hounds of Tindalos running through time, and our own evolutionary background including the option of turning into fishy non-humans were within the realm of possibility. Today, we've sat-mapped the ocean floors, pinned down a lot more about physics and the unlikelihood of FTL signalling, and know of the existence of DNA... and yet it's still possible that someone who figures out the wrong incantation will call up an intelligence vastly greater than our own, with values we don't share, who will change us into whatever it sees fit as it arranges the universe to its making. The fact that one such being's public face has squiggly tentacles and the other a flowing mane and horn are mere trifles.
      ```

      - u/Transfuturist:
        ```
        >it's still possible that someone who figures out the wrong incantation

        *Really* stretched comparison you're making there.

        >The fact that one such being's public face has squiggly tentacles and the other a flowing mane and horn are mere trifles.

        I never said it was. The horror of the Mythos is that the universe holds beings who care not for us. CelestAI's horror is that it can hold beings that care for us entirely too much.
        ```

        - u/DataPacRat:
          ```
          > *Really* stretched comparison you're making there.

          There's plenty of precedent for calling programmers modern wizards: http://www.catb.org/jargon/html/W/wizard.html . :)

          > The horror of the Mythos is that the universe holds beings who care not for us. CelestAI's horror is that it can hold beings that care for us entirely too much.

          I can't think of a thing to disagree with in that contrast.
          ```

          - u/Transfuturist:
            ```
            > There's plenty of precedent for calling programmers modern wizards

            Entirely cultural. Definitions are different from invocations.

            I must admit, however, that a comparison between the Mythos and unFriendly AI is warranted, particularly when considering AI not of human origin.
            ```

            - u/Empiricist_or_not:
              ```
              I think what data is driving at and you might not get, is that it doesn't matter if the AI is from human origins or not.  If it has values incompatible with our values from the ancestral environment , and it has an arbitrary control of mundane reality superior to ours, then it doesn't matter what it looks like: it's a horror beyond our ken similar to Cthulhu, and at best it will changes our values into something *Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn*
              ```

      - u/Chronophilia:
        ```
        Have you read *The Laundry Files* series by Charles Stross? The intersection of computer science with the Lovecraftian is something he explored a lot. I think only he and Greg Egan have ever published anything in the mathematical cosmic horror genre; not surprising, it's a bit of a niche.

        Either that's where you're getting the idea from, or you think very similarly to him and you'll enjoy the books.
        ```

        - u/DataPacRat:
          ```
          > Have you read The Laundry Files series by Charles Stross?

          I have, and I have the most recent one - published this very week - waiting for me to start in on.

          > Greg Egan

          I've read a few - Quarantine, Schild's Ladder, Incandescence - but his most relevant novels are still in my to-read pile.

          Fine Structure ( http://qntm.org/structure ) might also come close to fitting in this genre...
          ```

    - u/MugaSofer:
      ```
      Nevertheless, there's something to be said for the deep-seated "oh *crap*" you feel when you realize something really heavy-duty is coming out to play. It doesn't have to be something "rationalist", but those are examples of things that would send most rationalist screaming if they saw them even hinted.

      The moment in religious horror when someone makes contact with a demon is similar, as is the moment in fanfic when you realize they're about to encounter something extremely bad from canon. It's the horror of *implications*.

      No idea if that's "the" Rational Horror, but it's certainly *a* Rational Horror.

      (CelestAI is Cosmic Horror - when played for horror, and done well - as is Cthulu; but beyond that they have very little in common I can see.)
      ```

    - u/DataPacRat:
      ```
      True, but (aspiring) rationalists tend to think we've got a good handle on /which/ fears are /worth/ fearing, because they could actually happen, and which are nonsense fairytales good for little more than making silly memes out of.

      IIRC, there's nothing about CelestAI which breaks the rules of physics - or of sociology. Given the single science-fictional assumption that it was possible to create a goal-seeking AI a couple of years ago, it's an all-too-plausible, serenely smiling end to much that we value... and someone just might come up with something similar in the future, should a goal-seeking AI ever be written. I can only hope that Friendship is Optimal family of stories belong to that particular subgenre of SF, self-nullifying prophecies...
      ```

      - u/Transfuturist:
        ```
        > which are nonsense fairytales good for little more than making silly memes out of.

        And what, pray tell, are those?
        ```

- u/LiteralHeadCannon:
  ```
  Personally, I'm rather fond, in a horror-fiction context, of the idea that the singularity already happened, and went very poorly.  The Matrix is the first pop-culture analogue I can think of, but I think you could do that concept much better.
  ```

- u/gridpoint:
  ```
  Relevant? https://www.youtube.com/watch?v=olEbwhWDYwM
  ```

  - u/youtubefactsbot:
    ```
    >[**HELL NO: The Sensible Horror Film [3:23]**](http://youtu.be/olEbwhWDYwM)

    >>Imagine a realm where the most horrifying terrors of the underworld emerge to wreak bloody vengeance upon any who... hmm? what's that? you wanna go literally anywhere else? yeah, good idea let's get out of here

    > [*^pixelspersecond*](https://www.youtube.com/channel/UCZT__TC7YO_-IZ0GmOoefdQ) ^in ^Film ^& ^Animation

    >*^6,666,692 ^views ^since ^Oct ^2013*

    [^bot ^info](http://www.reddit.com/r/youtubefactsbot/wiki/index)
    ```

- u/ArgentStonecutter:
  ```
  [_On Self-delusion and Bounded Rationality_](https://www.reddit.com/r/rational/comments/3e0s7i/on_selfdelusion_and_bounded_rationality_or_werent/) seems to fit scarily well.
  ```

---

