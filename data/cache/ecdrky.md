## [D] Wednesday Worldbuilding and Writing Thread

### Post:

Welcome to the Wednesday thread for worldbuilding and writing discussions!

/r/rational is focussed on rational and rationalist fiction, so we don't usually allow discussion of scenarios or worldbuilding unless there's finished chapters involved (see the sidebar).  It *is* pretty fun to cut loose with a likeminded community though, so this is our regular chance to:

* Plan out a new story
* Discuss how to escape a supervillian lair... or build a perfect prison
* Poke holes in a popular setting (without writing fanfic)
* Test your idea of how to rational-ify *Alice in Wonderland*
* Generally work through the problems of a fictional world.

On the other hand, this is *also* the place to talk about writing, whether you're working on plotting, characters, or just kicking around an idea that feels like it might be a story. Hopefully these two purposes (writing and worldbuilding) will overlap each other to some extent.

^(Non-fiction should probably go in the Friday Off-topic thread, or Monday General Rationality)

### Comments:

- u/phylogenik:
  ```
  To what extent would the existence of magic hamper technological progress? A common trope in fantasy is the technologically and scientifically static society, frozen in Medieval European facsimile for millennia. Its usual explanation cites a lack of incentives -- why develop mechanical plows, public transit, or refrigeration when easily summoned spectral horses can satisfy all three needs by tilling fields, carrying you to town, and then sacrificing themselves to produce salty spectral steak?

  (sometimes there's also some tyrannical government or shadowy cabal of ancient wizards directly stymieing progress -- but often it's presented as a natural consequence of the existence of magic itself)

  But this explanation has never satisfied me much, especially in low-to-moderate, non-utopian magic settings. Often the use of magic here requires years of dedicated study, rare ingredients, and personal fortitude -- all to produce effects well within the remit of modern programming, electricity, and medicine. Why then doesn't it follow similar developmental paths to the latter? Why hasn't it been turned into a branch of engineering? Why haven't industrious magicians developed industrial processes to synthesize the active ingredients in unicorn horns and newts' eyes? And where are those curious souls driven to innovate and explore the unknown as an end in itself (perhaps all dead from tampering with unstable forces beyond their ken)?

  Some works do it differently and set stories in lands with burgeoning magitek industries. Others acknowledge external pressures, such as those mentioned in the earlier parenthetical. 

  Is there any saving the "no incentives" argument? Is the presence of a slightly easier *magical* solution enough to slow technological progress to a standstill?
  ```

  - u/alexanderwales:
    ```
    I think there's some sense in the "no incentives" argument, in that you're likely focusing on being a mage *or* being a scientist, but probably not both. Technological progress (to my way of thinking, at least) isn't caused by the need for technological solutions, it's caused by having enough capital, security, and excess population in order for a fraction of the workforce to focus on labor-saving and the acquisition of knowledge.

    So if you have mages, then rather than having a scientific and intellectual class, you have a split scientific/magical/intellectual class, and your once-in-a-generation minds that are perfectly positioned for pursuing whatever they would like will instead go for something having to do with magic rather than something to do with science or engineering. It's not necessarily that there aren't incentives for technology, since there are, it's that a society has limited people that it can put in any one direction, especially in "non-productive" directions that won't be paid off in decades or centuries. If the kingdom can fund one a single brilliant orphan and push them towards either magic or scientific inquiry, then maybe the balance is such that these brilliant orphans get pushed toward magic.

    Of course, if magic and STEM had exactly equal payouts, then this wouldn't matter too much, because you wouldn't be stuck with a medieval society, you would have a modern society that had magical solutions instead of STEM ones. So maybe if you wanted to justify a stagnant society, you would have "magic development traps" where lots of resources and people get put into magic ... which then doesn't have accelerating returns, or doesn't allow the population to support more mages/STEM, and requires agrarian society to stay how it is. Alternately, maybe magic just doesn't build on itself like STEM does, and each mage is essentially working from scratch (or close to it) rather than standing on the shoulders of giants, simply because of how magic works.
    ```

    - u/phylogenik:
      ```
      I think what I take issue with is the premise that magic and science (or scientific epistemology or engineering or whatever) are non-overlapping magisteria to begin with. Like, why aren't there "research magicians", separate from "applied magicians", looking to understand the source or mechanism of magic as just some other energy source or technology? And even if that's fundamentally ineffable or whatever, you could still make progress in applied settings. Electromagnetism, cell biology, etc. didn't get a decent description until recent centuries, but people could still make progress in, say, the theory of how plants grow. 

      I guess I can imagine a setting where magical effects are fundamentally limited by one's personal mana pool, but then I'd expect to see experiments directed at increasing that pool or harnessing ambient mana or extracting mana from animals via building-sized spell-engines or something. Maybe attempts to systematically study magic all meet mysterious ends, or cause the spark of magic to fade away etc., but that feels a bit ad hoc to me. It just seems to me like these pseudo-medieval settings still have all the appropriate ingredients for a magical Enlightenment of sorts, in most works.
      ```

  - u/None:
    ```
    I think it makes sense for tech to lag behind if the magic that exists is widespread and powerful, such that there would be no incentive to invent the technologies that lead to more innovation. So maybe if there’s a relatively common “create food” spell maybe there’s no reason for advanced farming technology. A teleportation spell of any kind would weaken the incentive for any other transportation or long range communication, and could make it completely irrelevant if the spell is easy enough. I think utilities like heating and plumbing would still see advancements over time if there isn’t any “set and forget” type spells for those purposes.
    ```

  - u/Norseman2:
    ```
    The easiest way to get magic to hamper technological progress would be to basically make it a short-term quick 'n' easy solution, but a long term trap. If magic is fairly powerful and everyone is capable of learning it, then it will be used in lieu of technology for almost everything. However, if it must be personally learned and developed, and can't really be taught or effectively have each user's techniques shared or passed down, then it will create a no-progress scenario, where each generation turns to magic out of short-term necessity but then can't make any significant advancements in the long run.

    As an example, using a magic system similar to that presented in the stories of the ''Magic: The Gathering'' setting, suppose magic depends upon each individual's memories of certain locations. The longer you spend in an area, the more easily you can draw upon the type of mana that that area provides. Live on an island for ten years while meditating about water and you can pretty easily do some water magic. Live near a volcano for ten years while meditating about fire and you can pretty easily do some fire magic. Most people in their early 20s will have already lived in some place for two decades, so with a bit of meditation they'd be able to easily start performing some significant magical feats. If magic supplants the need for most other labor or technological development, generation after generation would get stuck at exactly the same level of development.
    ```

    - u/Frommerman:
      ```
      Magic isn't a great example, though, as it has high-magitech settings like Kaladesh, Ravnica, and Phyrexia. The worlds which don't have technology are generally either always on the verge of annihilation (Innistrad, Zendikar, Amonkhet), or representative of a different point in human development (Theros, Ixalan, Kamigawa). The representative worlds don't appear to be artificially stunted, they just got a later start.
      ```

- u/MagicWeasel:
  ```
  Does anyone have good resources / pages / etc on writing interpersonal conflicts? I'm coming up on an important part of my story where the main characters have a disagreement, and it's important that it's well-written. I know why each character feels that they are in the right, and I believe that there are real people with these attitudes, so I'm more interested in how to "structure" an argument (you know... "you're wrong!" "no you're wrong!" "well you're ugly!" "no your mum's ugly", how do I write all that?). Or just... articles on arguing in general, on conflict between characters, on how to make sure that neither character becomes "unredeemable" to the readers. And on how to write resolutions. 

  Alternatively, general advice/opining on this would be good, but as I'm not really asking a specific question I think pointing me to general blog posts that have helped others would be better, probably?
  ```

  - u/None:
    ```
    It really depends on the nature of the conflict and the individual personalities, and the specific situation that turns it from a disagreement to an argument.
    ```

  - u/None:
    ```
    I've been reading nonfiction about conflict, but I wouldn't recommend much of it. Maybe Crucial Conversations by Patterson, Grenny, McMillan, and Switzler.

    But also, my advice is to just write the scene. Don't think about it too much. Then go back and revise it over and over until you like it.
    ```

  - u/grekhaus:
    ```
    I think an important realization here is that making an argument yourself and writing about two people having an argument are two different problems which involve different skills. 

    For writing an argument, step one is to decide in advance whether you'd like them to come out of it agreeing or come out of it disagreeing, and whether you'd like the two to have an amicable, grudging or resentful relationship afterwards. Note that these are largely orthogonal choices; you can have two people come to an agreement but still hate one another afterwards and you can also have people disagree but admire one another despite their dispute.

    From there, you come up with a conversational arc that A] produces this outcome, and B] remains consistent with the characterization of each arguer, C] reveals something important *about* one or more of the characters involved, and D] avoids anti-rational tropes like Can't Spit It Out or Just Talk To Each Other.
    ```

  - u/Norseman2:
    ```
    If it's a rationalist story, I'd recommend starting with the standard format for logical [arguments](https://en.wikipedia.org/wiki/Argument). Use a [deductive argument](https://en.wikipedia.org/wiki/Deductive_reasoning) if possible, or an [inductive argument](https://en.wikipedia.org/wiki/Inductive_reasoning) if not. For a conversation, you can usually skip any premises that both characters (and the reader) already know. If it's an inductive argument, it might not hurt to list and refresh memory of each of the relevant premises.

    To then make that argument sound good, you might consider reading works about how to write speeches. Wikipedia might be of use with its articles on [rhetoric](https://en.wikipedia.org/wiki/Rhetoric), [modes of persuasion](https://en.wikipedia.org/wiki/Modes_of_persuasion), and the [rhetorical techniques](https://en.wikipedia.org/wiki/Category:Rhetorical_techniques) category.

    If the character listening to the argument is also a rationalist, then I'd expect them to either agree, or identify [faulty premises](https://en.wikipedia.org/wiki/False_premise), or pick apart [logical fallacies](https://en.wikipedia.org/wiki/List_of_fallacies) between the premises and conclusion before proposing alternative possibilities, and possibly offering an entirely new argument with its own premises and conclusion. Once again, after you have the underlying argument(s) in place, you can make it sound better by employing rhetorical techniques.

    I would expect several revisions of the debate before it's going to be something that you and readers would be happy with. It's hard enough to write a convincing, enjoyable, and logically correct speech with just a one-sided perspective, so creating a proper debate between two rationalists would probably take a while.
    ```

- u/happyfridays_:
  ```
  Trying to figure out a way to balance / nerf singularity-esque ai.

  Setting is Galaxy-wide, with hard magic system mixed with FTL. 

  Current thoughts are to make magic only work for us biologicals. Make FTL require magic. And constrain the AIs to a strict deontic morality (by their choice).

  Maybe they also have to babysit a few simulated universes they errantly spun up in their youth.

  Seem plausible?
  ```

  - u/AbysmalLion:
    ```
    It does seem plausible. Some thoughts though:

    The FTL only with biological sentient works, but the question then comes, what happens when an AI starts puppeting people. What stops a machine from sticking some probes in a brain to control a biological for matter?

    Also, FTL isn't really that big of a hard limit for a "singularity"-risk AI. It can just expand the old fashion way, what prevents that?

    What happens when AIs go rouge? Can they go rogue?

    For my science-fantasy universe I simply put a limit on intelligence vs. size of brain. Which is to say one can have a sentient building, but it can't be much smarter than a human, it will have a central brain, and most of it's ability to sort through it's sensorium is "plain old software" (no sentient pattern matching all the camera feeds at once, only on ones it is "paying attention to"). Anything bigger shards into multiple personalities and sentience can't think faster than a smart human.

    My point is I think you can solve your problems:

    * Magic is special, only the actual will of the sentient will activate it.
    * Divergence of purpose when the AI separates thought, splitting up computation causes drift and internal conflicts. This is unlikely in reality, but as a universal axiom it's fine.
    * Again as a universal axiom "AIs arrive at a common morality" is fine, but I think it might need to be fleshed out a little more.
    ```

---

