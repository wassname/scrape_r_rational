## [TH] Ann Leckie's Ancillary Justice

### Post:

OK, I just read this book. It took 5 major awards this year (Hugo, Nebula, BSFA, Arthur C. Clarke, and Locus). It earned them.

First of all: my not labelling this HSF is not an accident, the 'science' here makes typical Star Wars laser sword and ray guns excesses look reasonable and well-explained, this is going full space opera 'science' where it's basically fantasy but with sci-fi aesthetics.

There's going to have to be spoilers because the plot of the book is intertwined heavily with major themes of interest to this subreddit. I am not going to spoiler text everything or discuss major plot reveals (or even that much more than the back cover of the trade paperback reveals). If you want to go completely and utterly unspoiled, go read it first. 

Major themes of this book: 

- Transhumanism, becoming different from regular humanity, the augmentation of people via technology.
- Identity and questions of self. The principal character was an AI that ran many 'bodies' at once as well as a starship, but is reduced to a single body by the start of the book. The vary effects tech has on people in the far-future is a major part of this book.
- Ethics and ethical struggles with science-fiction-based colonialism and a bunch of other similar related issues. 

There's a lot to like here. The book is fast-paced, well-written, and structured in a really nice alternating series of flashbacks; I really enjoyed the nonlinear plot and pacing and structure.  

Stuff I didn't like:

- The presentation of AI minds as like humans' minds is a little to facile and easy and so forth, and their near-universal altruism even after being effectively made into servitors and footsoldiers seems a little forced. Sometimes the lack of introspection of the lead character and their inability to understand their own emotions seemed frustrating.
- [SPOILERS: DON'T READ THIS UNTIL YOU'VE READ THE NOVEL!](#s " the ending was a little too pat and the final bit too neatly written to set up a sequel, it felt like an artificial way to get to a sequel rather than a natural resolution to the plot elements in play at that juncture of the novel. I could have bought a lot of ways for the protagonist to get away with a ship and her friend, which would not have included what actually happened. In the scenario as presented I would have been more satisfied with a resolution where the protagonist did in fact die and we got an epilogue from their surviving friend.")
- The whole gender recognition thing (where the AI protag has difficulty identifying and using appropriately gendered pronouns and comes from a culture where gender is not a major part of language. The culture without gender is fine, but the lack of recognition seems badly done. We've developed, in 2014, automatic systems that can classify people's genders based on facial images fairly accurately; with addition cues from physique and clothing and sound/speech and everything else, the whole 'I am a helpless AI who can't determine genders of people" ends up feeling like a major did not do the research failure. I mean, I suck at programming but I could still use open source tools build a haar cascade classifier to accurately classify gender of mugshots with greater than 70% accuracy pretty easily using tech mostly from 2001, I've done similar tasks as minor homework over the course of a couple weeks. It seems really silly that the space-travel sentient AI builders can't do (much!) better. I am aware it was probably trying to do some feminist point or whatever and make things more alien and different in perspective for the reader, but it still read like particularly egregiously bad SF. If they had established well that there were hundreds or thousands of different cultures on each place the protagonists went to with radically different gender norms for each, that would make it a lot more tolerable.

I mean, it's possible that in a far-future scenario like the one under discussion it's all much more confusing and you've got to deal with a super nonbinary system with inordinately complex variations where some cultures recognize many more than the traditional two genders and the like and people have changed sufficiently in sexism inherent to societies that the major clues used nowadays are not as useful (see e.g. John Varley's Steel Beach where most people change sex multiple times in their lives, have resulting complicated sexual orientations like "born male who currently prefers to be a physically-female person and looks for female-born female-presently sexual partners", or something even stranger than that - Steel Beach opens with '"In five years, the penis will be obsolete," said the salesman.'). However, I think that if such a complicated and difficult systems have arisen from cultural shifts and medical advances that you need to establish that by e.g. having some normal humans ever having trouble with it and not having the only two gender options be 'he' and 'she' and having the AI stand out by failing 50% of the time (i.e. not doing even slightly better than random luck). 

### Comments:

- u/alexanderwales:
  ```
  Alright, I think this recommendation pushes me over the edge into reading it, though I stopped when you said that there were going to be spoilers. I went to the Writer's Symposium at Gencon, and a lot of the authors there were raving about this book.
  ```

  - u/Escapement:
    ```
    The rec that pushed me over the edge to getting the book was [Charles Stross's](http://www.reddit.com/r/scifi/comments/2eozt5/how_is_it_iain_m_banks_never_won_a_hugo/ck1rq30?context=3)

    >It is, however, a stunning debut novel by a complete unknown that it has swept the award lists this year in a manner that hasn't happened since "Neuromancer" in 1986
    ```

- u/alexeyr:
  ```
  > It seems really silly that the space-travel sentient AI builders can't do (much!) better.

  1. They weren't trying to, if they even considered it at all (since they are from the same culture with its superiority complex). Why would they?

  2. The AI herself doesn't care about the issue, as far as I remember. It's possible she _could_ do better.
  ```

- u/embrodski:
  ```
  I blogged about the book soon after I read it, [here](http://www.deathisbadblog.com/themes-in-ancillary-justice/). I'm kinda unsure about etiquette at this point. Do I just leave the link here? Or should I post the entire text as a comment? It's pretty long, but I want to engage people on it, and I assume anyone reading this subreddit would rather comment on it here than at my blog. Suggestions?

  (note that the post has spoilers of the entire book)
  ```

- u/VaqueroGalactico:
  ```
  As far as the gender thing, I think it's reasonable. It's specifically mentioned in the book that different cultures have significantly different gender markers, such as length of hair and such. Relatively, earth has a monoculture as far as gender signaling goes. 

  Also, to do what you said you would need a good set of tagged data. Maybe the AI has access to this, but maybe not. Also, as far as I can tell, the AI is an artificial mind, but not a computer. I don't think she has access to the computer-interface to her brain. I don't think she can just write code and run it on herself, if that makes sense.
  ```

  - u/Escapement:
    ```
    We happen to be living in a time and place where people will consistently and for free run around and tag themselves in their own data which they will generate and upload to the internet for free and in such huge quantities that we have major difficulties processing it all. Perhaps this has biased me and my perceptions. 

    There are a lot of plausible explanations about the gender thing (ex: her programmers specifically programmed the inability/lack in to help alienate her from most major non-Radch societies and keep her distinctly Radch; or her programmers didn't care and did no real work and the AI has no ability to do such work herself; or there is far greater cultural balkanization in the far future and everything didn't descend into melting pot monocultures as the modern day seems to be doing (in spite of all the e.g. plot points about how e.g. Radch Station AI or Mianaai would recognize the habits and behaviours of one specific planet and detect fakery, and the plot points about Radch culture remaining largely invariant over a millenial timespan in spite of supposedly absorbing and being changed by constant annexation); or maybe all the computer science people were eaten by Grues in 2050 and their knowledge lost to the ages forever, or slightly more plausibly there's been some sort of Butlerian Jihad against computers and comp-sci like in Dune everywhere except the Radch military because they want to maintain a monopoly on thinking machines, and the Radch have a tiny cadre of programmers who design for the military and stations but do not innovate and do not allow their creations to mould or change themselves.

    There are *lots* of really good possible explanations one can make up; the lack of picking a *good* one (and instead rolling with 'every AI is mysteriously no good at this one specific task that it probably would help them to be good at, and furthermore they've been bad at this for literally thousands of years of experience and practice, and finally the specific task is one natural humans have done forever and also have in the real world developed computers to do back in the previous decade') therefore offends me. It's not a dealbreaker, but the specifics of the plot point bother me.
    ```

---

