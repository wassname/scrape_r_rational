## [D] Monday General Rationality Thread

### Post:

Welcome to the Monday thread on general rationality topics!  Do you really want to talk about something non-fictional, related to the real world?  Have you:

* Seen something interesting on /r/science?
* Found a new way to get your shit even-more together?
* Figured out how to become immortal?
* Constructed artificial general intelligence?
* Read a neat nonfiction book?
* Munchkined your way into total control of your D&D campaign?


### Comments:

- u/None:
  ```
  Does anyone have any techniques on how to change large parts of your personality? I have some character traits which are extremely sub-optimal.
  ```

  - u/None:
    ```
    IME, the major thing is to focus on acquiring some positive habit or practice to override the negative "traits".  You can't have a "null" personality trait.

    Tips from the s.o. are to seek help from an actual behavioral therapist and/or read about those techniques, since we've heard good things about them from friends. And to start training yourself with positive reinforcement to behave & hold attitudes more similar to how you wish you were behaving/thinking - replace negative lines of thought with preferable ones, catch yourself in unwanted behaviors and re-direct to better alternatives, and reward yourself for good days and small goals achieved. :D from "coping with anxiety ALL the time"

    Back on my own account now: yeah, Cognitive Behavioral Therapy really ought to be the first and default recommendation.
    ```

  - u/Farmerbob1:
    ```
    If you are not physically active, you might consider exercise.  Being in good physical condition can make a significant difference in your chemical balances and your emotional state.  If you are in very poor condition, it may take a lot of work to get to the point where the good aspects of being physically active will be more significant than the sore muscles and tiredness.

    In and of itself, exercise won't help you change your personality, but a lot of traits/behaviors that you do not like might be linked to your current chemical balances and physical condition. 

    If laziness or excessive procrastination is one of the traits you have, this might be a problem.
    ```

- u/TimTravel:
  ```
  I've read how bayesians describe bayesianism, I've read how bayesians describe frequentism, I've read how frequentists describe frequentism, but I've never read anything about how frequentists describe bayesianism. I feel I can't make an informed decision until I've read a criticism of bayesianism written by an intelligent frequentist or group of frequentists. Where can I find such a thing?
  ```

  - u/None:
    ```
    > I feel I can't make an informed decision until I've read a criticism of bayesianism written by an intelligent frequentist or group of frequentists.

    Why make a "decision"?  Employ statistical methods as they suit you.  It's all sigma-algebras underneath; Boolean propositional combinations are just a discrete special-case that don't need the sophisticated machinery of real measure theory to map its algebra elements onto the real unit interval.  (I guess that's a "frequentist" philosophical opinion, even though I like "Bayesian" methods better, though on the other hand, my only actual publication uses Fisherian statistics, though on the gripping hand, the publication I'm working on as a labor of love uses Bayesian probabilistic programming.)

    As it is, [here's a critique of Bayesian epistemology on grounds that it's not very good math.](http://meaningness.com/probability-and-logic)
    ```

  - u/None:
    ```
    Oh yes, and [here's](http://bactra.org/weblog/569.html) the other major critique of "Bayesianism" (Bayesian epistemology, less Bayesian statistical methods) I've read, this time by a professional frequentist statistician.  [And a longer post on rationalist Tumblr track-backed by it.](http://nostalgebraist.tumblr.com/post/83006103140/what-is-bayesianism-we-i-just-dont-know)
    ```

  - u/isitike:
    ```
    https://errorstatistics.com/ has some.
    ```

- u/LiteralHeadCannon:
  ```
  Came up with an interesting variation on the Prisoner's Dilemma which I think has interesting implications. I call it the Dilemma Of The Magi for reasons I think should be discernible.

  Two people are presented with two buttons, and each must choose to press one of them. The Rescue Button always kills whoever presses it. The Rest Button also kills whoever presses it - unless the other person presses the Rescue Button, in which case the Rest Button does nothing at all.

  I am not sure what the dominant strategy is here if there is no communication between the people involved. Societies composed entirely of cooperate-bots and societies composed entirely of defect-bots will both go extinct, while random button choosers will survive among their own kind a quarter of the time. A defect-bot introduced into a society of random button choosers will survive half the time, twice as often as the random button choosers, but the advantage disintegrates once the society is taken over by defect-bots.

  On the other hand, it seems that if there is communication between the people, altruistic behavior would be forced, as clearly one person dying (which might be you) is preferable to two people dying (one of which is definitely you), at least in the generic case. So the two people would have to argue until they could unanimously decide who should sacrifice themselves - with no decision being made until then.  This challenges our intuition that altruistic behavior is extra-rational.
  ```

  - u/electrace:
    ```
    The dominant strategy is to press rest.

    Classic game theory assumes sociopaths actors. They wouldn't care about saving someone else. Pressing rest is the only scenario that has an payoff that includes not dying, so it dominates pressing rescue.

    Yes, both defect bots and cooperate bots would die, but that has nothing to do with a dominant strategy.


    _______________________________________________________________________________

    If they aren't sociopathic, and care about the other person living, then the payoff would be functionally the same as the following matrix (assuming that they care more about themselves than the other person).



    P1 / P2| Rescue| Rest
    ---|---|----
    Rest| (3,2)| (0,0)
    Rescue| (0,0) | (2,3)

    (Note how Rescue and Rest are reversed for the other player)

    This is *functionally* the same as [battle of the sexes](https://en.wikipedia.org/wiki/Battle_of_the_sexes_\(game_theory\)) (it doesn't matter that Rescue and Rest are reversed). The best strategy in battle of the sexes is to lock in your answer (of Rest) before your opponent. In effect, forcing them to choose between killing you, or saving you, since that person's death is already assured.

    If you can't communicate that you've pressed the button, you could both agree to randomize (which only lets you live 25% of the time).

    (Edit: It occurs to me that a better strategy is for one person to randomize, and then the other person to pick the opposite, assuming it could be enforced. This leads to you living 50% of the time)

    If you can't communicate at all, (or can't enforce an agreement) then randomize based on payoffs to find the Nash equilibrium (I don't feel like doing the math, but I'm pretty sure that it would end up with you living less than 50% (and maybe even less than 25%) of the time). 

    If you can't even randomize, then the game collapses into a game where both of you end up dead, regardless of your decision.
    ```

    - u/Chronophilia:
      ```
      What I find particularly interesting in the communication-allowed unenforceable-agreements situation is that you could end up using some shared external factor as a randomizer, to prevent cheating. For example, we agree that I'll live if the test takes place between the new moon and the full moon, and you'll live if it's between the full moon and the new moon.

      Once such an agreement exists, neither player has an incentive to violate it before the other, so it's a Nash equilibrium. And that's how you can create a situation where two perfectly rational, perfectly informed actors are making decisions based on astrology.
      ```

- u/elevul:
  ```
  Can we talk about fanfictions here? I'd like to discuss the direction Power Games (Aleph/Immatrael's "rational" Nanoha fanfiction) is going.
  ```

  - u/PeridexisErrant:
    ```
    If you're discussing the rational aspects, that probably deserves its own thread - post away!

    If it feels 'off-topic', the Friday Off-Topic thread is probably the best place.
    ```

- u/None:
  ```
  Has anyone given any thought into good techniques for brainstorming? I feel like whenever I try to come up with ideas, I'm doing it in a very inefficient way, but I can't for the life of me understand how I would do it any better.
  ```

  - u/TimTravel:
    ```
    All I know is you're supposed to filter absolutely nothing, no matter how obviously terrible the idea is. I type out notes in a plain old text file because I have bad working memory and I don't want ideas to slip away a while I'm writing the previous idea. If you're running out of ideas, try drawing a thought web / directed graph of how your ideas relate. Go through each of your ideas and add the opposite / reverse / etc of the idea if that's meaningful, keeping in mind that statements can have multiple opposites (she gives letters to everyone, she takes letters from everyone, she doesn't give letters to everyone, she doesn't give letters to anyone, everyone but her gives letters to everyone, etc). If that's still not enough, try enumerating through each pair of ideas and try to come up with a way to combine them in an interesting way.

    When possible, sleep on it and come back later. Don't bother thinking about it until the next day. Sleep does mysterious magical things for brain organization.
    ```

  - u/syberdragon:
    ```
    John Cleese (Monty Python) has a [great video](https://www.youtube.com/watch?v=PQ0lck7oo4A) where he talks about effective brainstorming.  Of course, hes a comedian and an artist, so he doesn't call it any of that, but that's what it is non the less.
    ```

---

