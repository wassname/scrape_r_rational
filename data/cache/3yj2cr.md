## [D] Monday General Rationality Thread

### Post:

Welcome to the Monday thread on general rationality topics!  Do you really want to talk about something non-fictional, related to the real world?  Have you:

* Seen something interesting on /r/science?
* Found a new way to get your shit even-more together?
* Figured out how to become immortal?
* Constructed artificial general intelligence?
* Read a neat nonfiction book?
* Munchkined your way into total control of your D&D campaign?


### Comments:

- u/tvcgrid:
  ```
  I've been reading Superforecasting by Philip Tetlock (5 chapters in) and also doing a semi-simultaneous summary of it as I read (instead of the usual margin notes or whatever). Surprisingly handy to have a small, thin notebook alongside the thing I'm reading... I ended up making all sorts of asides too.

  Superforecasting is about recent findings about certain methodologies of forecasting that seem to have very good results. IARPA (apparently that's a thing now, as of '06, because of the 2002 iraq wmd fuckup it seems) conducted a tournament over 4 years to figure out if there's better ways to make forecasts. Each team had full control over how they actually produced the forecasts. Topics ranged from political to economic, domestic to international and so on, and the forecasts needed to be submitted daily (I think). The Good Judgement Project beat out everybody, even people with access to classified info, with handy margins, consistently over 4 years, and with growing effect each year. Lots of interesting details about how this was done in the book.

  Turns out, a forecast is not worth much if it's not time bound and if it doesn't pass the clairvoyance test -- if you can see the future state of the world perfectly and still can't thumbs up or thumbs down if the forecast is correct or not, it's not a good forecast. There's more to it too... using actual numbers to indicate probability and so on. Lots of tidbits and details.

  It's also a book I keep recommending to friends because of how broadly accessible it is. It nicely summarizes a whole bunch of common rationality topics like base rate neglect, regression to the mean, system 1 vs system 2 thinking, not understanding randomness, etc.
  ```

  - u/Uncaffeinated:
    ```
    How have they done since the experiment ended?
    ```

    - u/tvcgrid:
      ```
      There's a spin off organization that's running more challenges and they're actually inviting more participants. You can check it out here: https://www.gjopen.com/. The IARPA-ACE program has ended though.
      ```

  - u/DaystarEld:
    ```
    Thanks for the recommendation, I'll have to check that out once I'm through my current reading list.
    ```

- u/LiteralHeadCannon:
  ```
  Huh, the Babyeaters from Three Worlds Collide would make a pretty good one-off Rick And Morty planet. I'd watch that crossover.
  ```

  - u/SvalbardCaretaker:
    ```
    Except instead of beautiful crystaline beings they'd be even more gross meatbags than the superhappies, oozing pus and fluids from their ventral sacs everywhere.
    ```

- u/DaystarEld:
  ```
  This Place recently made a [Youtube video](https://www.youtube.com/watch?v=3MRHcYtZjFY) that's decently short (20 minutes) but goes into great and fairly engaging detail about how science works, and what's more, how rational beliefs and a rational epistemology are justified. It probably doesn't say anything new to anyone here, but if you ever meet someone that you want to introduce to concepts like "what is science" or "why science is great," it's a good video for that.
  ```

- u/iemfi:
  ```
  I've been watching [The Genius](http://bxrme.tumblr.com/tagged/the-genius) after a friend recommended it to me. Loving it so far, it's a Korean reality TV show without all the drama and nonsense and with lots of plotting and  interesting games instead. Still a lot of your usual filler but that's easy enough to skip through. Reminded me a bit of HPMOR's army battles.
  ```

  - u/Charlie___:
    ```
    Ah, someone made Liar Game the TV Show, huh?

    First game, I'm disappointed that they're not doing the obvious thing (gain the maximum points via cooperation, use randomization or threat of future punishment to keep people honest). All that talk about making the producers feel regret was, in fact, probably just prompted by the producers.
    ```

- u/LiteralHeadCannon:
  ```
  I'd like to introduce a term adjacent to taboo tradeoff: taboo analysis. A taboo tradeoff is taboo because it trades sacred values for non-sacred ones. A taboo analysis is taboo because it analyzes sacred values through a non-sacred lens. In effect, people are offended that you have tried to claim their terminal values are not terminal values, but the result of other terminal values, because this implies you could theoretically trade them off.
  ```

  - u/alexanderwales:
    ```
    Give me some examples?
    ```

    - u/Transfuturist:
      ```
      Hmmm... Participating in Christianity not because God is good, but because you are avoiding hell and seeking heaven?
      ```

---

