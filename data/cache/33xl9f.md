## [D] Enlightened Hedonism (Leftover Soup)

### Post:

A while ago, u/MugaSofer posted the webcomic Leftover Soup here: http://www.reddit.com/r/rational/comments/2czpg9/webcomic_leftover_soup/

I've since become quite a fan, and recently discovered (upon re-reading) that the author actually wrote out the life-philosophy of my favorite character.  I figured it might be of interest--it strikes me as one of the most cogent, intelligent character philosophies I've seen, not to mention that I personally agree with it entirely.  Link is below; what do you guys think?

http://leftoversoup.com/enlightenedhedonism.html

### Comments:

- u/MugaSofer:
  ```
  Similar though this is to my own philosophy, and much though I love Leftover Soup, I am now going to do a point-by-point rebuttal for my own amusement. I am large, I contain multitudes, etc etc.

  >It is self-evident that the purpose of life is the pursuit of pleasure and the avoidance of pain.

  >Note that "pleasure", here, denotes enjoyable sensations and the fulfillment of desire at any and all levels of the consciousness - the existence of masochism does not invalidate this precept.

  This is either wrong or tautological; either "pleasure" just means a being's utility function, in which case it is tautological, or it means the usual meaning of "pleasure" ... in which case it is self-admittedly wrong. In practise, this is clearly an attempt at what some people call the motte-and-bailey fallacy; definibg your terms one way and then using them another.

  >It is equally self-evident that the most powerful and effective tool possessed by human beings for the achievement of this purpose is the ability to think.

  How about hands? Or speech? If you find a way to safely wirehead, will *that* be the new Most Important Thing?

  >An enlightened person seeks higher-level pleasures over lower-level ones, and long-term pleasurable lifestyles over short-term harmful thrills.

  Long-term pleasurability versus short-term is just basic utilitarianism, obviously; but I think using it this way brushes the possibility of long-term wireheading under the carpet.

  The phrase "higher-level metapleasures" is, as far as I can tell, gibberish. It's clearly being used as code for "obviously I *actually* value lots of things other than pleasure, and when it becomes important enough I will ignore my stated principles".

  >The definition of "good" behaviour is the practice of empathy - the belief that one's own pleasure and pain are no more and no less important than the pleasure and pain of another.

  >Enlightened hedonists attempt to expand their empathy as far as possible - not only to other humans who are physically or psychologically dissimilar, but to any entity capable of experiencing sensations analogous to human pleasure and pain.

  As is, in fact, clear in the strip, this has led Max to value literally every sentient being equally; up to and including insects. The only reason this is tenable is because she apparently can't multiply.

  Still, there's not much else I can argue with here.

  >The enlightened hedonist embraces the alteration of her own consciousness in the pursuit of greater pleasure.

  >Enlightened hedonists seek out pleasure in all its forms - they embrace every taste, explore every thrill and test out every sensation available within the bounds of reason and empathy. She utilizes discipline and willpower to surmount any and all instincts, prejudices and limitations that stand between her and pleasure.

  "I will self-modify away anything that prevents me wireheading, including elements of my utility function that make wireheading less valuable to me!"

  Nobody must ever tell Max that "wireheading" isn't a metaphor, it's an actual medical procedure we've been able to do for decades :(

  >Enlightened hedonists accept the validity of choice in other entities in direct proportion to that entity's intelligence.

  >It should be noted, here, that "intelligence" means exactly that - the ability to think. It does not in any way refer to an entity's actual thinking, nor to their adherence to enlightened hedonism. Followers of other philosophies should be free to follow their philosophies.

  >Enlightened hedonists may advocate the benefits of their worldview, but they should in no way impose these beliefs on anyone capable of dissenting, except in such cases where their beliefs result in the causing of pain to others. While an enlightened hedonist's empathy may twinge in response to another entity's self-inflicted pain, she has no right to force decisions on that party, except in such cases where said self-inflicted pain is the result of ignorance or mental impairment.

  Huh, that's a pretty interesting point. I'd forgotten that was there.

  Anyway, since this only permits "self-inflicted pain", you're still trying to force literally everyone into complying with your beliefs. It sounds tolerant and open-minded, but it really, really isn't.
  ```

  - u/RolandsVaria:
    ```
    WHAT? Wireheading has been possible for decades? I thought it was just a thought experiment. I think that might qualify as an information hazard.
    ```

    - u/Transfuturist:
      ```
      The barrier to entry is literally brain surgery, so I don't think it's a particular hazard for now.
      ```

  - u/eaglejarl:
    ```
    Let me start with my definition of wireheading so we're all on the same page:

    "Artificially stimulating the pleasure center of the brain so that the individual continuously experiences the maximum physical pleasure possible for a human."

    Further, I have the following assumptions about wireheading:

    1. The recipient will resist, to the best of their limited ability, having the wire removed.
    1. The recipient is not capable of other actions while wireheading.
    1. Because of 1. and 2. the recipient will starve / thirst to death unless bodily maintenance methods have been put in place ahead of time.



    Assuming the above is what we're talking about, I've never understood why conversations about wireheading as a dangerous thing happen...or, at least, why they are dangerous for a randomly selected individual.

    On [Maslow's Hierarchy of Needs](http://capitalistexploits.at/wp-content/uploads/2014/11/Maslows_Hierarchy_of_Needs.png) physical pleasure falls somewhere around level 2.5 -- it's something you look for after security of body etc, but probably before you look for friendship and sexual intimacy (*intimacy*, not just release).  

    There are three full levels above that!  Once you start wireheading you can't seek pleasure from family, friendship, respect of others, creativity, etc.  Sure, once you're actually under the wire you won't care about any of that, but before you go under the wire you will.  It is my belief that most people will say "I'm sure this would be fun, but I'd rather have these other things."  As evidence of this belief I submit that the vast majority of humans are not heroin addicts.
    ```

    - u/callmebrotherg:
      ```
      I have to say, I am not nearly so worried about the likelihood of my, say, tripping headfirst into a wireheading chair as I am about the possibility of well-meaning hedonist utilitarians deciding that the best thing is to force everybody into those chairs. 

      Because I may not endorse the fact that my mind reacts in certain ways to pleasure over pain, but that doesn't change the fact that such a machine as you describe would still be incredibly addictive and hard to kick, much as meth and heroin are hard to kick (but less so than the wireheading, I would imagine).
      ```

      - u/eaglejarl:
        ```
        > hard to kick

        That's exactly what I said; once you're in the machine you don't care about anything else and will attempt to keep yourself from being disconnected.

        I believe that the vast majority of people will not choose to get into the machine of their own free will.

        "well-meaning hedonist utilitarians [forcing everybody] into those chairs" is a different conversation.  That's not about the dangers of wireheading, that's about the dangers of people imposing their utility function on others.
        ```

    - u/None:
      ```
      Actually, based on studies of addicts, you *will* care about all those other things after you go under the wire.  You just won't be acting in any kind of reflectively coherent goal-seeking way with regards to any goals other than wireheading: your planning functions will be hijacked to ignore all emotions but the strongest reward signal (ie: the wire).
      ```

      - u/eaglejarl:
        ```
        Okay. I'm not sure it invalidates my point, though -- the practical difference between "I care but won't do anything about" and "I don't care" is pretty small.
        ```

    - u/rthomas2:
      ```
      I'm actually very unsure as to the accuracy of that definition, and especially of the assumptions.  IIRC, animals follow the assumptions, but people don't.
      ```

      - u/eaglejarl:
        ```
        Can you explain your own definition?
        ```

        - u/rthomas2:
          ```
          Yup.  And it's only a slight difference: direct stimulation of the brain so as to provide positive/desirable feelings.

          However, that difference allows for the possibility of feeling whichever level of Maslow's hierarchy one can feel via such stimulation, thus making wireheading a lot more potentially desirable.

          Still, whatever level of wireheading we've achieved so far has produced the following:
          - Animals basically become immediate addicts
          - Humans generally report varied levels of enjoyment, mostly very high, but don't seem to show addiction
          - And in addition, regular wireheading has been shown, when done correctly, to help mitigate depression

          Note that I'm using a loose definition of addiction here...extreme compulsion might be a better phrase as pertains to accuracy.
          ```

      - u/ArgentStonecutter:
        ```
        The experiments described [in Wikipedia](https://en.wikipedia.org/wiki/Pleasure_center#Human_experiments) seem to be similar to animal models.
        ```

        - u/autowikibot:
          ```
          #####&#009;

          ######&#009;

          ####&#009;
          Section 2. [**Human experiments**](https://en.wikipedia.org/wiki/Pleasure_center#Human_experiments) of article  [**Pleasure center**](https://en.wikipedia.org/wiki/Pleasure%20center): [](#sfw) 

          ---

          >

          >Dr. [JosÃ© Manuel Rodriguez Delgado](https://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_Rodriguez_Delgado) implanted electrodes in the brains of 25 people. 

          >


          >* 1963: ["Electrical self-stimulation of the brain in man."](http://www.scribd.com/doc/6052216/Electrical-selfstimulation-of-the-brain-in-man) by [Dr. Robert Heath](https://en.wikipedia.org/wiki/Robert_Galbraith_Heath). 

          >


          >* 1972: A 24-year-old man with temporal lobe epilepsy, identified as patient "B-19". "He was permitted to wear the device for 3 hours at a time: on one occasion he stimulated his septal region 1,200 times, on another occasion 1,500 times, and on a third occasion 900 times. He protested each time the unit was taken from him, pleading to self-stimulate just a few more times... "    

          >* 1986: A 48-year-old woman with chronic pain. "the patient self-stimulated throughout the day, neglecting personal hygiene and family commitments." 


          >


          >

          ---

          ^Interesting: [^Pleasure](https://en.wikipedia.org/wiki/Pleasure) ^| [^Death ^by ^Ecstasy](https://en.wikipedia.org/wiki/Death_by_Ecstasy) ^| [^James ^Olds](https://en.wikipedia.org/wiki/James_Olds) 

          ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&subject=AutoWikibot NSFW toggle&message=%2Btoggle-nsfw+cqqblyu) ^or[](#or) [^delete](/message/compose?to=autowikibot&subject=AutoWikibot Deletion&message=%2Bdelete+cqqblyu)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
          ```

    - u/ArgentStonecutter:
      ```
      According to Wikipedia, ["More recent research has shown that the so-called pleasure electrodes lead only a form of wanting or motivation to obtain the stimulation, rather than pleasure."](https://en.wikipedia.org/wiki/Pleasure%20center) (Berridge, K.C., Kringelbach, M.L. (2008) Affective neuroscience of pleasure: Reward in humans and other animals. Psychopharmacology 199, 457-80.)

      At the very least that should make it something to be approached cautiously by would-be hedonists.
      ```

      - u/None:
        ```
        So it's really more like: wireheading creates a desire to wirehead that doesn't bring any *particular* pleasure when you wirehead, just a relief from the constant desire to wirehead.

        Or as the Buddhists would note: addiction is torture.
        ```

    - u/IomKg:
      ```
      It seems to me that either you have some other implicit assumption or something is wrong with what you are describing..

      >maximum physical pleasure possible for a human


      What other kind of pleasure is there?
      In the end any kind of positive feeling a creature can experience is physical, be it "simple" fun, such as eating something tasty, or "complex fun, such as the fulfillment of a person seeing their child succeeding and enjoying his life.
      That is unless one of your assumptions is the existence of "souls" and you decide that they do not fit the the definition of "physical

      So why wouldn't such a theoretical machine supply the person with those kind of enjoyment as well?
      ```

      - u/eaglejarl:
        ```
        > What other kind of pleasure is there? 

        There is physical pleasure (e.g orgasm) and mental pleasure (e.g. having a great time with your friends, or succeeding at a difficult task).  

        Wireheading, according to my definition, provides only physical pleasure.  It's basically super-heroin.

        > So why wouldn't such a theoretical machine supply the person with those kind of enjoyment as well?

        I'm discussing machines that could reasonably be created with existing or foreseeable technology.  I'm not discussing theoretical machines with computational engines so powerful that they can completely simulate my brain state, determine what brain states correspond to pleasure-at-difficult-job-well-done, pleasure-at-seeing-my-loved-ones-succeed, schadenfreude, etc and then find some way to overlay all of those various brain states on me at the same time without them interfering with one another.
        ```

      - u/ArgentStonecutter:
        ```
        An optimized reward system? Hopefully it won't be so crude as simply stimulating "pleasure" forever.

        From Greg Egan's "Schild's Ladder":

        > *Tchicaya is a posthuman with a quantum processor for a brain, Yann is a fully software entity currently occupying a similar posthuman body. They have been attempting to have sex, and it's not working out:*
        >
        > Yann lay on the floor, watching him. "I think I'm getting all the signals you talked about," he mused. "But they're so crude, even now. And before, it was just a single message, repeating itself endlessly: 'Be happy, be happy, be happy!' Do you think there's something wrong with this body?"
        >
        > "I doubt it." Tchicaya sat cross-legged on the floor beside him. "You expected more?"
        >
        > "I was already happy, so it was a bit redundant."
        >
        > "How happy?"
        >
        > "As happy as it's possible to be, for no particular reason."

        Wireheading is meaningless for Yann, because his reward system is already optimized. He's already as happy as it's possible to be for no particular reason. Why not?

        > "But when you have a malleable mental structure, intensifying pleasure for its own sake is a very uninteresting cul-de-sac. We worked that out a long time ago."
        ```

- u/The_Insane_Gamer:
  ```
  I like Tailsteak's work. His old webcomic 1/0 was also pretty philosophical.
  ```

---

