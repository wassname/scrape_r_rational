## If you could create a clone of yourself that will activate and take over after your death, what is the optimal time for it to wait?

### Post:

In this example, let's assume that the clone is basically in a coma until activated, and they (somehow) receive your memories. In this scenario, for whatever reason you don't want a clone of yourself running around and interfering with your life. 

To prevent the clone from waking up, you have to visit it and perform some kind of action, basically signifying, "Hey, I'm still alive", with this being your only way of preventing an early wake up. This is presumably when the memory transfer happens. The idea being that if you don't check in you're obviously dead and it's time for the clone to take over.

For the sake of more info, let's assume you face mortal danger roughly every couple months at minimum (say, you're a super hero or something).

Obviously, there's the chance that you could be incapacitated, kidnapped, or otherwise unable to make your check in. How do you balance this factor against how long the clone should wait?

I've given specific info for this example, but speculation based on different assumptions would also be welcome. 

### Comments:

- u/MrCogmor:
  ```
  Wake up the clone immediately and start getting twice the superheroing done.
  ```

  - u/dinoseen:
    ```
    Definitely a valid answer, depending on how trusting of yourself you are. Although, it wouldn't be "yourself" in the sense of what they are going to do, would it? We trust ourselves at least in part because we have control of ourselves, but you don't have control over a clone. They just naturally act the way you would. 

    Problems arise when you would act in a way that is incompatible with having a clone, thus creating a conflict. Example: you have a wife, and you only ever want a monogamous relationship. The clone also remembers having that, and wants the same things you do. 

    Even if the wife would be okay with polygamy, there's still a conflict between you and your clone, since you both want her for yourself. Either one or both of you must go without. This can obviously be extrapolated into much more lethal situations as well.
    ```

    - u/melmonella:
      ```
      So change your views on polygamy until you are fine with sharing with a copy of yourself and don't miss on a times two (can you make more clones? Potentially times many more) efficiency multiplier on everything you do. Defecting on a literal copy of yourself for any reason seems like a really dumb idea to me. At worst, you can always flip a coin and let random chance decide which one of you copies is going to do a thing.
      ```

      - u/GeneralExtension:
        ```
        >Defecting on a literal copy of yourself for any reason seems like a really dumb idea to me.

        (That'd make for an interesting murder mystery - on the one hand, if duplicates of you are dying you're a suspect. On the other hand, the culprit could be...another one of your clones.) 

        What if *you* have to pay the price - the clone stays, but you go? (Or more generally, the clone decides how things are resolved.)

        &#x200B;
        ```

        - u/melmonella:
          ```
          I don't understand the question. There is no meaningful difference between you and your clone, and both of you know that. Whomever decides will arrive at the same decision, what with having the same information at their disposal and the same patterns of thinking.

          Unless there is a practical difference between you and the clone a-la Simulacra in MoL, in which case again, both of you know the clone is more expendable and both would be okay with it.
          ```

          - u/Anderkent:
            ```
            > There is no meaningful difference between you and your clone, and both of you know that

            This is a big assumption that needs to be shown.

            >Unless there is a practical difference between you and the clone a-la Simulacra in MoL, in which case again, both of you know the clone is more expendable and both would be okay with it.

            Being 'more expendable' doesn't necessarily mean you are okay with it. In fact an 'expendable' clone has a lot of incentive to find other ways to survive, which puts it at odds with the original.
            ```

            - u/melmonella:
              ```
              > This is a big assumption that needs to be shown.

              What is there to show? Same memories, same personality, same ideals, same goals, same everything except position in space. You'd probably make an interference pattern if someone threw you through a double slit experiment for people. What's the meaningful difference here?

              > has a lot of incentive to find other ways to survive

              I genuinely don't understand this. Clone knows the same things you know. If a third party knocked you and the clone out at the moment of cloning, and then put you in a room together without either of you knowing (both have only memories up til the moment of cloning, and wake up in the same room but on opposite sides) which one is the "original", there would be no way for either of you to tell which one was the "original" without analysing the body composition. Ergo, both have the same goals of insuring their mind state keeps existing into the future, and their goals get accomplished. That can be accomplished by sending the clone into danger while keeping the squishy original holed up in a bunker, because original is necessary to make clones in the future. What kind of insanity would your clone have to be under to decide "no, you know what, I am not going to do this thing I have just decided I should do, I am instead going to risk my survival and indeed the survival of any possible copy of myself by attacking the original and attempting to chance into some kind of permanent life for myself by killing myself."

              As for emotional impact of death, I frankly consider myself to be emotionally stable enough to not freak out in this situation, and be capable of braving mortal danger when I have physical proof that some copy of me will stay undamaged. If hundreds of thousands of soldiers can charge enemy lines *without* any kind of assurance besides a glass of vodka beforehand and following orders from a general they never even seen, I damn well should be capable of doing the same *with* rock solid assurance in order to achieve my own personal objectives.
              ```

  - u/callmesalticidae:
    ```
    Or just, like, have myself^clone kill myself^original, which I imagine would be incredibly cathartic.
    ```

- u/vaegrim:
  ```
  The distrust of what is essentially a copy of yourself is really bizarre to me. That said, I'm willing to take the scenario at face value. 

  My answer is that the ideal set-up allows for early check-ins. If your "adventures" mostly stay in the same city and threats are likewise local: I'd use a four week wake-up timer that I reset every week. If your threats are likely to use planes, I'd double the length; and double again for fantastic-four style interdimensional/interplanetary shenanigans.
  ```

  - u/None:
    ```
    [deleted]
    ```

    - u/vaegrim:
      ```
      That mode of thinking is so alien to me as to be incomprehensible. Person A and Person B are the same person; they both have the same wife, child, family, friends, job, and passport. This single person just happens to occupy two places at the same time and can't remember half of his life as of the instant of divergence.

      Killing your clone would be like building an elaborate death trap over your bed on the off-chance that, next morning you forget you did so the night before and so were **a di^ffe^rent p^ers^on no^w**!
      ```

      - u/callmesalticidae:
        ```
        Yeah. I'd *love* to have a double. I could take breaks while ensuring that there was somebody still doing work (we'd switch off, obviously; I wouldn't want to be taken advantage of, so my duplicate wouldn't want to, either).
        ```

        - u/melmonella:
          ```
          Would take some time to figure out how to deal with needing twice as much money for food while only having one ID to get a job with, but yeah, should still be an awesome benefit.
          ```

          - u/callmesalticidae:
            ```
            I'd probably look into freelancing.
            ```

      - u/dinoseen:
        ```
        In this example, if they're clones of someone like you, then obviously the clones would get along fine. 

        But our lives are obviously ruled by much more than just our own perspective. 
        Philosophically, sure, you're the same person (at least at the start), but socially? I would wager in a society where clones aren't widespread (like ours, and most superhero fiction), people would not think of you and your clone as the same person in all ways. 

        Would your wife and kids really be okay with having two dads? Since you selected/raised them, quite possibly, but it's no guarantee.

        Perhaps a way to try understanding this way of thinking is that there is only so much "social space" in relationships. Most people just aren't going to be able to think of both of you as one person. There's only enough space in their conception of "you" for one individual, not two individuals who are the same. They will treat you and the clone differently, and thus socially you will basically be different people. Obviously not everyone will act in this way, but I would say definitely enough people to make an impact would.
        ```

      - u/CCC_037:
        ```
        > Person A and Person B are the same person; they both have the same wife, child, family, friends, job, and passport. This single person just happens to occupy two places at the same time and can't remember half of his life as of the instant of divergence.

        What are your criteria for being 'the same person', then? It can't be memory, or the clone would diverge into its own person after some time. I doubt it's DNA, or truly identical twins would count as one person with a very odd case of amnesia.

        So what are your criteria?
        ```

        - u/vaegrim:
          ```
          I am everyone who both believes they are me and agrees with this sentence.
          ```

          - u/CCC_037:
            ```
            So, in the case where your clone runs into a rogue philosophy professor and is persuaded that the above sentence is false, then you are no longer the same person as your clone because your clone no longer agrees?
            ```

            - u/vaegrim:
              ```
              That's correct. If the clone either believed it was someone else, or no longer accepted the contagious nature of my identity I'd consider it a fundamentally different person.
              ```

              - u/CCC_037:
                ```
                Fair enough. What would you think about Crazy Dave, who believes he is you (but shares none of your memory, DNA, or anything else)?
                ```

                - u/vaegrim:
                  ```
                  Again, correct. If Crazy Dave happened to know, understand and accept my self-definition then Dave and "Crazy Dave" are just Daves separated by space and experience.

                  In the same way that if Dave's mind gets uploaded into a time-traveling robot and goes to the past during a time when Dave had amnesia, both amnesia-Dave and robot-Dave are still ultimately Dave. 

                  If my name wasn't Dave, I'm not sure I'd believe he was me if he insisted on calling himself "Crazy Dave" though.
                  ```

                  - u/CCC_037:
                    ```
                    Huh. Well, your definition is strange to me, but it certainly seems self-consistent, at the very least.
                    ```

    - u/The_Magus_199:
      ```
      I mean... why would person A bother making a clone of himself to be woken up when he dies? If he’s selfish, then why would he care about making a clone to wake up once he’s no longer capable of experiencing the world himself?
      ```

      - u/xland44:
        ```
        My explanation was more in general for why having a clone isn't always good, but to answer your question:

        It could be that he *didn't* have the clone be made voluntarily. Perhaps made as a scheme by an enemy, and it's all he can do to delay the clone from being released. Also, if the clone's location is also hidden, he can't destroy it.

        If you've read Worm, it could be a clone that has been altered to hate his progenitor and everything they stand for. Said clone also has the original's memories, which means he can easily come up with ways to ruin their lives.
        ```

  - u/Izeinwinter:
    ```
    It is not necessarily distrust. If forking is possible, I would expect there to very shortly to be very severe penalties for doing it. Up to and including "We are going to shoot you on sight until we are sure there is at most one copy of you, and we will not be making *that* much of an effort to make sure we do not get the count wrong". 

    Because unrestricted forking has predictable horrible outcomes on a society wide level.
    ```

- u/Sparkwitch:
  ```
  There are so many different arguments that are more or less equally valid that I think the best answer is whatever makes the story most interesting.

  Personally, I'd check up on the clone as often as possible and have something like a week before it wakes up. Wherever it's located I'd have a computer or something on which I could archive what was happening in my life. Something I could email with updates even if I wasn't able to visit. Ideally I'd have somebody I trust doing the same thing whether I'm alive or not.

  If the clone waking up when I'm still alive is that much of a problem I'd have to establish some network of allies who could rescue me from situations who would be on a similar but smaller deadman switch. If the clone wakes, not only have I died but the other options have failed.

  They can be on a short timer, because the consequences of having my friends go out looking for me aren't as disastrous as if my clone wakes, right? Five days should be enough time for them to resolve most non-James Bond situations.
  ```

- u/Xtraordinaire:
  ```
  It depends on what you expect the clone to do. If you want it to take on next monthly mortal danger lest you fall, then the answer is
  rather trivial. Less than a month, and while you are alive you check up on it daily. 

  In fact, it is better to have a cascade of clones, set to irregular intervals after the first one, preferably violating the 'no doubles' rule. For your nemeses it looks like this. 1 - you are killed. 2 - ~2 weeks later a clone arrives and tries to finish them off and resume the normal routine. If it fails, 17 weeks later five clones arrive, and take on the danger with overwhelming force. You are dead, let *those five shmucks* deal with the inconvenience of copies of themselves 'interfering with their life'.
  ```

- u/Trips-Over-Tail:
  ```
  At the very least you want a Google news alert for your obituary. The law has a system to decalre the missing "legally dead" but that also goes wrong sometimes. There's no real way to guarantee that you're dead without your body, and if you're limiting commands to your personal check-in and a timer, which is essentially how the law does it, then you are going to run the risk.

  I just want to have it barge in halfway through my funeral. "I object!"
  ```

- u/wndering_wnderer:
  ```
  Have a wearable or implantable device which continuously monitors your vitals. Device & device communications should be secure. Device continuously sends out a signal to let it be known that you are alive. In the event that *all* your vitals flatline, the device sends out a signal to state that you are dead. In the event that the device does not send a signal for x days (depending on whether you are Superman, fighting across worlds, or Batman, fighting within the city) the clone activates and investigates your disappearance. Need to consider the event where your device sends out signals indicating incapacitation but not death, for y days without improvement. Solution is contingent on the device bring tougher than your body.
  ```

  - u/Nimelennar:
    ```
    I think you'd pretty much need something like this anyway for the clone to "receive your memories."  So, when the clone stops receiving memories for, say, a week, wake it up.
    ```

- u/EthanCC:
  ```
  Depends on the situation. Are you a villain who is a big enough threat that the entire world will unite against you? Wait a few generations. Are you a hero who needs to be constantly saving the world? Wait a day at most, you can't afford to be gone too long even if it means forking yourself.




  The best solution is probably to get someone you trust to activate the clone when *they* think you're dead. After all, they can react to a fluid situation better than an algorithm.
  ```

- u/RMcD94:
  ```
  Why would you not want to make your clone wake?
  ```

  - u/dinoseen:
    ```
    You could argue that it would interfere with your life. While I understand many would not feel this way, the point of this post is more to ask how people would act if they *did*.
    ```

---

