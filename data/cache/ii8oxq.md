## [D] Friday Open Thread

### Post:

Welcome to the Friday Open Thread! Is there something that you want to talk about with /r/rational, but which isn't rational fiction, or doesn't otherwise belong as a top-level post? This is the place to post it. The idea is that while reddit is a large place, with lots of special little niches, sometimes you just want to talk with a certain group of people about certain sorts of things that aren't related to why you're all here. It's totally understandable that you might want to talk about Japanese game shows with /r/rational instead of going over to /r/japanesegameshows, but it's hopefully also understandable that this isn't really the place for that sort of thing.

So do you want to talk about how your life has been going? Non-rational and/or non-fictional stuff you've been reading? The recent album from your favourite German pop singer? The politics of Southern India? Different ways to plot meteorological data? The cost of living in Portugal? Corner cases for siteswap notation? All these things and more could (possibly) be found in the comments below!

Please note that this thread has been merged with the Monday General Rationality Thread.

### Comments:

- u/TheFlameTest2:
  ```
  I had some thoughts over the week I wanted to share with this community

  What are some of the white lies that we tell society and are useful to propagate?
  For example a media campaign to promote recycling may say you can't recycle black plastic. But actually you can, it is just very difficult to and will more likely end up in landfill.
  Or you might tell people wearing face mask is to protect you from disease when actually it is to protect other people, but saying it this way might encourage more people to wear them.

  On a mostly unrelated note I've often heard that if you win the lottery the first thing you should do is hire an account to help manage your money because most people lose their fortune relatively quickly. However, I think this is selection bias and actually people who play the lottery enough to win are more likely to have bad financial sense so that advice is not good for most people, but it is good for most people who would win I guess.

  If you came into a large sum of money what would you do with it? If your answer was invest how large of an amount would that need to be?
  ```

  - u/RetardedWabbit:
    ```
    Convincing people to recycle and not litter, it's good for the environment but it's outsourcing the cost of cleaning things up to the public and let's businesses blame consumers.

    I think getting an accountant for the lottery is still sound advice, you're suddenly in a tax bracket where you can spend large amounts of money to save/make even more money through all kinds of tricks. I don't know about elsewhere but things get very messy in the USA once you're making enough money that the costs of legal and financial instruments are relatively small. 

    My personal break point would be >$1,000 dollars to take the effort to adjust my 401k contribution for the month, otherwise I would just deposit it to be invested later.
    ```

  - u/Radioterrill:
    ```
    I think free will might qualify? I'm not sure how well the papers involved would replicate, but it's a common belief that lacks strong evidence but nonetheless seems to promote better behaviour than deterministic attitudes.

    I like your point about the selection bias of lottery winners.
    ```

    - u/RetardedWabbit:
      ```
      I also thought of this and looked for the sources to back it up. Research looks like it's more of a mixed bag as opposed to "telling people free will isn't real makes them act worse" as I've heard it.
      ```

    - u/D0TheMath:
      ```
      From a materialist perspective, if free will means that I am able to make choices and act on them, and my brain is me, then I clearly have free will.

      From a dualist perspective, if free will means that I am able to make choices and act on them, and I have a soul which is me, then I also clearly have free will. 

      So I don’t think this counts as a white lie. It’s just the truth.

      (edit: this is a simplified argument, and plausibly the real conclusion is we have free will *some* of the time, since we don’t always actually do what we want to do. In this paradigm it would make sense to think of your own will not as free, but as a scarce quantity. If this became general knowledge (and was true) I believe the world would actually get better, as people would be able to utilize this understanding to their advantage to spend will more wisely to do the things they actually want to do.)
      ```

    - u/babalook:
      ```
      I think the white lie of free will is actually because without the presumption of free will it's basically impossible to talk about morality which is the bedrock of legislation. As far as I understand the issue, that's the purpose of dualism, to redefine free will so we can still have philosophical discussions while recognizing that free will, in the more colloquial sense, doesn't exist.
      ```

  - u/D0TheMath:
    ```
    I think most are all too ready to propagate white lies. I would guess, however I have little supporting data, that usually the result is simply taking the nuance out of discussion, propagating harmful misconceptions, and convincing people that most topics are simple and straightforward. Not complex and requiring deep thought and knowledge.

    This, I think, is harmful to the long term mental & intellectual health of civilization, as well as the legitimacy of sources of authority once the “truth” behind the white lies is revealed. 

    This outweighs the relatively minor benefits of white lies in aggregate mostly. The negatives of the no-white-lies approach appears in the form of people coming to conclusions not supported by the mainstream culture. These conclusions are likely generally correct, but can often be wrong (ex. literally all of history). So the benefits of white lies are small at best, a priori.
    ```

- u/jupbarrera:
  ```
  Just learned of the solarpunk genre, Since i am a little depressed with the current situation of the world. Might be what the doctor prescribed.

  What are your impressions of this genre?
  ```

  - u/Roxolan:
    ```
    Makes for some damn cool individual art pieces (especially in the "cluttered manga street scene" style which I love), and Hayao Miyazaki rocks. Basically non-existent outside of those, far as I've seen.
    ```

- u/RavensDagger:
  ```
  Plasma Guns! 

  I'm writing a sci-fi story (Stray cat Strut) and the main character just got her hands on some nifty plasma weaponry. She hasn't fired it yet, mostly because I want the weapon to be somewhat realistic. 

  Which means I need an idea of how a 'realistic' plasma-based weapon would work (where 'realistic' means I can bullshit a believable enough answer that the reader will nod and accept that the awesome gun does awesome things). I've been looking at a few ideas, but none of them really jive with me. 

  I was wondering if anyone here had a better idea on how a weapon like that would work?
  ```

  - u/Frommerman:
    ```
    [Laser-Induced Plasma Channel](https://en.m.wikipedia.org/wiki/Electrolaser) weapons are actually real, if wildly impractical with current energy storage technology. They work by firing a laser powerful enough to ionize the air at a target, then firing an electric charge down the newly-conductive air wire to incapacitate them. They're basically taser rifles which don't require finnicky wires and contact points, or they would be if they didn't require huge capacitor banks to fire even once. However, they have the capacity to transfer far larger amounts of energy into the target than a traditional wired taser because their plasma wire won't burn out like a fuse, so they can be made lethal far more easily. They would also obviously be highly lethal to androids and/or cyborgs, and don't fire through walls, making them relatively safe weapons for urban combat in high-rise slums and the like. You don't have to worry about shooting the kid through three units down.

    Also you might recognize this mechanism as being similar to the way lightning works. That's because it basically is a lightning gun. It will cause thunderclaps, and would be impossible to silence.

    Beyond that, the problem with plasma weaponry is that plasma doesn't tend to be very dense. As a result, very hot plasma often has little actual heat-transfering capacity. Furthermore, because it's a gas, it will be interrupted by the atmosphere and will probably lose most of its energy before it hits a target. It also doesn't have much kinetic energy, so it won't punch people the way normal guns will. Traditional bullets work because they are dense and have momentum, but plasma just doesn't.

    However, if you had some technology which could directly manipulate magnetic fields, you could probably do interesting things with plasma. If you had the means to project a magnetic containment field at near-lightspeed, you could pack in plasma at temperatures and densities just below fusing point and fire that packet at the enemy. This would be far more dense and hot, akin to scooping out a bit of the Sun's core, and would obviously be quite destructive. You wouldn't be able to look directly at it without a welding mask, though, and it would probably be closer to an RPG than a gun. You don't want to be anywhere near the target when containment fails. Though it might be safer than an RPG for your internal organs, due to the lack of an explosive shockwave.

    The problem with this interpretation is that it's Clarketech which any civilization smart enough to develop could use for things far better than handheld weapons. There's nothing I can think of between the realistic, but energy-chugging stun gun and the unrealistic mini-sun-chucker, though.
    ```

    - u/RavensDagger:
      ```
      I did some further reading after posting the question and came across one (theoretical) design that seems kind of neat.

      Essentially, you have a chamber that's filled with a gas and that's given a nice jolt to turn it into plasma. Using some coils you push this ball of plasma down a barrel where it runs into a piece of metallic 'cloth.' 

      So the cloth wraps around the plasma (like dropping a rock through a tarp) and fires away like a more or less normal projectile, only its a ball of superheated not-gas. 

      It's... probably less effective than just shooting a bullet.
      ```

      - u/Frommerman:
        ```
        Having thought about it a bit more, LIPC is probably your best bet. For one, as long as your civilization has a sufficiently robust lasing medium, a LIPC has all the advantages of a laser rifle while also having a practical stun setting. Just keep the laser on longer and don't dump electricity down the muzzle to use it as a highly lethal cutting laser. Furthermore, the only thing your civilization needs to make them which we don't have is mass-producible ultracapacitors, which should be doable with mass-producible graphene. You would still need to worry about heat dispersal in such a weapon, but I would expect such a civilization to view cryogenic cooling of superconducting electronics as relatively normal anyway.

        You'd wind up with a recoilless rifle which can switch instantly between lethal and nonlethal operation, with "clips" you can recharge by plugging into the wall. It would probably have tons of awesome-looking heat sink fins protruding off the barrel and lasing medium cartridge, just in case the active cooling system failed, which might also make this thing into an effective mace-like melee weapon if the fins were sharp and strong enough. If these things are common enough, the heat sink might be shaped more as a shield for deflecting shots from other people firing them at you. Or perhaps the fins themselves are mirrored and arraged to diffuse incoming laser fire. 

        Basically, you actually can justify some seemingly stupid sci-fi weapon tropes with this technology. Go wild.
        ```

- u/WhiteSpock:
  ```
  So Bobiverse. It's not rational.

  It has elements of rationality, sure. But the main character himself is not rational.

  I made it through the first book, but I couldn't go further since the author started talking about uninteresting stuff, and ignoring obvious solutions.

  Spoilers from the first book..

  >!Enemy AIs, one of the first things he should've done once he realized FAITH still had codes to control him, was wonder if the other factions had codes for their own AIs. This should've been a major consideration, considering the Brazilians tried to wipe humanity out.

  >!Destroying his drones just to get a single kill in. Like. What? That's a very short term solution at best, and assuming railguns wouldn't work. And he hates explosives. What about something as simple as a crossbow. Instead he's exploding his work all over the place.

  >!Self modification, this might be something Bob hates. But he's already gone through his code before. But it's never brought up again. The closest he's gotten to self modification is that Australian AI, but that was handwaved away.

  >!Evacuating Earth. Oh no, he can only evac 15k people at a time! So many people are going to die :( We have stasis pods, which were not shown to have any downsides. If only there was a way to sardine pack humans away. Ah well, guess you lot are dying.

  >!Terrorist Attacks. So the world's network has been brought down right? So signals should stand out. Which means logically, they're focused on a certain part of the world. Which means he should focus attention there. Going from that, the basis of attacks and how they're spread out, drones can be deployed to track movement patterns and narrow down the search field with cameras. It doesn't have to be identifying information either, just a few pixels showing someone moving around can be worlds of info.

  >!Survivors talking to each other, so if I recall correctly they mention 50 or so groups. And 15 million survivors. That's kind of a weird number, especially when they're talking about the food production being an issue and 25 cows dead from terrorist attacks as crucial.

  >!Bob the Introvert. Yet he loves chatting for ages to people that he's closely related to. Ok. But those people love talking to him? And remember, they're raised in a society where replicants are slaves. The minister would never approve of Bob being accepted as human, he wouldn't encourage this large scale of behavior. And even, why is he leaving the minister alive when he'll clearly regret it in the future? It's like I raise a lion, but never attempt to teach the lion not to prey on humans.

  >!The high ratio of worlds at similar stages of development. Yes, I'm including humans and the giant ocean world in that. The only way it makes sense, is if they were seeded.

  >!Hippogriffs, just use IR.. You should've been capable of that already.

  >!Describing alien lifeforms, I haven't seen actual descriptions of alien life yet. Just modifications of stuff on Earth. The first aliens he contacted? Described as a cross between bat and pig. The animal they like to feed off? Described as a pig but shaped as a bear.

  >!They talk about backing themselves up, but I seriously have to wonder. Why the hell are they backing themselves up? I can understand backing themselves up outside of their hardware, but when they are the software themselves... On Earth they would've been backed up to roll back mistakes. But here, if their mainframe is shotup they're instantly considered a loss. Because they backup to the same place as their OS.

  >!Space is vast. So very vast. But there's people that want to kill them :( If only they could live in outerspace, if only they had a way to generate power without involving the sun. If only they had a way to move giant planets to a location in the middle of space. Apparently this isn't viable.

  >!VR fasination with creating only what he's familiar with. New flavors? New sights? Weird scenes? No no. Lets just remake other peoples ideas and remake stuff we know. And lets theme everything on being in a tiny room with different scenes. Because floating in outerspace is impossible, a swimming pool is impossible, etc.

  This is a story, but the author doesn't consider rationality very much. The main character also describes himself as rational, but doesn't follow the rational path.

  That said, "Post Human" on Royal Road is a better book.
  ```

- u/VapeKarlMarx:
  ```
  Does the neurolink look like jt is gonna turn out to be anything?  From what I could gather still looks like it is before thr proof of concept stsge but people are saying all kinds of diffrent things
  ```

  - u/alexanderwales:
    ```
    It will probably be something, but as to what ... that's hard to say, and depends upon a lot of different factors. A lot of what people are talking about it doing is just total, complete bunk that we don't even have the frameworks to talk about doing, let alone the technology to do them *at all*, let alone safely.

    But in a few years (largely depending on regulatory agencies, though there are a lot of unknowns) it will start to be put into people who really, badly want/need it, namely those with some specific impairments or disabilities. Because it doesn't go very deep into the brain, the applications will be fairly limited.

    After that, when people are having one put in on an elective basis ... it's hard to say at this point. Because it can read and write, it's possible that they'll develop the software and understanding necessary to do a proper brain-computer interface of some kind. My guess is that this won't be particularly good, but it depends on how well they're able to distinguish neuron spikes, and how that translates to specific thoughts or other brain activity. *In theory*, thinking some specific mnemonic hard enough produces some pattern of spiking that Neuralink can recognize, and once you have that, you can hook it up to various apps running on Neuralink itself, or in your phone.

    More speculatively, the ability to "write", which is to say, electrically stimulate part of the brain, might have a number of uses, but it's fairly indiscriminate from what they've shown, and the actual effects are a person's brain are questionable. There are some existing therapies that use similarish techniques (two I know of are for depression and Parkinson's), but those are both much deeper than Neuralink is planned to go, at least for the moment.

    Overall, I don't think that it's nothing, but this is the ground floor that they're starting from. My guess is that progress will be quite slow. Anyone talking about more mature uses, like copying memories, inserting new memories, mimicing or spoofing senses, altering mood ... you should assume is talking science fiction, rather than science fact.

    (This is based on what I know of the state of the art, and what I saw at their presentation, but I was watching with my son, who was very interested in talking about pigs, so I apologize if I missed something key to their approach or what they currently have working.)
    ```

---

