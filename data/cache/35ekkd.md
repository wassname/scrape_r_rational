## [D] Anyone seen "Ex Machina"?

### Post:

I've seen it heavily advertised on reddit, and the reviews seem to say it's startlingly intelligent etc. So what does /r/rational think of it, on a HSF/RT scale?

### Comments:

- u/PL_TOC:
  ```
  Would watch again/10

  Not really mind blowing, given the slow pace, but it introduces a few concepts those unfamiliar with AI probably haven't seen in other films. 

  It's not particularly a thriller, as the trailer might imply. I wouldn't say the main character was irrational or holding the idiot ball, but suffered from a lack of genre savvy I'd expect any AI researcher to have.
  ```

  - u/NoahTheDuke:
    ```
    Given that his background is in AI, it felt like the main character was holding the idiot ball for the second half.
    ```

  - u/None:
    ```
    Honestly, whenever I see movie AI researchers, I sit there gawping, "Do you want a hegemonizing swarm?  Because this is how hegemonizing swarms start.  And what's the #1 rule of successful research into very powerful technologies?  Hint: NO HEGEMONIZING SWARMS EVER."

    EDIT: Upon checking TVTropes, apparently this film contains the more anthropomorphic kind of robots, so that above objection doesn't apply.
    ```

- u/gryfft:
  ```
  I've been thinking about this for a while. I really *did* enjoy the movie, and I thought the cinematography was beautiful, and I found the premise interesting, and I liked a lot of the acting. There were some genuinely tense moments.

  As *a story about a mind-maker,* it falls short in numerous ways, many of which have already been covered here. However, in trying to articulate my issues with this film while discussing it with others, I noticed a more fundamental flaw in the writing. Take a look at the motivations of the characters in the film:

  CALEB is a nerdy loner software dev. He is ambitious and intelligent. **He wants to get the girl.**

  AVA seems to fit the 'damsel in distress' archetype. Her consciousness arose from a search engine's code, and her creator is keeping her prisoner. **She wants to escape.**

  NATHAN is a successful businessman and a paranoiac. He wrote the search engine that made him his fortune when he was thirteen years old. He has built what is essentially a remote castle in whose dungeon he keeps his creations.  **He wants to know *something* about AI, or how humans and AI interact**, but...

  Although we are at first told this is a Turing test, the film quickly abandons that idea in favor of a "test" in which Nathan seems to want to elicit a specific emotional reaction *from Caleb*. He repeatedly derides Caleb for asking questions about Ava's construction and programming, instead probing to understand *Caleb*'s emotions. 

  Nathan drinks himself to sleep every night, spies on everyone, and has sex with his robots.

  If he was just mustache-twirlingly evil, and as intelligent as he is portrayed to be (this is a mind-maker who became a billionaire with software he wrote when he was *thirteen*) then... what does he *gain* from all this? 

  Let's say he's a sadist who just enjoys torturing people or things. *He's a billionaire.* He could ship in crates of disadvantaged humans of whatever shape or color he pleases. He could have *a great deal more control over the situation.* And he is portrayed as someone who *loves control.*

  Or let's say he's an AI researcher who is just genuinely concerned about having ushered in humanity's extinction with his creation. But that doesn't make any sense, because his creations *openly hate him.* One of them *destroyed itself* trying to escape.

  He explicitly states that his creations *are capable of experiencing pleasure*-- he made sure to build in that capability so that they would enjoy sex. Why wouldn't he design his robots to love being around him? *OR AT LEAST TO PRETEND TO?*

  So... yeah. I don't really have any problems with Caleb or Ava. They behave fairly rationally. They're not perfect but their motivations make sense.

  Nathan exists to allow the plot to advance.
  ```

  - u/None:
    ```
    [deleted]
    ```

    - u/gryfft:
      ```
      >His ultimate goal (at least, I am inferring this from his reveal to Caleb) was to observe the interaction and PoV from both sides as his AI used the tools at its disposal to manipulate Caleb, which worked pretty much exactly as it should have.

      Sure. But what does this *gain* him? *Why* does he want to observe this specific interaction? He's built this massively complex, horrifically unethical situation, so that he can... build a machine that is *even better* at manipulating humans? If his **goal** is unfriendly AI, he's going about it in a *ridiculously* convoluted way.

      Some of his actions *do* make sense in the context of the film. It's the context itself I take issue with.

      (I highly recommend the novel [Blood Music.](#s "There is a scene in which a man who created biological computers from his own white blood cells is sitting in a bathtub, splashing around in hyperintelligent sludge that is oozing from his skin. He is debating with himself about whether to pull the drain stopper and release his creation into the world. I think the cold horror of that scene is what Ex Machina could have been, and wasn't."))
      ```

- u/None:
  ```
  It was worth watching to be sure, but it wasn't great by any means. Likely nothing anyone on this sub hasn't already seen.

  For the portrayal of an AI, top notch (for a mainstream movie at least). That's about all it has going for it though. The movie itself leaves much to be desired. Two dimensional characters with not much of a plot to speak of. Technical inaccuracies are enough I would not consider this HSF.

  My biggest gripe is that the humans are shown as having to make stupid mistakes for the AI to take advantage. Ideally, they should be portrayed as making highly intelligent, sound, considered, informed decisions, taking every precaution imaginable, and still being played like a harp by the AI. This would have improved my opinion by an order of magnitude at least.
  ```

- u/aeschenkarnos:
  ```
  Nathan holds the idiot ball in a major, major way.

  SPOILERS BELOW

  1. Nathan is aware of what Ava is doing with the power yet continues to use a power-down locking system. Even if the power outages are totally fake, her actions are at least somewhat unpredictable. She might *really* damage the house power and security system.

  2. He attempted to physically combat *two* AIs with microsecond-resolution expression-reading capability, unknown(?) strength and speed, with *very high* electrical requirements, more than capable of modifying themselves into super-Tasers, constructing weapons, etc etc. I grant that he knew their designed capabilities and perhaps made them physically weaker than himself (and he is a strong man), however this was a really, really stupid error and he deserved what he got. (I was very disappointed by how ineffective the fembots were; even at a lower strength level they should have pwned him like Batman versus an elderly drunk.)

  3. The whole test protocol was doomed and stupid from the start. Empathy for the AI as victory condition? People are wired to experience empathy. We attempt to release suffering lab animals or factory farmed animals; even *lab plants* are occasionally stolen and replanted. *Of course* any remotely normal human being is going to empathize with the vulnerable, attractive prisoner. There's a fair chance a given test subject would release the AI with no verbal interaction or personal bonding time at all. The only "test" here with the benefit of hindsight, is "is Caleb a psychopath *who doesn't bother to fake niceness*?"

  4. Perhaps this is an explanation - Nathan is psychologically fucked up to an absurd degree. He appears extremely depressed, is drinking himself to death, thinly maintains a false personality that is a caricature of an alpha male "dudebro", and keeps the gruesomely injured hyperrealistic bodies of nude women (who he knows had *self-awareness*) in his *bedroom*. His only human contact is Caleb. Apparently he has abandoned all self-checking. (Granted, this may be a reason for the rest of the idiot ball actions.)

  And there's more.
  ```

- u/i_dont_know:
  ```
  My suspension of disbelief was broken during Nathan's description of the first "power outage" and his ass-backwards "security". The guy is supposed to be a tech genius and he hasn't heard of two-factor authentication? For that matter, a simple password without the use of key cards would have prevented the the security breach that happened. And he paid a "fortune" for the power system at his remote mansion, but he hasn't heard of the concept of isolation or air-gapping, or at least root-cause analysis for his *extremely frequent* power problems. And for some reason, when he is running on backup power, his security systems and computer shut off? A $100 UPS could have saved his computer and his cameras. Ugh. 

  Ignoring the plentiful technical blunders, I didn't find the human characters at all interesting or engaging, and the plot was slow, boring, and utterly predictable.
  ```

- u/None:
  ```
  I was excited to see an AI shown with more fidelity than most movies (having seen Age of Ultron yesterday and being slightly annoyed).

  I think the cinematography was great. I thought the characters were all interesting, and I'm not sure what people mean when they say "two-dimensional characters": Only Caleb really is, and that's arguably for a plot reason (i.e he was chosen); Nathan and Ava both showed a lot of complexity.

  Also, I think it was well paced, and I loved the way it was pretty much split into different "acts" by the session/day number. I thought it progressed well, and the character dynamics over that span of time were pretty good.

  I love the premise. Some scenes were just incredibly good, like the first scene where the power goes out, and the scene where Caleb cuts himself open to make sure he wasn't just an AI. Also, the climactic scene.

  Something about it struck home with me. Maybe it's that I like slower-paced films, maybe I'm just a sucker for love+artificial intelligence (I did really like Her...), but I thoroughly enjoyed the movie, and am intending to see it again as soon as I have plausible reason to (a friend is coming back from college in a couple weeks...).
  ```

- u/forrestib:
  ```
  My primary complaint is that the AI seems a little TOO advanced for the presumably modern setting. The thing that makes that even worse is that it's supposed to be one of the earliest successful models. I have no problem with the idea of emotional computers being made eventually, but the first stable AI to be made most definitely will not be as human in mind as she is portrayed.

  Still, it's a pretty good movie, if you have enough suspension of disbelief to go around.
  ```

---

