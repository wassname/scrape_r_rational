## [D] Irrational Fiction

### Post:

Imagine a situation in which perfectly rational behaviour is *counter-productive*. Trying to acquire information and draw conclusions from it is pointless. Clear and logical thinking leads you to incorrect answers, whilst biased, emotional or thoughtless actions would lead to victory. Attempts at being reasonable fail you, while relying on intuition, poorly-made guesses, and biased thinking is the right choice.

In extreme cases, the situation would be such that you're unlikely to figure that last bit out, even. Rational behaviour would lead you to death, irrational behaviour would grant you victory, but you'll most likely die before you understand this — unless you're irrational to begin with.

A story based on such premise would be an example of ***irrational fiction***: a peculiar subgenre of rational fiction in which rational behaviour is punished. (Perhaps a fitting alternate genre-name would be "rationalist horror", though being horrifying is not a strict prerequisite.)

It should be noted that it has to feature an actual difference between rationality and irrationality. A rational person could *model* an irrational one, query this model for advice, and follow it whenever it seems to be a good idea — in fact, this is exactly what we always do when interacting with irrational people. In this case, it must not work, either because the problem is internal, or because the ability to model irrationality is imperfect, or because of some even more esoteric reason. You would need to actually *make yourself* irrational to succeed.

* The most prominent example of this subgenre is, of course, [*CORDYCEPS: Too Clever For Their Own Good*](https://archiveofourown.org/works/6178036/chapters/14154868), which self-identified as an irrationalfic, coining the term. [Spoilers: Cordyceps, All ](#s "Here, trying to gather information and study your condition, or being distrustful of people who have apparently abducted you and are trying to brainwash you by messing with your memory, would be directly responsible for your death.")

* A weaker example is [*On Self-Delusion and Bounded Rationality*](https://www.scottaaronson.com/writings/selfdelusion.html), a short story. [Spoilers: OSDaBR, All ](#s "There, the protagonist is neurologically incapable of pursuing her happiness at the expense of the truth: she can't back down from arguments, can't accept even the smallest self-delusion. She reasons that it would doom her to an unhappy life, restricting her ability to positively interact with people, and sets on a path to give herself permanent brain-damage.") As opposed to *Cordyceps*, becoming irrational not the most optimal way forward here, but it's arguably one of the better alternatives.

* Stanislaw Lem's [*Memoirs Found in a Bathtub*](https://en.wikipedia.org/wiki/Memoirs_Found_in_a_Bathtub) could be considered an irrationalfic as well: the Building's plots within plots and layers of disinformation would be very resistant to rational scrutiny, and the best way to function there is to accept the insanity.

* Scott Alexander's [*The Last Temptation of Christ*](http://squid314.livejournal.com/324957.html), if interpreted as an attempt of Devil to deceive an actual Christ, would be an interesting edge case. Jesus doesn't have any evidence that he isn't insane, and can't gather them, so the only way for him to win is to disregard the rational conclusion, and, for all he knows, doom himself to a life of insanity. Albeit his thought patterns don't change, all his thinking from that point onwards becomes compromised.

___

What do you think about it?

Do you know any other examples of irrational fiction?

### Comments:

- u/eternal-potato:
  ```
  The premise does not make sense to me. (Instrumental) rationality is ability to archive one's goals. Whatever arcane process you use to decide on a course of action, if it consistently brings you closer to achieving your goals, then it is rational by definition, regardless of how emotional, impulsive, spastic, random or inexplicable it appears to be.

  Thus acting "irrationally" (thoughtlessly, impulsively and randomly) in the environment you describe is actually quite rational, and acting "rational" (based on drawing conclusions from prior evidence using reason and logic) is irrational.

  Basically, you described a universe with different rules for what constitutes rational decision process from what we are used to, but that does not make it (the process) irrational.
  ```

  - u/DCarrier:
    ```
    Rationality is the ability to achieve one's goals in a wide variety of circumstances. This is about a pathological circumstance where your ability to achieve your goals is negatively correlated to your ability to do it in other circumstances in general.

    As an extreme example, imagine you stick someone in a simulation that's indistinguishable from reality, see how many lives they save, and then kill that many people. The more (generally) rational that person is, the more people will get killed.
    ```

  - u/Noumero:
    ```
    **Edit:** Yes, one would need to have a contrast between the two approaches, i.e. what we consider rational and what is rational in this story. In *Cordyceps*, the particulars of the situation make usually-irrational behaviour (i.e. such that it can't be expected to let you win in most cases) rational; in *Methods of Obstinacy*, it's the contrast between rational approaches in two universes.

    ___

    Take *Cordyceps* as an example. Someone found themselves captive in an institution with no memory, and found strong evidence that their memory is repetitively erased by the people who hold them there. We would expect that staying put and doing what they're told would have unpleasant consequences for them, while trying to find out more and make a successful escape would constitute a victory; in actuality, it's the opposite. A rational person would fail here, while a gullible one would win.

    Similarly, as in u/ToaKraka's example, there could be situations where trying to study a phenomenon using scientific method would have counterproductive results, as would be trying to systematically find any kind of pattern in behaviour of this phenomenon. Trying to manipulate the outcome by simulating an irrational person would perhaps also fail, simply by virtue of you expecting this to succeed based on rational analysis of the situation.

    In some examples, yes, it would still be possible to make a rational decision to act irrationally (as in, how people without any rational training act), and win this way. In other cases ([](#s "Cordyceps, kind of  ")), it wouldn't be.
    ```

- u/ToaKraka:
  ```
  [*Magisterius University and the Methods of Obstinacy*](http://www.talesofmu.com/other/mumoo)
  ```

  - u/Noumero:
    ```
    Very interesting. I do think it qualifies as irrational fiction.

    I'm not convinced that it's impossible to figure out meta-rules by figuring out how the rules of physics change, though.

    Even if we're using the omniscient GM analogy that deliberately sabotages all attempts to munchkin the rules, rational optimization is still possible, as all rule-changes would be made to achieve some goal. In a tabletop game, the GM optimizes for entertainment of players/own's entertainment/building an interesting narrative. Similarly, this inconsistent universe should be optimizing for something, and the way to victory is figuring out what it is and making sure your goals align.

    Even if the universe smites anyone trying to make even those judgements, it's evidently not smiting those who note that it's consistent in its smiting of people who try to study it. As such, rational people could see the corpses of all the other rational people who tried to understand it, and decide to not do that, instead choosing the vague direction of making their lives a satisfying story.
    ```

    - u/Endovior:
      ```
      > Even if the universe smites anyone trying to make even those judgements, it's evidently not smiting those who note that it's consistent in its smiting of people who try to study it.

      Except when it does. Random peasants who keep their heads down and don't do any of the things you're not supposed to do can still get struck by lightning from a clear sky, or eaten by dragons, or fall into the sky after gravity stops working for no reason.

      Consider Descartes. The thing about reality being run by an infinitely powerful deceiving demon is that it's not very fun to live in that reality, and there's literally nothing you can do to avoid arbitrary consequences. Whatever you think you've figured out is subject to revision at any time, including your thoughts and memories, if the malevolent entity in absolute control of absolutely everything thinks it'd be funny.

      This leaves the only *working* method to get one over on reality is to play the demon, not the game... which, as has been noted, is also something that usually ends badly, especially if reality happens to notice you trying to be manipulative like that. However, it still likes what it likes, and if you're clever, you've noticed that it likes 'epic' and 'heroic' stories, and gives more leeway to individuals whose actions fall under those tropes. This might not work any better than anything else; wannabe heroes die in droves. But when you're a helpless pawn dancing in the palm of an infinitely powerful demon, your only real choice is whether or not to attract its attention... so if you are going to try getting that attention, you should at least try to do so in a good way.

      If at all approximately possible, a more sensible course of action still is to flee the universe by any means available.
      ```

      - u/nick012000:
        ```
        >If at all approximately possible, a more sensible course of action still is to flee the universe by any means available.

        Set sail on the SS Gnosticism to go and try to find the Sophia? ;)
        ```

- u/CeruleanTresses:
  ```
  I read a great book once called Every Heart A Doorway (sample excerpt [here](https://io9.gizmodo.com/seanan-mcguires-new-book-is-just-so-mindblowingly-good-1768914959)), which is about a boarding school/support structure for young people who've returned to Earth from various fantastical realms. The realms are broadly categorized as points along the spectra of Logic<->Nonsense and Virtue<->Wickedness. Students from "High Nonsense" worlds tend to behave absurdly, and this is explained as basically a residual survival mechanism from their time in those worlds. So I imagine the experience of surviving in a High Nonsense world would be similar to what you've described. There's an upcoming sequel set in one of those worlds, so I guess I'll find out when it comes out.
  ```

  - u/nick012000:
    ```
    >looks at the excerpt in the link

    >the book makes a point about how the population of the boarding school is almost entirely female

    I guess most of the boys want to stick with their isekai harem comedies rather than returning home to mundanity?
    ```

    - u/CeruleanTresses:
      ```
      In the book's setting it's more common for girls to pass through doors to other realms in the first place. I remember it positing a couple of possible explanations for this, having to do with the ways girls are socialized/treated differently (e.g., girls might be more likely to feel out of place in the real world; girls might more easily slip away unnoticed). Actually none of the students at this particular boarding school *wanted* to go home--there's apparently a different school for kids who had a shitty time in their fantasy realms and want to move on with their mundane lives.
      ```

  - u/DaystarEld:
    ```
    Huh. This actually seems really interesting. Would you formally recommend it to others here? (Even if it's not a rational(ist) book)
    ```

- u/HeroOfOldIron:
  ```
  Technically wouldn't Gurren Lagann count?
  ```

  - u/Subrosian_Smithy:
    ```
    >[*eh-hem*. Real-world heuristics for instrumental rationality are not *actually* instrumental rationality.  If you find yourself in a universe with Spiral Power, going beyond the impossible and kicking logic to the curb *is the strictly rational move*.  You cannot rationalfic Gurren Lagann because there are no errors in reasoning to fix, whatsoever: they're doing the right things the whole time because *their universe really does run on awesomesauce.*](https://www.reddit.com/r/rational/comments/2s6uf1/thought_experiment_for_the_bored_rationalists_is/cnmq6ge/?context=10)
    ```

    - u/None:
      ```
      Thanks for the repost, so I didn't need to.
      ```

- u/None:
  ```
  >A weaker example is On Self-Delusion and Bounded Rationality, a short story. 

  I resemble this character.
  ```

  - u/trekie140:
    ```
    So do I, to the point where it worries me. I discovered rationality at a time when I was a hardcore New Age hippie weirdo who was getting a physics degree specifically to study psychics and Reiki. Now I have that degree but no idea what to do with it, suffered multiple existential crises over whether the spirits I talk to while meditating are real, and regularly experience depressive episodes due to doubting that my positive thinking can influence reality.

    Part of me feels like I made a wrong turn in my personal development. I've become as implicitly loyal to epistemic rationality as any religious doctrine, attempting to live up to ideals even when I am psychologically incapable of doing so purely because I was told they were good. Now I second guess everything I believe due to concern over unobservable biases, which has ruined the optimistic worldview I once had. Now I don't have confidence in my ability to control myself and the world around me.

    Life wasn't easy before this transition happened, and it would be conceited of me to believe that other experiences I've had couldn't also be responsible for my change in mindset, but it was extremely comforting back then to believe in an immaterial higher power that was guiding me and giving me more control over my life despite my mental illnesses. Now I have to contend with lingering doubts over whether any of it is real if all I can measure is how much I despair I'm in when my faith wanes.

    I already concluded, long ago, that I am not psychologically capable of being an atheist or materialist. I cannot live happily if I reject my dualistic beliefs, I will always feel like I'm living half the life I did before because it all still seems real to me. However, I cannot reliably maintain my belief in such things when I also believe it is virtuous to constantly be skeptical about my beliefs and seek out objective evidence for them. I'm glad I don't believe in pseudoscience and confirmation bias anymore, but without it I can't rationally justify a worldview that is foundational to my ability to self-actualize.
    ```

    - u/None:
      ```
      > Part of me feels like I made a wrong turn in my personal development. I've become as implicitly loyal to epistemic rationality as any religious doctrine, attempting to live up to ideals even when I am psychologically incapable of doing so purely because I was told they were good.

      Generally we call them both "rationality" because, in real life, true knowledge and useful action go together.

      >Now I don't have confidence in my ability to control myself and the world around me.

      Ok.  So let's ask: do causal arrows flow from your actions to your self and your life around you?

      (I totally feel the existential despair angle on *perceiving* oneself as having little-to-no affordance, little causal effect on the my-salient stuff of my lifeworld.  I guesstimate that it's a major component of the feeling of despair, which is admittedly common sense.  But also, I keep getting told not to view myself that way Because Reasons.)

      >I already concluded, long ago, that I am not psychologically capable of being an atheist or materialist. I cannot live happily if I reject my dualistic beliefs, I will always feel like I'm living half the life I did before because it all still seems real to me.

      Sounds like you're already a materialist, and just believe you believe in dualism and believe strongly that you *ought* to believe in dualism.

      I used to be religious, but ultimately, what kicked me off it wasn't so much *factual evidence* one way or the other, it was [throwing out the fact-value dichotomy](https://reasonpapers.com/pdf/28/rp_28_9.pdf), thus ceasing to ideologically wall-off certain beliefs from evidence on grounds that they were the Values rather than the Facts.

      Besides which, I feel like I've got a lot more Spiral Power now that I strictly look for the causal arrows that *make stuff happen* rather than trying to delegate important parts of the work to Above, so despite me having followed a conventional religion rather than believing in any sense that I could will drills into being, stuff actually feels kinda better.
      ```

      - u/trekie140:
        ```
        Actually, I'm pretty sure I belief in belief in materialism. I think I ought to be an atheist based upon the lack of physical evidence for anything else, but sincerely believe in New Age spiritualism. I'm in denial over the correlation between the sincere performance of my religious rituals and the state of my mental health. When I doubt the validity of my "visions", I feel more despair to the point where I decided having faith is necessary for my personal happiness.
        ```

        - u/None:
          ```
          Oh, well ok then.  I always thought the one you "really believe" is the one you that drives what you *expect to see happen*, but I suppose you're right that emotional variables count as experiences too, for predictive purposes.
          ```

    - u/AKAAkira:
      ```
      So I don't actually know about the character this conversation is about, just jumping in because it seems you're having a crisis with a concept I think I can say something meaningful about. I bring this up hoping it will have a positive effect, but with the acknowledgement that what I'm doing may only aggravate, though I justify that you probably have a decent chance of running into this concept in the normal course of life and may already know about it to begin with.

      Do you know about r/tulpas? It's essentially the concept of having a different self in your mind. I read enough to think that the phenomenon is real, and while I personally think the most likely explanation for it is purely psychological, it's not inconceivable for it to have a spiritual basis, and I think some of the people in the subreddit do believe whole-heartedly that that train of thought is the correct one and developed their tulpas with spiritual methods. Whether or not you identify your spirits as being similar to tulpas, I think a community of people already versed in communing with non-physical beings might be able to help you or give you good insights if you have your own, uh, headspace issues, so you might want to try talking to them.

      The one thing I doubt this will help you with is your former feelings of reassurance from a formerly-believed in higher being. But the people at the tulpas subreddit indicate they have made positive, even constructive relationships with their tulpas, and I think you should start on making something similar first. Who knows, if you manage to accomplish that much, that might just be enough for you to live with.
      ```

      - u/trekie140:
        ```
        I don't think that would work, I genuinely believe that I'm communicating with the ghosts of dead relatives I was close to in life. I place value on speaking with them specifically because I view them as separate entities from me that know things I don't, but believe that guiding me towards learning things on my own would be better for me than directly explaining. 

        The way the afterlife and God operate is key to my worldview because it allows me to justify hope, determination, and personal growth as part of the purpose of existence. If it's just in my head, then it loses such meaning. It's not that my morality would change if that were the case, but that I would lose confidence in my potential to live the best life I can.
        ```

        - u/AKAAkira:
          ```
          I see. I overstepped my bounds.
          ```

          - u/trekie140:
            ```
            No you didn't, you gave a perfectly reasonable suggestion from your perspective that was meant to help me optimize my happiness. I'm not the least bit put off, if anything I'm thankful to you for taking the time to offer advice at all that fit into a logical assumption about my mental paradigm.
            ```

- u/thrawnca:
  ```
  This reminds me of the Surprise Hanging dilemma. Since the judge tells the prisoner that he won't know the day of the hanging until the executioner knocks on his cell, he's basically saying "if you try to work this out, you will be wrong."
  ```

---

