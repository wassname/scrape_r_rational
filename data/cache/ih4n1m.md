## [RT][HSF] Post-history is written by the martyrs

### Post:

[Link to content](https://www.royalroad.com/fiction/35360/post-history-is-written-by-the-martyrs/chapter/544607/post-history-is-written-by-the-martyrs)

### Comments:

- u/DeepTundra:
  ```
  I liked this. It's very in the vein of the classic sci-fi short story to take technology, or possible technology, think about its possible impact for a bit, and then just run with the implications as far as you can. Fun thought exercises are a decent vehicle for story concepts.

  I would argue that some meaningful amount of societal pre-digestion of the ethics of technology is done in this fashion, actually. We certainly don't have perfect cloning or immortality serum or AGI or consciousness-presenting machines, but we've been preparing for the possible reality of them for so long that modern culture has a weirdly solid grounding in questions about the ethics of shooting androids.

  For a writing-specific review, I thought that you did a decent job here. IMO, the short story is the writing format that lends itself best to a tight focus, good pacing, and a functional narrative. So you're doing well right off the bat. Going from highest-level concerns downwards:

  The "retrospective historical narrative" structuring is a good balance between getting across the central idea you're working with and restraining the amount of work you have to do. Of course as a writer there's a struggle about "where" the best place to showcase your idea is in the world you build. That is, what type of narrative best gets across the most interesting possible cross-section of the story concept.

  On one hand, presenting it this way allows you to use a larger amount of your worldbuilding for the writing, as well as most straightforwardly presents the idea. But tension is harder to maintain when the only sense of ongoing action comes from a clearly retrospective chronological explanation of the procession of events, especially if the speaker's situation seems unpleasant but not immediately dire. Maybe there are other points here that would be interesting for you to further explore, like the viewpoint of a "AI risk denialist" or a western internet libertarian.

  This leads nicely into my next point, which is that I'm not such a fan of the speaker/viewpoint character here. Like, we get enough hints to construct a decent character profile, but his voice isn't particularly interesting to me. Which seems like it's on purpose, obviously. The writing is very historically impersonal, even when the tone isn't, and there are only a few spots where the actual presumably human character actually peaks through. Again, this seems like it's on purpose, but I don't know if it does you any favors.

  When Sam says:

  \> This is a human fact, on which humans must deliberate.

  It's really strong. But I didn't get such a strong feeling of deliberation or grappling with ideas  from the text itself. More of a straightforward presentation of historical fact that deliberately elides explicit values-based discussion or presentation of personal thoughts until the very, very end. I know that the speaker cares a lot about the subject, to an unusual degree, because he tells me.

  So...I didn't feel too attached to him, even at the end when we see him struggle a bit.  The dystopian feeling I was getting while reading was a sense of empathetic general malaise for the situation. I think the impact would have been stronger if I felt more connected to the character in question. I'm not saying this idea isn't engaging or good, because it is, but if the viewpoint character's voice primarily expresses a mild, resigned discontent, then that's what I'll feel too. Maybe that tone or feeling is natural for someone born into the situation, or for someone that has only been exposed to GPT-3 writing in-universe, and maybe there's more intellectual horror there for the reader from viewpoint dissonance, but in terms of emotional impact it felt a little flat. I might just be overtrained by movies with hollywood soundtracks, though.

  The horror of the situation is indeed buttressed a little by the total lack of realism in having governments take decisive world-saving action when presented with a clearly real and apocalyptic technological or scientific problem (**O O F**). IRL nobody would do anything and ASI would obliterate the world. But getting an unlikely but technically fortuitous resolution that nonetheless feels like a bad end still works, mostly because the bad end here is unique to the speculation you're doing rather than yet another ASI apocalypse.

  Of course, there's some reasonable doubt to be had about whether ASI is a really a deathly risk in-universe, or if a greater than human AGI already exists. Both seem like somewhat plausible theories to have about the singular phenomena of a language modeler writing an "ASI Bad" paper so convincing that it utterly changes the course of human history.

  The paranoia of wondering if the story is written by GPT-3  (both in and out of universe, oof) adds a stimulating spice. Obviously, due to the subject matter, an explicit clarification appended to the story that it isn't GPT-3 doesn't do anything, lmao. I suppose the scene at the end clarifies whether it's GPT-3 or another modeling software in-universe, though.

  I didn't notice any problems with paragraphing or structure or pacing or repetition. The occasional spelling mistakes were a nice touch; I was Noticing them whenever they happened, which I hope was intentional.

  Feignman is a good pun.
  ```

  - u/Veedrac:
    ```
    This is an excellent review, thanks so much.
    ```

- u/zombieking26:
  ```
  "Some maverick historians have archives of the entire historic web, but the authorities typically treat that as arms trafficking, and that's where you can get into deep trouble"

  I really loved this line - I can imagine a world in which AI is so unbelievably convincing that it could drive people to do anything. I assume that's what you're referring to, anyway.
  ```

  - u/zaxqs:
    ```
    I thought it was because they didn't want anyone to have access to a large amount of real human content because it could be used to train a world-ending AI.
    ```

- u/MilesSand:
  ```
  I don't get it.  So GPT3's ability to ape a variety of creative writing tasks lets it flood the internet and therefore be god?  I'm just not following the train of thought that the story takes for granted.   Is this someone's wet dream of how they would take down Rupert's Propaganda Emporium? 0.3 out of 5 pizza slices, would not attempt to consume again.
  ```

  - u/TrebarTilonai:
    ```
    To me, it seemed like GPT3's ability to flood the internet with content is being used not to be god, but to prevent a god-like AI. In other words, if all of the training data is written by AI, then it can't be used to train an AI beyond what GPT3 was trained on already. At least... as long as you don't already have an AI that can positively train itself recursively on its own output, which you can't get with JUST the existing data which is why the paranoia about archives of the historical internet.  


    However, the end result of all of this is a society where GPT3 controls almost all human communication. And the paranoia of a god-like AI was fanned by a research paper written conclusively by an AI. So there is, of course, the chance that the god-like AI already won and has taken over humanity, and the whole society is a look at a post-AI apocalypse with an emphasis on us having come to terms by thinking we won.
    ```

- u/GreenSatyr:
  ```
  heh is the pun intended? (Post-history vs. post history)
  ```

---

