## [D] Rationalist fiction and ethics

### Post:

[deleted]

### Comments:

- u/alexanderwales:
  ```
  Most people here think of utilitarianism as being the "correct" moral framework.

  But beyond that, rational fiction tends to put a focus on thought, and it's difficult for me to see how that exists within a deontological framework. That is, if you're a deontologist, you just ... do the right thing, even if it has bad consequences. Where's the thought in that?

  Kant said that it was wrong to tell a lie to save a friend from a murderer. If you put that into a story ... I just don't see how that works *unless* it's a deontologist flirting with consequentialism.

  The current story that I'm writing for National Novel Writing Month *does* have a deontologist protagonist paired with a utilitarian protagonist, with both utilitarian and deontological villains, but it's not super rational, and in part it's an argument against absolutist moral rules.

  I was raised Mennonite, a rather extreme sect of Christianity which holds that non-resistance is morally correct, e.g. if a man comes to your house and attempts to rape your wife, you and she are both obligated not to resist him. Reading some of the interviews with Mennonites from the World War I conscientious objector board is a look into the eyes of moral madness, in my opinion. Edit: [*The Conscientious Objector* by Walter Guest Kellogg](https://archive.org/details/conscientiousobj00kelluoft), starting in the section "The Mennonites and Others", though I think the whole book is worth a read; it was written by one of the three members of the Board of Inquiry which assessed whether those seeking CO status were just faking it.

  > You can not get him to say whether in his opinion the United States should triumph over Germany or Germany over the United States — he will tell you, "It is not for me to judge." He will, in all likelihood, testify that if some brute were to break into his mother's or sister's room and attempt to rape her, he would allow his mother or sister to be raped before he would shoot or otherwise injure her assailant. He will not admit having been in any fight or having ever used force against a human being since joining the church.

  (Now that I think about it, I did actually put some of this into [*Metropolitan Man*](https://www.fanfiction.net/s/10360716/1/The-Metropolitan-Man).)
  ```

  - u/None:
    ```
    I guess I find it interesting how certain things are assumed as moral axioms without justification. As in, "do the thing that benefits the most people" is often the reason for the protagonist to go against the world-conquering despot, but rarely is it explained why they want to do that. I guess deep down I just want to read a story where there is a completely self-absorbed protagonist, if only for novelty's sake.

    P.s. Glimwarden is heroin I need it
    ```

    - u/InfernoVulpix:
      ```
      Given how we're raised on the axiom that caring about innocent bystanders and other such actions signals the hero, while not doing that signals the villain, I think what you're looking for, to an extent, is the [Villain Protaognist](http://tvtropes.org/pmwiki/pmwiki.php/Main/VillainProtagonist).  From the above hero/villain traits, if such a story ever talks about morality, the protagonist is usually classified as evil, but that doesn't stop the villain from having a sympathetic portrayal.

      I just recently finished [Seventh Horcrux](https://www.fanfiction.net/s/10677106/1/Seventh-Horcrux), recommended from another thread here, in which when Voldemort died his identity overwrote Harry's, and Harry!Voldemort decides that going through life again as the saviour of wizarding Britain isn't so bad.  It re-imagines Voldemort as less 'completely evil' and more amoral with a tendency to believe what's told to him (a byproduct of growing up in the house of purebloods after living in a muggle orphanage; he has to give off the impression that he already knows what they're talking about, and knew it all along, or else they'll turn on him).  It's a rather funny story, and Harry fits the bill of always having a selfish motive for whatever he's doing.
      ```

    - u/None:
      ```
      Super interesting about your background too! I have been struggling with the concept of just war and pacifism, and how the two coexist (if they do). What exactly does non-resistance look like? Is fleeing allowed, or non-lethal incapacitation?
      ```

      - u/alexanderwales:
        ```
        Matthew 5:38

        >  “You have heard that it was said, ‘Eye for eye, and tooth for tooth.’ But I tell you, do not resist an evil person. If anyone slaps you on the right cheek, turn to them the other cheek also. And if anyone wants to sue you and take your shirt, hand over your coat as well.

        They take this seriously and literally. They *are* allowed to run (but there are some instructions in the texts not to), but not at all allowed to use force upon another person. That is, you're not allowed to break someone's leg, punch someone in the face, or even to use force to restrain them without harming them. There is no such thing as a just war, to the extent that paying taxes which will be used for a war is either forbidden or strongly discouraged.

        [*Martyr's Mirror*](http://www.homecomers.org/mirror/martyrs152.htm) is one of the most important Mennonite texts, which has stuff like this:

        > Being brought before the lords and judges, he was asked, whether he had been baptized upon his faith, which he finally confessed and acknowledged, not ashamed of what he had done by the command of his Lord and Master Christ Jesus, though he certainly knew that they did not ask him to be taught of him, but only to get a word from his mouth by which they might sentence him to death. When the lords and criminal judges had heard this Christian confession, they rose up and went to sentence him to death; and having returned from their evil consultation, they pronounced and declared their sentence over this servant of God: that he should publicly be burnt alive at the stake till death should ensue.

        (This was during a time when being a Mennonite was cause for death without any other crime being committed.) And insane stuff like this:

        > When the executioner had come to him, he commanded him to put out his tongue, which he (faithful and pious servant of God), willingly did, since he had not a member on his body, which he was not willing to deliver up to suffering for the name of Christ, being well assured that all the sufferings of this present time are not worthy to be compared with the joy and glory which God has promised them that overcome. Matt. 10:22; Romans 8:18; Rev. 2:7.

        > And when he put out his tongue, the executioner fastened it with a piece of iron, and screwed it very tight with a vise or screw, and then touched the end of the tongue with a hot iron, that swelling, the screw might not slip off or become loose. O bitter cruelty and great tyranny.

        The moral lesson here is basically that if someone comes to you with a searing hot iron to pull out your tongue, you act as a willing participant. (Though there always appears to be some consequentialist thinking in these things, because there's explicit acknowledgement that God's glory is greater, and things like "whose reward is the crown of eternal, imperishable life" which very much seems to be an argument that in part this is all done with the expectation of reward. That's always something that I struggle with though, because I'm not sure how much I'm reading these texts with my own utilitarian mindset.)
        ```

        - u/None:
          ```
          You know what, I can respect that. If they believe that violence is wrong, then their commitment even unto death strikes me as brave, not foolish. The question behind the question is: are they right? If yes, great people. If no, unfortunately misguided people.
          Interesting point on divine reward! I guess the classic rebuttal would be that reward is a byproduct of obedience, not the reason for it. The reason for obedience is not because it benefits us, but because it's one's function. And the fact that reward exists is a cause for celebration.
          ```

        - u/Cariyaga:
          ```
          To be honest, I don't go to *quite* that extreme (I would defend myself or others from injury, etc.), but I can kind of see their point. I've thought about it, and decided that if someone broke into my house, I'd talk to them, help them get what they wanted, and call the police afterwards (in large part because their showing up could trigger a robber to take a hostage i.e. me).

          But... well, the reason for my behaving that way is more because of my personality and the fact that few people are psycho/sociopaths, even robbers. I don't have the build that would be capable of physically restraining them, and even if I did I wouldn't feel right to do so over *property* -- it can always be replaced, where I could do serious damage bludgeoning someone over the head with a crutch or whatever, much less shooting them. I figure I'm better off talking it through -- or pretending I'm asleep -- and seeing if I can't get them to see me as someone who cares about them.

          ...well, that was a little rambly.
          ```

          - u/None:
            ```
            I agree with your property statement. My problem with killing and the like is that it is so definite. I am removing in an instant any future probabilities for this person to be reformed and happy for the sake of my own protection or protection of my possessions. The thorny side of it is when you are killing for the sake of another- then you are prioritising one life over another.
            ```

        - u/TennisMaster2:
          ```
          Serious question: 

          What about tickle fights?  Or lip biting and affectionate nugies?  Assisted stretching and massage, even.
          ```

        - u/RMcD94:
          ```
          Makes sense in context of an eternal afterlife I suppose
          ```

      - u/callmebrotherg:
        ```
        Speaking as someone who was an ardent pacifist in the waning days of his theism, it can vary according to the theory that you subscribe to. I was personally considering learning aikido, which was designed to be "an art that practitioners could use to defend themselves while also protecting their attacker from injury." 

        (and truth be told, I still hold "thwarting violence without killing anyone" to be the ideal, and as /u/eaturbrainz has said, we should regard it as a horrible, tragic thing when someone is killed, even when there was literally no other option, because a mind was just destroyed forever and it is awful that things ever had to get to this point)

        You could also probably find pacifists who are okay with inflicting temporary harm but not draw the line at killing.

        It's a much easier philosophy if you believe that the world is ruled by supernatural beings who are willing and able to make sure that everything turns out right in the end.

        I'm on a tablet right now but if you're interested in more, then let me know and I can elaborate as much as you'd like when I get to my laptop. Most of my knowledge is from a Mormon pov, but I'm familiar with some other traditions, like the Jains.
        ```

    - u/DataPacRat:
      ```
      > I guess deep down I just want to read a story where there is a completely self-absorbed protagonist, if only for novelty's sake.

      A recently-written quote from my NaNoWriMo attempt, "[Extracts](https://docs.google.com/document/d/1jPU6QKEohcrw6l6O3SxorIxf2Tnq54h36LtQO6Qv86w/edit)": 

      > "I may be a selfish bastard in the middle of a war zone, but I'm not /evil/."

      Minor spoiler: IIRC, some of the other journal entries therein include discussions about making plans to kill innocent people to survive if necessary, and the selfish reasoning for avoiding doing so if other reasonable options are available.
      ```

    - u/Amonwilde:
      ```
      This is my problem with stories like Luminosity. I just find that level of extreme altruism to be unbelievable. It's just not how people act, even good or saintly people. There is also nothing more inherently rational about not drinking human blood as a vampire, any more than it's necessarily more rational to be a vegan. The question comes down to your goals and values, or utility function as they say around here.

      If you want stories about self-interested protagonists that can occasionaly veer into the rational, try Wuxia stories like ISSTH or WMW. The prose can be a bit sloppy in translation, though.

      http://www.wuxiaworld.com/issth-index/
      ```

      - u/callmebrotherg:
        ```
        > any more than it's necessarily more rational to be a vegan.

        Except that if you're a utilitarian without any speciesism in your system, then it **totally** follows that you should be a vegan, at least unless you make certain arguments which are only true under particular conditions that may or may not exist. 

        If you say "utilitarian" without qualifying it, then I'm going to assume that you're talking about the most common kind of utilitarian, who tries to maximizes pleasure and minimize pain on a universal scale (and in my experience is either vegan/vegetarian or recognizes that not being so is a shortcoming rather than something that Isn't Wrong After All)
        ```

        - u/Amonwilde:
          ```
          I didn't mean that it wasn't rational to be a vegan, I think it can be quite rational. However, it's not axiomatic that veganism is more rational than non-veganism, you need a justification based on some chosen values. My issue isn't the conclusions they came to, more the fact that the values and ethics presented in that story are presented as if they were self-evident. The story would be stronger if there were a carnivorous (hemoverous?) vampire to articulate that side of the argument, even if they were set up to lose the debate.
          ```

        - u/Bowbreaker:
          ```
          How would you call someone who believes that utilitarianism is correct but chooses, on purpose, to not do the right thing?

          To give an example, I personally agree that eating meat is Evil (and not a necessary evil) but I still do it. And I plan on continuing to do so until society disadvantages me for it. I know that it is wrong from a moral standpoint but I accept that level of immorality from myself.

          I thought I was still a utilitarian when it comes to my beliefs and world view, but it sounds like in your opinion only people who either always act that way, or always try to act that way, or at the very least wish they *would* try to always act that way can consider themselves utilitarians.
          ```

  - u/wren42:
    ```
    Oh hey! Just wanted to say I loved metropolitan man.  I'll be watching for your new fic!
    ```

  - u/CouteauBleu:
    ```
    > Reading some of the interviews with Mennonites from the World War I conscientious objector board is a look into the eyes of moral madness, in my opinion

    Wait, really? The USA entering World War I was very beneficial to their interests, and it broke up the years-long stalemate between the two sides, but otherwise it was very morally neutral at best. Allying with Germany to defeat France+UK+Russia would not have been any less ethical than what they did.

    I mean, maybe the people in whose interviews you read had very poor reason to hold their position. But I don't think it's an invalid position at all.
    ```

    - u/alexanderwales:
      ```
      As Kellogg says, Mennonites didn't know anything about the first World War. (And more to the point, it's not even their rejection of war, including defensive war, it's their stance towards ever using force against another human being.)

      > I had spent some time in examining Mennonites concerning the sinking of the *Lusitania*, but nothing significant developed from my questioning: many of them were equally unsatisfying when asked regarding General Foch and Edith Cavell. It occurred to me one day to ask a Mennonite what the Lusitania was. He did not know! He had, he told me, never heard of Edith Cavell, nor of General Foch, nor, strange to say, of General Pershing. Nor, I later ascertained, was his case an exception. I have examined at least fifty Mennonites at random in widely separated camps who did not know what the *Lusitania* was, who Edith Cavell was, nor who General Foch or who General Pershing is. Others had heard of the *Lusitania* — that she was a boat which they thought had been sunk by the Germans, but they knew nothing about the surrounding facts. Several thought her an American ship; one said ''she had got into a glazier (sic) of ice." Two or three had an idea that ''Edith Cavell was some nurse who was shot." About half of them had heard of General Foch; one said he was "the manager of the French army." Pershing was more familiar; he was "the American general" or, as several of them put it, "one of the big men in the American army."

      > Such ignorance, to one who has seen many of them, is hardly surprising. They are an isolated people; they do not mix freely with others.

      But in any case, you couldn't get CO status if you just objected to *that particular war*, due to how Congress had drafted their criteria:

      > The objector who happened to disagree with the Congress or with the President regarding our entrance into this particular war clearly did not come within the Congressional enactment requiring that the objection be "against warfare in any form."

      Which is its own thorny moral issue.
      ```

- u/Amonwilde:
  ```
  I think it's about control. The deontological moral framework acknowledges that attempting to predict the future that will result from your actions is at best a crapshoot and at worst a goad to do otherwise unacceptable things. In real life, this is spot on. Humans always think they can predict the future, and in general fall short.

  Rationalism as presented here is largely a way of attempting to better predict the future or understand the present.  I think this appeals to a certain kind of person, and in my opinion makes a great (and different) kind of story. Unfortunately , in the real world, even people who have reread Thinking Fast and Slow and hang out on Less Wrong should probably build their ethics around the assumption that they can't predict future events. So I guess the answer is that a story about a deontologist might actually be more rational, as it acknowledges reality and our inability to actually do the things we read about in stories like HPMoR. On the other hand, it doesn't allow one to indulge in the fantasies of control that characterize most rationalist fiction, which admittedly I find as appealing as anyone here on this subreddit.
  ```

  - u/AugSphere:
    ```
    I think that dismissing utilitarianism just because the world isn't totally predictable is a mistake. It is at the very least disingenuous, if you don't also bite the bullet and extend the same argument in favour of discarding any kind of planning and prediction in life and just simply live by following some set of rules. I think that when you try to extend deontologist reasoning to every decision it becomes obvious that we are indeed capable of imperfectly predicting the consequences of our actions to some degree and consequentialist reasoning really makes more sense most of the time. 

    The issue with people doing otherwise unacceptable things is a failure mode, true, although it's a failure mode of the user, rather that the system, and can be avoided in principle. Deontological reasoning has similar failure modes and you can easily construct scenarios in which rigidly following it leads people to make decisions which will have obviously unacceptable and quite predictable consequences, unless you smuggle the ability to make consequentialist judgements into it.

    Consequentialism is vulnerable to abuse, but giving up on predictive reasoning entirely is throwing out the baby with the bathwater.
    ```

    - u/Amonwilde:
      ```
      I'm sympathetic to your point about prediction, but I think conflating ethical and non-ethical decisions isn't fully valid. Experimentation might be ethical in one sphere and not in another, making iterative learning and planning acceptable in, say, planning milestones for a coding project but not in deciding when to tell the truth to your partner.

      Funny enough, Kant uses a failure mode in describing deontological ethics, and it's the most famous example...the story with the crazed man running down the street and asking the location of your loved one. (Unfortunately a terrible branding exercise for deontological ethics.) I think justification for a deontological stance isn't really something I can bring across in this format, since a preference for deontological ethics or utilitarianism comes about through personal experience, and I'm no exception to that. But I will say that many (in my mind) impressive Weltanschung or systems of seeing the world are based on accepting the extent to which we don't have control in life, and these systems are therefore more compatible with deontological ethics. I'm thinking of stoicism and zen Buddhism among others. Note that Christianity is actually more utilitarian in my mind, as it's based on deciding you know exactly what the outcome of your actions will be (heaven or hell). 

      I think the extent to which Kantianism appeals to you will also have to do with personal experiences of control or acceptance, i.e. has there been something in your life that wasn't solvable and the extent of one's acceptance or non-acceptance of that. I personally think deontological ethics are generally undervalued, not just here but in general. Lying, for example, seems to be something people do very casually, often because they think or assume the lie won't come out. In my experience, lies come out far more often than people predict and a policy of never lying, even in extraordinary circumstances, has paid off with dividends for me over the years. I think part of being rational (a large part) is accepting our shortcomings. Deonotological ethics does that well. That's not to say I'm a perfect deontologist (it's hard) or that there aren't failure states (there are). But my experience has led me to believe that there are better outcomes when you make decisions based on the ethics of your actions rather than the relative desirability of that which may or may not follow.

      I
      ```

      - u/AugSphere:
        ```
        Could a useful deontological ethics system even be constructed without smuggling in consequentialism in one form or another? When you're establishing a rule against experimentation in some medical field, or a rule against lying, you're using your knowledge of the world to predict which rules will perform better. Any consistently useful system will in the end depend on predicting the consequences of the actions, there is simply no alternative that I can see. So, as I see it, the argument about deontological reasoning being advantageous due to the world being hard to predict doesn't really work. That's my sole point here. I'm not claiming that consequentialism is superior in some absolute sense, or even that it performs better in most real-world situations, I just think that particular argument from unpredictability to be flawed.

        I think deontological reasoning has its place and can achieve better results in many cases. Ultimately though, I think it's a kludge that works as well as it does purely by the virtue of being optimised to counter human stupidity, rather than any inherent elegance or optimality. The less stupidity there is to counter, the less advantage over consequentialism it offers.

        Amusingly enough you can also recover a fairly decent approximation of rules against lying if you [add some fancy decision theory to consequentialism.](https://sideways-view.com/2016/11/14/integrity-for-consequentialists/)
        ```

      - u/Amonwilde:
        ```
        Also forgot to say that I agree with your point in general (prediction is important) and that I liked your response. Though that is, perhaps, a dorky sentiment.
        ```

  - u/TennisMaster2:
    ```
    I've never seen rationality as a predictive element.  It's always been about becoming optimally self-consistent and -efficient.
    ```

    - u/traverseda:
      ```
      I don't know how one could effectively practice rationality without understanding the predictive elements. Have you read the sequences? Particularly "Making beliefs pay rent in anticipated experiences".
      ```

- u/Roxolan:
  ```
  HPMoR!Hermione is a rational deontologist. Harry finds clever consequentialist justifications to do unpalatable things; Hermione just doesn't do them. And she is frequently (though not always) vindicated even on consequentialist grounds. This showcases Yudkowsky's position in [Ends Don't Justify Means (Among Humans)](http://lesswrong.com/lw/uv/ends_dont_justify_means_among_humans/).
  ```

- u/That2009WeirdEmoKid:
  ```
  I've always thought it's because optimization and utilitarianism complement each other very well. It makes sense that a rationalist would be drawn to these concepts. I agree though, there's room for more variety. Has there been any rational fiction that highlights the flaws with utilitarianism?
  ```

  - u/None:
    ```
    I like to think that utilitarian protagonists can quickly become villains when confronted with a large enough timeframe. Establishing that a certain morally reprehensible action would result in the prolonging of the human race by another million years and seeing what the protagonist would do would be very interesting...
    ```

    - u/traverseda:
      ```
      Well, that is something that comes up in the community. Donating money to friendly AI research or donating to an effective-altruist charity? Closely related to "pascals mugging" and the like. How to deal with very small probabilities that have very large consequences.
      ```

      - u/None:
        ```
        I love that phrase! "Pascals mugging". Would you mind going into more depth as to what that is?
        ```

        - u/696e6372656469626c65:
          ```
          http://lesswrong.com/lw/kd/pascals_mugging_tiny_probabilities_of_vast/
          ```

        - u/traverseda:
          ```
          Sure. Imagine someone comes up to you and says "I'm a god. If you don't give me $100 right now, I'll create a billion-billion new earths, and torture everyone to death on them"

          Now, if you're running preference utilitarianism and bayesian probability, the obvious answer is to say "okay". There's very little chance that they're telling the truth, but the result if they are is *so* bad, that it balances out a $100. Is it not bad enough to balance out $100? They can just add a few more order of magnitude.

          In this case the bayesian decision theory so many of us use day-to-day fails completely.

          And this is why the standard lesswrong decision theory is unsuited for use in an AI or the like. When you're weird niche decision theory and common sense are both telling you very different things, go with common sense. Also, rationalists should win and adopting what the decision theory tells us to would very quickly lead to us losing.

          It's worth noting that pascals mugging is actually "roko's basilisk" told differently. A solution to one is a solution to the other. It's been carefully reformatted not to cause anyone any distress. So the next time someone goes off about lesswrong banning roko's basilisk, keep in mind that the question is still open, just with less distressing connotations.
          ```

- u/TK17Studios:
  ```
  There's a common phrase I've heard which goes something like "I'm a virtue ethicist (deontologist) and I think the virtue is 'what makes the most good (utilitarianism).'"

  I'm a rational deontologist whose guiding light is "What would Ender do?"

  No, really.
  ```

  - u/semiurge:
    ```
    > I'm a rational deontologist whose guiding light is "What would Ender do?"

    Sounds more like an agent-based virtue ethics position than a deontological one to me.

    Are we talking pre- or post-Bugger War Ender? Either way, basing your morality off a YA genre fiction character doesn't seem very rational.
    ```

---

