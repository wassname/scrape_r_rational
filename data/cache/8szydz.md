## "Only humans can think in three levels of recursion, and all other magical races stop at 2." What are the implications of this?

### Post:

>Only humans can think in three levels of recursion, and all other magical races stop at 2.

—Eliezer Yudkowsky

Okay, I think I get what this *is*. You can think about a car, and then think about how you thought about that car, and then think about how you thought about thinking about that car. But what actual implications would this have, aside from the obvious? This just seems really abstract, like something a competent programmer could use is some very specific function, but which is otherwise practically useless for everything except philosophy.

### Comments:

- u/Anakiri:
  ```
  Forget about thinking about what *you* think. If you can't think about what *other people* think you think, then you can't be a very good liar.  You can tell lies - try to get other people to think certain things - but you can't think about your lies, and adapt them based on what you think other people think. This will cripple your ability to engage in deception.

  But I think you're still one level down from what Mr. Yudkowsky meant. Thinking about cars is level zero, the object level. Thinking about how you thought about the car is recursing once, and thinking about that is recursing twice. So magical races actually can think about their lies, but only humans can go further. This means that while magical races can believably lie, only humans can believably lie about lying. Magical races can use spies and informants, but only humans can use double agents. Only humans can even think about the concept of double agents, without going cross-eyed and needing to work it out on paper.

  Also, only humans can realize that someone is trying to make them think that they are lying. Say, Alice saw a red car, but wants Bob to think that the car is blue. Any magical race can say "The car is blue," and fill in details of the story, adjusting to the picture Bob has (2) of the picture Alice is trying to make for him (1) of the car (0). But if Alice is human, then she can avoid eye contact and fidget uncomfortably and mumble, "The car is bl- I mean, *red*." Bob instantly thinks: Alice wants (2) Bob to think (1) that the car is red (0). She is lying badly, and the car is probably actually blue. Bob congratulates himself on piercing the deception. Alice wins, because humans can pretend to pretend.
  ```

  - u/ArgentStonecutter:
    ```
    In coming up with this argument you've engaged in four levels of recursion. Right?

    I don't buy it. There's only a couple of pieces of information you have to keep track of to map recursion into iteration here, and you can do that in your short term memory. You don't even need paper.
    ```

    - u/Anakiri:
      ```
      I can do it in my short term memory without needing paper because I'm human. An elf would need paper to work through it, once they realized that there was more to the problem in the first place. And the elf *could* work through it, it just wouldn't be intuitive. As opposed to a human Bob, whose literal first instinct would be "Either the car is blue, or Alice wants me to think the car is blue." If Alice is a known competent liar, then it might not even occur to human-Bob that Alice might be having an off day - the car is definitely not blue.

      Humans can't actually get much deeper than that in practice, on an intuitive level. We tend to immediately get stuck in a loop of, "But what if that's what she wanted me to think she thought I thought she thought? Damnit, get me some paper." At some point in recursion/iteration (you're right, there is no computational difference in this context), every higher level of abstraction is indistinguishable to you. It's entirely possible for different people/races to hit that point at different levels. That fact can have interesting worldbuilding implications.

      Not every elf will notice that the problem even requires further thought. Not every elf will care to give the problem more thought even if they recognize that the human is being all *human* about it, and would prefer to just ignore all information from humans. Not every elf will have the Nobel Prize winning insight to be able to work through the bizarre twisty nature of human minds even if they wanted to. Some will. It is very unlikely that this is a hard limit. But the difference can have interesting implications for interactions between random people on the street.
      ```

      - u/EthanCC:
        ```
        It's not that we *can't* go deeper intuitively, it's that it's impractical to go any deeper than a really good lie unless you can model the other person very well, since it's so easy to backfire. Simplest solution and all that. You're more likely to succeed with a good lie than with trying to convince someone you were trying to lie to them recursively.



        We usually figure out lies through body language and context, if you can control those well enough to lie there's no reason to go any deeper.



        Say Alice is a good liar, Bob knows this. Alice seems to fumble in the lie, Bob knows she wouldn't do that. So the fumble must be intentional. Alice knows Bob knows she's a good liar, so he knows she wouldn't fumble except on purpose, so it can't be the obvious (that the car really is red and she's trying to convince him it's blue) since she knows he'd see through that. At this point you enter a bunch of recursions where Bob is wondering how well she predicted how he interpreted what she did, and then decides to go one level above it...unless she predicted *that*. Alice can't reasonably predict how Bob will think about this, so you basically just have it down to random chance. 



        By fumbling the lie intentionally, Alice gave away that she was trying to lie about something. She would have better odds of succeeding by just lying since Bob wouldn't have suspected anything.
        ```

      - u/ArgentStonecutter:
        ```
        If you only need a small amount of bookkeeping (<5-9 items) you can do it without the paper once you jave learned the algorithm.

        Algorithms are learnable. You don't need to be Einstein to understand Relativity. They can be written down. They are not subject to the Interdict. This one would be taught at Gringotts in 'Humans 101'.
        ```

        - u/Anakiri:
          ```
          Indeed. You could write an interesting story about what mental mechanisms non-humans have to use to adapt to this difference. But you seem to be admitting that non-humans would, in fact, require some learned non-intuitive mechanisms. What would Humans 101 teach goblins that they should watch out for?
          ```

          - u/ArgentStonecutter:
            ```
            Nothing is intuitive but the nipple. It's all learned.
            ```

            - u/Anakiri:
              ```
              Okay, but suppose that while different races *can* learn anything, humans find it much, much easier to learn about thinking about thinking about thinking about things than goblins do. Regardless of whether that's how it works in the real world, suppose you're writing about a world where that is how it works. Most goblins can't get their heads around third level recursion before they're college age. It's your job to set up the curriculum for that class. What do you say, on the first day of class, to convince your goblin students that they should care about third level recursion and higher, instead of dropping it in favor of easier and more interesting classes like Microeconomic Effects of Promissory Notes in Eighth Century Ruritania II?
              ```

            - u/CouteauBleu:
              ```
              Maybe, but "intuitive" still has value as a qualifier; even though "intuitive" is subjective, there are still contexts (such as this discussion), where saying "A is more intuitive than B" conveys useful information.

              Also re-using smart-sounding quotes without elaborating sucks.
              ```

      - u/MrCogmor:
        ```
        > If Alice is a known competent liar, then it might not even occur to human-Bob that Alice might be having an off day - the car is definitely not blue.

        Unless that is just what Alice wants you to think.
        ```

    - u/Lightwavers:
      ```
      You're thinking like a human. The premise is that only humans can keep track of those pieces of information.
      ```

      - u/ArgentStonecutter:
        ```
        Keeping track of information you can't keep track of with just your brain is what writing is basically about. That's the whole point. You'd have to make your non-humans inherently illiterate, and... no, I can't imagine the kind of cognitive shortcomings that would result from this kind of limitation. It would make Binns seem normal.
        ```

        - u/Lightwavers:
          ```
          I don't think you're understanding what's going on here. Yes, a nonhuman would be able to figure this out with pen and paper, but it seems the practical implications that matter are the ones in the moment. Bob could determine Alice wants Bob to think she's lying if he thought it through and wrote out the steps, but intuitively he wouldn't realize it. It would take him a long time and some clues to figure it out, if he ever did. The thing with making up nonexistent races with different thought processes is that you have to entertain that they think differently than we do. If that means functional illiteracy (which this doesn't), then so be it.
          ```

          - u/ArgentStonecutter:
            ```
            > Bob could determine Alice wants Bob to think she's lying if he thought it through and wrote out the steps, but intuitively he wouldn't realize it.

            These are not distinct concepts.

            Humans can think about all kinds of things that are counter-intuitive. They can even win Nobel Prizes for it.

            > It would take him a long time and some clues to figure it out, if he ever did.

            There are about a zillion and a half rational/rationalist/rationaloid stories where the hero goes "wait a minute" and sits down and draws game-theory diagrams to solve a problem, and nobody goes "see, humans can't think about game theory" because it was too much to keep track of without using a diagram and taking a long time.
            ```

            - u/Lightwavers:
              ```
              You are misunderstanding it, I think. I don't think a rationalist Bob couldn't sit down a draw out everything that happened and figure out she wanted him to think she was lying. Uneducated peasant Bob probably would not though.
              ```

              - u/ArgentStonecutter:
                ```
                Uneducated peasant Bob is functionally illiterate.
                ```

                - u/Lightwavers:
                  ```
                  Haha, you got me there. Alright, he knows how to write but isn't in any way a rationalist. No need to be too pedantic. :P
                  ```

            - u/King_of_Men:
              ```
              Do you understand the practical difference between seeing something immediately, while you're conversing, as in 2+2, and having to think about it, as in 14324 + 9812?
              ```

  - u/Norseman2:
    ```
    >Magical races can use spies and informants, but only humans can use double agents. Only humans can even think about the concept of double agents, without going cross-eyed and needing to work it out on paper.

    Triple agents, actually.

    0: Bob works as an intelligence analyst for the CIA.

    1: Bob is a mole recruited by Russia who got a placed as an intelligence analyst in the CIA.

    2: Bob is a double-agent, a mole recruited by Russia who notified the CIA and began working for them to relay false intelligence back to Russia.

    3: Bob is a triple-agent, a mole recruited by Russia who notified the CIA and pretended to begin working for them as an intelligence analyst in order to relay false intelligence back to Russia, but then became a defector for China and now relays Chinese deceptions about US intelligence to Russia, while getting paid by all three countries.
    ```

    - u/Noumero:
      ```
      No, your examples go: agent, double agent, triple agent, quadruple agent. A Russian spy in CIA is already a double agent:

      * (agent, recursion 1) works for cause A;

      * (double-agent, 2) pretends to work for cause A, works for cause B;

      * (triple-agent, 3) pretends to pretend to work for cause A, pretends to work for cause B, works for cause A;

      * (quadruple-agent, 4) pretends to pretend to pretend to work for cause A, pretends to pretend to work for cause B, pretends to work for cause A, works for cause B.

      Recursion here means the number of relations with a particular concept ("cause"). An agent has one relation [agent] → [cause]. A double-agent has two: [agent] → ← [cause], triple-agent has three: [agent] → ← → [cause], and so on. If you treat arrows as vectors and sum them, you would see that agents and triple-agents work for the cause, whereas a double-agent doesn't.

      Another way of looking at it is, an intelligence agent is expected to model/predict the behaviour of the agency's enemies, which is already recursion 1. Double-agent thinks at recursion 2, and triple-agent thinks at recursion 3.

      Humans aren't usually able to be quadruple-agents, which means non-humans wouldn't be able to be triple-agents, i. e. be fake defectors.
      ```

      - u/Norseman2:
        ```
        >A Russian spy in CIA is already a double agent.

        No. A spy, or agent, is someone who betrays their home country by giving secret information to a foreign country. A [double agent](https://en.wikipedia.org/wiki/Double_agent) is a spy who has reversed their allegiance back to their home country and is feeding false information to the foreign country. An intelligence analyst is a a desk jockey with a security clearance, and not a spy unless they happen to be abusing that security clearance.
        ```

        - u/Noumero:
          ```
          Hmm. Yes, you're right, I misread this definition.

          The terminology seems confusing, though. A spy visibly works for one organization, but in actuality works for another. From the perspective of the first organization, their agent/worker is betraying them to another party. Why wouldn't this agent be termed a double-agent?

          ... Because the definition of the term "agent" used by intelligence services is different from the definition of the term "agent" used by game theory, isn't it.
          ```

    - u/Anakiri:
      ```
      Even if they mostly work at the object level, a CIA intelligence analyst is expected to be able to figure out what Russia knows about things. I'd say that you need at least one level of recursion to even be in the field with any success.
      ```

      - u/Norseman2:
        ```
        Sure, but should be looking at it from an outside point of view, not from the spy's point of view. At face value, Bob is an intelligence analyst as far as his coworkers are aware. His Russian recruiter goes a level or two deeper, knowing he's a mole and wondering if he has become a double agent. His American boss goes two or three steps deep, knowing he's a double agent and wondering if his loyalties actually still lie with his home country. His Chinese handler goes three or four steps deep, knowing he's a defected double-agent, and wondering if he's had opportunities to start collecting money from other countries as well.
        ```

    - u/sparr:
      ```
      HPMOR fandom is the only place I've ever heard triple/quadruple agent used to refer to three or more separate influencing parties. In other contexts, I've heard it used to refer to the same two parties repeatedly. I wonder if there are other terms to clarify this?
      ```

  - u/Lightwavers:
    ```
    This makes sense. Thanks for entertaining the scenario.
    ```

- u/xamueljones:
  ```
  This idea is inspired from a quote "in practice, infinite recursions are at most three levels deep."

  The zero level is generic statements about the world around us such as 'the sky is blue' and 'Alice is a nice woman'.

  The first level is any statement/reflections about yourself which includes statements like 'I (Bob) am a nice guy' or 'I (Bob) like Alice'. A common question of the first level is "What do I think of myself?" or "What do I think about other people?"

  The second level is any statement about other people's conceptions about yourself or another person. For example, 'Alice thinks I'm not so nice' or 'Alice thinks Carl is nice'. A common question of the second level is "What does Alice think about me (Bob)?" or "What does Alice think about Carl?"

  The third level is any statement/thought about another person's thoughts about what they think of someone else. For example, "Alice thinks Bob believes Carl is rude', 'Bob thinks Alice thinks he is attracted to her', and 'Carl thinks Bob thinks Carl wants to date Alice'. A common question of the third level is "What does Alice think I (Bob) think about Alice?"

  The first level is a model of your own mind. The second level requires you to have a model of other people's minds to reason about how they think about you. The third level is required to have models of how other people are modeling your thoughts.

  In this way, the magical races can reason about themselves and how other people think about the people around them. But without the third level, you can't know how other people think *you* think. The third level is required to lie or bluff convincingly. Without it, you can't model how other people will react to your lies.
  ```

  - u/Lightwavers:
    ```
    Aaah, thanks. I like this explanation. So humans would be master liars, and no one else would no what was going on.
    ```

- u/ArgentStonecutter:
  ```
  This is not technically a computational limitation in cognition. Anything you can do with recursion you can do with iteration and some book-keeping. Ink and paper and Bob's your uncle.
  ```

  - u/Lightwavers:
    ```
    Alright, but let's instate a fascist government and burn all the books. What does three levels of recursion actually allow you to do that you can't with just two? I cannot think of a single practical thing.
    ```

    - u/ArgentStonecutter:
      ```
      > Alright, but let's instate a fascist government and burn all the books.

      Let's have a fascist government that drugs everyone, like in Brave New World... burning all the books would also have a huge impact on *human* cognition. We're already using book-keeping to get around limitations in our own base computational structure. Literacy literally made us more intelligent.

      However you figure it, I think this was just EY coming up with something that sounded good.
      ```

      - u/Lightwavers:
        ```
        I'm having a hard time understanding what exactly you mean.

        Alright, let's say that only humans are capable of sorting through three levels of recursion, even in text. Are you saying that in this scenario, there is no practical difference between human and nonhuman cognition?
        ```

        - u/ArgentStonecutter:
          ```
          > I'm having a hard time understanding what exactly you mean.

          I'm saying you can prove anything given a counterfactual. They'd have to do more than burn all the books.

          *And* humans have limitations in our ability to perform computation... to process information... limitations in our cognition that *we* bypass by bookkeeping. This would literally change the kinds of things humans could think about as well.

          > Alright, let's say that only humans are capable of sorting through three levels of recursion, even in text.

          Pretty sure that breaks both Turing Equivalence and the Church-Turing Hypothesis, and I don't think that's what EY intended given the rest of HPMoR.
          ```

          - u/Lightwavers:
            ```
            Work with me here? Give everyone, human and nonhuman alike, paper and pen. Assume nonhuman entities as unable to comprehend more than two levels of recursion, no matter how it's written down. Ignore how impossible this is, just roll with it.

            What are the practical differences?
            ```

            - u/ArgentStonecutter:
              ```
              You don't have to comprehend recursion to simulate it. You aren't thinking in terms of recursion, you're thinking in terms of iteration.

              What you're talking about is some kind of memory limitation that can't be bypassed by reading and writing information in external memory. This amounts to functional illiteracy. Even something like "they can't recall more than two items they've read" wouldn't do it, because you could still build a Beowulf Cluster of Grendels. I'm not sure that a being so limited would be able to pass as a human in casual conversation.

              So there's your answer.
              ```

              - u/Lightwavers:
                ```
                I don't think you understand the difference between iteration and recursion. An iteration is a loop, a repetition, oftentimes with a variable changed each time. Recursion is taking a step back and calling a function within itself. So we take function thinking() and make it call function thinking() within itself, usually with something changed each iteration. An iteration is an important step in recursive functions, but while you need to iterate to recurse, iteration != recursion. Meanwhile, iterating function thinking() loops it continually. So you would be thinking about something, and then thinking about it again.
                ```

                - u/ArgentStonecutter:
                  ```
                  > I don't think you understand the difference between iteration and recursion.

                  I have been a professional computer programmer for almost 40 years. I wrote my first compiler in 1979. I have implemented at least a dozen arithmetic expression parsers (an inherently recursive algorithm) in Fortran (a language that doesn't support recursion). I know the difference between iteration and recursion. Given indexable storage they are Turing-equivalent operations.
                  ```

---

