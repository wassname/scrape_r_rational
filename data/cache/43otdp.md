## [D] Monday General Rationality Thread

### Post:

Welcome to the Monday thread on general rationality topics!  Do you really want to talk about something non-fictional, related to the real world?  Have you:

* Seen something interesting on /r/science?
* Found a new way to get your shit even-more together?
* Figured out how to become immortal?
* Constructed artificial general intelligence?
* Read a neat nonfiction book?
* Munchkined your way into total control of your D&D campaign?


### Comments:

- u/None:
  ```
  I feel inspired by Xvim's shaping exercises (from Mother of Learning), and I am interested in real-life application of his methodology. The essence could be maybe phrased like this: **take a small, concrete ability, and repeat it ad nauseam, until you master it. Only then continue with next step**. 

  Lukeprog from LW wrote about his experience with something [very similar](http://lesswrong.com/lw/58m/build_small_skills_in_the_right_order/) (TW: scientology, LW), and it also reminds me of [Kaizen](https://en.wikipedia.org/wiki/Kaizen) and of the math course on [Khan's Academy](https://www.khanacademy.org/).

  I don't think this is especially unusual idea, but for some reason I feel very motivated by Xvim and by MoL main character. Do you have any experience with this method of self-improvement?
  ```

  - u/Charlie___:
    ```
    Check out Brienne Yudkowsky's blog posts on "turtles," (slow and steady skills) they sound up your alley.
    ```

- u/traverseda:
  ```
  So I recently made it into the "final selection round" of [entrepreneurs first](http://www.joinef.com/).

  They contacted me, had me do a short programming test, that was intentionally designed so that most people couldn't complete *any* of the tasks in it in the allotted timeframe. I managed to complete one of the 3, but it was pretty close.

  The whole thing is pretty weird. They contacted me out of the blue, and a few days later I'm in their "final selection round".

  I suspect it might be because a lot of my linkdin contacts are impressive. A lot of CFAR graduates and others in the rationality community. They mentioned they found me through linkdin, but I pay *very* little attention to it.

  This definitely seems a lot easier then I'd expect, which makes me a bit nervous.
  ```

  - u/Chronophilia:
    ```
    Well done! Keep us posted!
    ```

  - u/None:
    ```
    This sounds exploitative.  What are the terms under which they'd be employing you?
    ```

    - u/traverseda:
      ```
      Known.

      >Entrepreneur First is a full-time six month programme. We invest £3,600 per founder (a £1,200 monthly stipend over the first three months) plus £10,000 in each company  for an eight per cent equity stake.  You'll also get office space all over London, legal and admin support so that you have the best possible environment to meet potential co-founders and launch your startup. 

      So pretty standard. Not as good as some of the better known accelerators, but not completely far off. Probably helps that it's no in the bay area.
      ```

      - u/None:
        ```
        So... is that actually a liveable wage in London for three months?  What happens after the first three months?  How are you living?
        ```

        - u/Chronophilia:
          ```
          Yes, £1200/mo is reasonable. I live in London and I spend a little less than £1000 per month.

          Edit: Be warned that rent is the main factor. I share a flat, and my share of the rent is £650/mo. Depending on where in London you live, though, you could burn through your entire budget and then some on a one-room studio.
          ```

          - u/None:
            ```
            Great!
            ```

    - u/None:
      ```
      [deleted]
      ```

- u/AurelianoTampa:
  ```
  I've come up with a funny problem recently.

  I've been reading a lot of rational fiction recently. It's not the only thing I read, but it's been most of it for the past few months. And when I turn back to "traditional" fiction, I find myself criticizing incongruities and poorly planned characters. Mostly in TV shows and movies.

  For example, I watched Wall-E for the first time over the weekend (yes, I know, shame on me for waiting so long). I liked it; it was cute and sappy. I could even get behind the pro-environmentalism motive. 

  But I kept criticizing the illogical parts of it. Why do the robots make trash towers? Why does Wall-E have emotions? Is that a change, or were all of the robots originally given the capacity? What happened to the humans not rich enough to leave - I find it hard to believe they just died out (it's not like it was a nuclear apocalypse). Why, after 700 years of harsh weather, were things like paint still on buildings? Why didn't all the metal rust? And on the spaceship, why did they have alarms ringing outside the ship? No one in a space suit would hear them. 

  I mean, it's a kid's movie, but I just kept overthinking everything and it sorta took away from the experience. I've been just as bad when playing *Fallout 4*. Worse, probably.

  I felt something similar when watching Agents of SHIELD. The characters' motivations jump so freaking often and seem so short-sighted and illogical. Again, I realize - cable TV show that relies on drama and creates it to keep viewers invested. But it was really frustrating.

  TL;DR: Rational fiction has ruined poorly written mainstream media for me!
  ```

  - u/Chronophilia:
    ```
    It's room for speculation and extrapolation, which makes watching media more fun and exercises your creativity! Especially if it turns out there's an actually logical reason that just wasn't explicitly stated.

    >Why do the robots make trash towers?

    It's the logical way to arrange cuboids of trash so they take up less space. Perhaps there were originally other robots that carried the towers away.

    >What happened to the humans not rich enough to leave - I find it hard to believe they just died out (it's not like it was a nuclear apocalypse).

    Starvation? No plants anywhere means no food.

    >Why, after 700 years of harsh weather, were things like paint still on buildings? Why didn't all the metal rust? And on the spaceship, why did they have alarms ringing outside the ship?

    I'm stumped on these ones.

    >Why does Wall-E have emotions? Is that a change, or were all of the robots originally given the capacity?

    It's a change.

    One of the major themes of Wall-E is that new experiences and challenges are what make us human. Throughout the film, the robots that display the most personality are either those who have to deal with the outside world (Wall-E, Eve, Auto, Mop) or those who've been damaged and learned to cope with it. The humans live in a tightly controlled environment and have basically no initiative or personality at the start of the film. Wall-E and Eve re-introduce the unexpected into the Axiom. The Captain is kicked out of his routine and ultimately defies Auto and his superiors, and it's all sparked off by Eve's plant and a few specks of dirt. Wall-E accidentally switches off a woman's computer and makes her look around herself for the first time. As long as the humans aren't challenged or stimulated at all they're content to be more passive than any robot, but when they need to re-colonise the Earth they pull off a roaring success. I think this is the film's main thesis. In the end, it's an optimistic one.

    In my opinion, your enjoyment of rational fiction has equipped you to ask these questions. Which is good! Now you can learn to answer them as well.

    ----

    p.s. This works because Wall-E is an excellently-written film and the world doesn't just stop making sense the moment you scratch at it a little. Poor worldbuilding won't hold up to this kind of scrutiny, but it can still be fun to try.
    ```

    - u/Frommerman:
      ```
      On the paint thing, it could be that there were robots designed to repaint the cities every once in a while, and that they have simply shut down as well, with Wall-E being the last survivor. If all of the paintbots died in the last 25 years or so, the paint would be faded, but not gone. Especially if the trash towers provided an insulating effect from harsh weather and wind.
      ```

  - u/IomKg:
    ```
    While there are plenty of works where the irrationality is just bad writing, for a lot of works it can simply not be the point of the story.
    In my opinion the question you need to ask yourself is not "Are the things happening on screen rational?", but instead "Can I imagine rational alternatives to the irrational issues in this story, and have its main point persist?".
    if the answer to the second question is "yes" then probably the irrationality is not really a big issue. Yes I do believe a better writer could probably make it both rational, interesting and keep the point(even if the alternatives i can imagine are not all of the above), but does it -really- matter if the main point that the writer tried to make would still stand the rationality test?
    ```

    - u/Transfuturist:
      ```
      Principle of Charity + Conservation of Detail.
      ```

  - u/NotUnusualYet:
    ```
    These sorts of things bug me too (why does the resistance in Star Wars VII, an organization spanning star systems, have about 30 fighters to its name?) but I don't think that irrational worldbuilding is the same thing as poor writing. Wall-E isn't poorly written - it's a masterpiece of visual story telling. It's just willing to sacrifice the scientific or logical details of its world for the sake of its desired plot, characterizations, and themes.

    We're here on /r/rational because we're not nearly so willing to make the same trades, but rationality isn't the be all end all of writing.
    ```

    - u/ArgentStonecutter:
      ```
      > why does the resistance in Star Wars VII, an organization spanning star systems, have about 30 fighters to its name?

      Irrationality in Star Wars VII?

      Now there's a well you'll never drink dry.
      ```

  - u/OutOfNiceUsernames:
    ```
    [There was a relevant discussion on the same issue not long ago:](https://upload.wikimedia.org/wikipedia/en/e/e3/Destiny%28Sandman%29.JPG) 

    >[Metropolitan Man ruined my hype for Batman Vs. Superman \[D\] \(self.rational\)]( https://www.reddit.com/r/rational/comments/3v90dw/metropolitan_man_ruined_my_hype_for_batman_vs/)

    >*submitted 2 months ago by KharakIsBurning*

    > > /u/alexanderwales wrote the defining piece about how I approach any DC universe work, and now I can't approach it at all.
    > > 
    > > In the new trailer, it seems Batman clearly articulates Wales's Lex Luthor's primary concern: Superman is an existential threat to humanity, and must be destroyed. This motivating factor is explicitly stated in the newest movie trailer, and is explicitly stated in Metropolitan Man.
    > > 
    > > Yet, it is obvious that is where the two diverge. While Lex daftly maneuvers around the Kryptonian in the fan fiction, it is obvious that Lex Zuckerberg and Batman only know how to use force. They will not find out Superman's weaknesses by probing at the edge of his powers. They will attempt to destroy him by (1) building a better batsuit and when that fails (2) making an even more powerful existential threat. Batman will switch to Superman's side to defeat this Big Bad along with the help of Wonder Woman.
    > > 
    > > That is, the power balance will be changed and the side that can punch harder will win.
    > > 
    > > God. It could be a good movie, too. It could have a good script and good action and not be as dark-and-edgy as its going for... but Metropolitan Man will always be in the back of my mind saying "this is dumb. hey. this is dumb."
    ```

  - u/gbear605:
    ```
    > Agents of SHIELD

    I had the same thing when watching Supergirl. I enjoy the show, but I also can't stand it.
    ```

    - u/MugaSofer:
      ```
      In all fairness, Supergirl is much less logical than Agents of SHIELD.
      ```

- u/None:
  ```
  [Election time is a lot less anxiety-inducing when you actually have statistical forecasts.](https://www.reddit.com/r/SandersForPresident/comments/43od7l/quinnipiac_feb_1st_iowa_poll_release_detail/czjokj8)
  ```

  - u/artifex0:
    ```
    Something else to keep in mind about the primaries is that Clinton and Cruz are probably a lot more popular with the super-delegates than the ordinary caucus voters, and the super-delegates can easily swing the results.
    ```

    - u/Rhamni:
      ```
      It will be interesting to see. Hillary had the super delegates in 2008 as well (Though by a smaller margin), but when the popular vote swung in favour of Obama they followed after. If Sanders somehow wins the popular vote but Hillary wins on super delegates, my American friends (All two of them) will be so extremely disappointed. And me too.
      ```

      - u/Turniper:
        ```
        At this point, just shy of half the superdelegates have already publicly committed to Clinton, as opposed to just over 1 percent of them committed to Sanders.  While they can still change their minds, Sanders is basically operating with a 360 delegate handicap, which is unlikely to change baring several landslide victories in early-middle primaries.  It isn't impossible to overcome, but at this point in time Clinton still looks like a near shoe-in for the Democratic nomination, regardless of primary results.
        ```

        - u/Rhamni:
          ```
          She's definitely most likely to win. But I think, or perhaps mostly hope, that the superdeligates will not ignore the prospect of the public outcry that would come if they override the primary. Which would, after all, make a lot of voters extremely unhappy with them not very long before a general election.

          That said, Hillary has a clear lead nationally in the primary, so the point may be moot.
          ```

- u/Transfuturist:
  ```
  So, I just remembered a lesson about social dynamics I learned from agar.io back when it became a thing. (I've been thinking about/researching game design and how you can use games to teach things/communicate, though the things taught aren't necessarily useful)

  The free-for-all games were fun, but I eventually became more interested in team games. At first I played like an individual, but with the added benefit of there being a few monoliths that I could commensalize, in the sense that I used them to ward off my predators while not particularly giving anything in return.

  So, that was interesting for a while as well. What changed my normal parasite behavior was interesting. In one game, our team was losing, consistently. There were three teams and we were less than a sixth of the pie, struggling to make headway. There were two different things I tried in order to fix this, which I suppose could be considered experiments.

  The first was selfish. I named myself 'W to beat green'. Green was in the lead by far, and the W key was what allowed you to eject bits of your mass out in order to get smaller. At least, that was what I thought. I had noticed people donating mass to others, but I hadn't really paid attention, playing mostly egocentrically. Now, however, I realized that mass could be traded/invested, and that was what I used. The strange thing was, my name actually worked. A bunch of people on my team committed themselves to collecting mass from the autotrophs and our opponents, and donated it to me. Often it was a few individuals who attached themselves to me, forming a kind of silent camaraderie. I quickly became very very big. I don't remember who won in the end (it never actually ends), but I believe we did manage to topple Green from their lead.

  The second was the opposite. That run had interested me, so I decided to play the role of the smaller symbiote. I committed myself to giving mass to others, specifically, single targets, who I followed and fed regularly. They became the monoliths, and sheltered me from larger enemies. Instead of a commensal relationship, I became a productive mutualist.

  I'm not sure if I'm inventing one or the other of these memories, or if both really did happen, or if I'm mixing up the order. But what I learned from agar.io was the power of social cooperation, and to an extent, tribal bonds and manipulative leadership, in the face of a complacent but large opponent.
  ```

  - u/Escapement:
    ```
    Interesting story. Thank you for sharing!

    > But what I learned from agar.io was the power of social cooperation, and to an extent, tribal bonds and manipulative leadership, in the face of a complacent but large opponent.

    I actually play team games a lot, especially Dota 2, which is a 5v5 game with fixed sides from the start of the game. I actually played a game recently where another player by charisma, willpower, and manipulative leadership caused our team to come back from a large deficit and win the game, in spite of lesser individual skill from basically all of our players on an individual level.

    Getting people to cooperate in Dota 2 is partially analogous to what you describe from Agar.io - I only played Agar.io for about a half hour once, but there are some striking similarities - teams where some players would sacrifice their own strength to add to the strength of others, outperforming more naive teams where it's every man for themselves.
    ```

    - u/Transfuturist:
      ```
      My experience with multiplayer has mostly been Quake 3 (and Legions: Overdrive/Fallen Empire: Legions). Super fun, but not a lot of coordination. I think team leaderboards might not help, as it acts as a way of pitting teammates against each other for better K/D ratios.

      A large part of my latent, impossible, and undesirable desire to join the military is to act as one part of a large machine. That also comes out in an unrealized desire for coordinating multiplayer. I'm not very fond of the individualistic multiplayer that's so common in most FPSes; I want to see a multiplayer game that is fundamentally collectivist, with explicit emphasis on coordination, specialized roles, and dependence on strategic intelligence and communication.

      I've heard of a few things that might fit. Space Station 13 is very much this, but not combat-oriented, and I fear that it will suck time out of my life like a sponge because I'm so attracted to this concept. Planetside 2 isn't something I know much about, but it appears as though its various levels are all parts of the same battlefront, to the point that it looks like a strategy game on the high-level. That is incredibly attractive. I want that multiple level of detail; where 'officers' as a role decide on strategies and goals and assign missions and direct troops. A literal virtual war, no deaths needed.

      To a lesser extent, the idea of clans in a lot of FPSes is also appealing, where voice communication is enabled and people actually treat games as something to be won together. I've never been able to play games with a mic, though, and I've never gotten good enough at any game to ever think I was up for joining a clan.

      I remember another story involving a game with impoverished communication. This was a game specifically designed so people had to help others, and you had to be helped to progress. It was a (computer) mouse maze game, with moving walls and buttons, and often several buttons had to be pushed at once in order to let people through. It was amazing. While I'm sure there were defectors, people queued up. A mouse entered the stage, made their way to a button, helped the next person through, and after all the mice that had been there before left their buttons and made their way to the exit, entering mice replaced them, and they could move forward themselves. There were also times when people would get trapped together (I was often trapped). You could draw on the walls, so we drew little messages back and forth. One guy and I stayed together for a little while, and when we ended up parting we drew each other little hearts. So cute. :)

      The key to coordination with impoverished communication is establishing Schelling points. 'W to beat green' is a minimal amount of information, communicated in the only info-dense medium the game has, names, but it reminds people that they can donate their power, and designates you as a natural recipient.

      Mutual cooperation is a Schelling point. So is mutual defection, but if the game isn't zero-sum why the fuck would you do something like that? We're in it together.

      (In cases where one side defecting and one side cooperating results in a greater total gain than mutual defection *or* cooperation, and the gains are transferable, then alternating defection, or one-sided defection plus sharing, can be another optimal collective strategy. I'm not sure what this type of game is called.)
      ```

      - u/Escapement:
        ```
        Regarding games to be won together: I have greatly enjoyed the game Keep Talking and Nobody Explodes, a collectivist game where one person plays a bomb defuser and can see the screen which has a bomb to be defused, and the other players are all playing bomb defusal experts who can see a (long, opaque, confusing) manual that tells how to defuse the bomb. The game in essence is trying to replicate the bomb defusal scene from movies where people are shouting about what wires to cut or what-have-you while a timer ticks down. The defuser relays information to the experts about what they see, while the experts relay instructions based on that advice. It's a great party game and can be played with microphones online or in person. It's good for playing with IRL friends casually, as it needs low equipment (only 1 computer / 1 manual, can have additional copies of manual).
        ```

      - u/None:
        ```
        [deleted]
        ```

- u/xamueljones:
  ```
  Has anyone here done anything they think is interesting involving dreams?
  ```

  - u/gabbalis:
    ```
    Uh, yeah, if you manage to fall asleep while on a caffeine buzz, you'll remember more of your dreams, and the buzz also draws time out a bit. As a result you also get the illusion of having dreamed for a very long time.

    ...Of course that's if you can fall asleep at all, and it's probably not healthy. But I've gotten some enjoyable experiences out of it, so I think it's worth trying occasionally.

    Edit: Back in highschool I had a tendency to stay up late then take a powernap after my morning coffee. That's where I recall most of my successful sessions.
    ```

  - u/Chronophilia:
    ```
    I tend to get much more vivid dreams when I'm not sleeping properly. Sleeping at high altitude, missing a dose of medication, having a fever, all induce particularly vivid dreams. I think this is related to /u/gabbalis' experiences with caffeine in the sister comment.

    It's not always pleasant - I wake up still feeling tired, and it sometimes causes nightmares.
    ```

    - u/Aabcehmu112358:
      ```
      Curiously, my experience is the opposite (not accounting for the possibility of forgotten dreams, anyway).

      Usually when I sleep poorly, with similar causes as those you listed, I have no sense of having dreamt at all, and at most have only a vague sense of having been dreaming, without any recollection for content. Meanwhile, when I sleep well, especially when I have the opportunity to bed especially early or sleep-in especially late, I have much more vivid memories, and often find myself so intellectually engrossed with them that I will consciously choose to back to sleep, not because I am still tired, but because I am interested in continuing the dream (which, surprisingly enough, do usually continue more or less linearly from where they ended).
      ```

    - u/Uncaffeinated:
      ```
      My theory is that forgetting a dream is the last stage of sleep, so if you remember your dreams, that's a sign that you're not sleeping properly. Don't know how accurate it is, but it matches my experiences.
      ```

- u/DataPacRat:
  ```
  **How big is Earth's past light-cone?**

  Designing a story, I want to know how confident a character should be about something. To know this, I need to know two numbers: How much space-time hyper-volume exists in his past light-cone (ie, the cubic volume multiplied by the time), and how large his past-light-cone will be at various points in the future (eg, 100 years, 10,000 years, 1,000,000 years, etc).

  Does anyone here have a good idea on how to approach the math?
  ```

  - u/Chronophilia:
    ```
    The hypervolume of a 4-cone is the 3-volume of the base, multiplied by the height, divided by 4.

    Ignoring the expansion of the universe, the hypercone is 14 billion years long and its base is a sphere of radius 14 billion lightyears.

    I get about 4\*10^40 light^(3)years^(4), but somebody should probably check that for me.

    It'll be a little bigger once you add the expansion of space into the mix, but I think it'll probably still be around 10^41 light^(3)years^(4).
    ```

    - u/DataPacRat:
      ```
      Let's see... using the figure of 13.82 billion years from https://www.google.ca/search?q=age+of+the+universe , the past light-cone of Earth, in light-years^3-years, circa 2100 AD, can be given by (4/3 * pi * (13.82e9)^3) * (13.82e9) /4 , which Google gives as https://www.google.ca/search?q=(4%2F3+*+pi+*+(13.82e9)^3)+*+(13.82e9)+%2F4 = 3.8199774e+40 . Twiddling with Laplace's rule of succession, then roughly, we can be 99% confident that we will continue to see no evidence of extraterrestrial life until that figure is about 1% higher, ie 3.858e+40, which happens when the 13.82 billion year figure increases to roughly 13.854 billion years, 34 million years from now. That's... a much stronger statement about the Fermi paradox than I was expecting.
      ```

      - u/Chronophilia:
        ```
        Well, we don't know for sure that there are no aliens anywhere in that volume. If they're not drastically re-engineering stars by the million, we're quite unlikely to detect them outside our own galaxy.

        Aliens with the same tech level as us would have difficulty detecting us from more than a few light-years away. We can barely detect Earth-sized planets at all, never mind determining if they have life.
        ```

        - u/DataPacRat:
          ```
          > we don't know for sure

          And thus the Great Filter theory, as can be seen at https://wiki.lesswrong.com/wiki/Great_Filter . The best estimate for the number of extraterrestrial civilizations may or may not be zero, but there is /a/ best estimate, and a level of confidence to be applied to that estimate; and those numbers can be used when trying to make certain critical decisions.
          ```

  - u/PeridexisErrant:
    ```
    You have to choose a start date, which can be fairly arbitrary.  2.8ish BYA for formation of earth, 900ish MYA for multicellular life, 600KYAish for modern humans, 19xx for birth of protagonist... (nb - check those numbers before use) 

    Then take the volume of a sphere with radius (elapsed time * c) and integrate over the length of time you've selected.
    ```

- u/None:
  ```
  Everyone says Kevin J Anderson is a bit crap, but *The Butlerian Jihad* is okay, really. It's not as "whoa, dude" as the original *Dune* series, but I'd still recommend giving it a go.
  ```

  - u/PeridexisErrant:
    ```
    Meh, I read it on a couple of planes a few years ago and wasn't that impressed - it was about average for scifi, which is a fair letdown from *Dune*.  Depends on what you expected, I guess...
    ```

- u/tvcgrid:
  ```
  One thing I've come to appreciate the difficulty of: prioritizing what to do and then actually doing it. I used to cycle a lot thinking about what to do, because any potential train of thought about what to do today/this week ended up leading to several hard-to-answer questions about future goals/objectives. And then, I'd get distracted about how certain choices now might affect me/others 3 months down the line.

  But one generally useful technique I'm now using is to just be okay doing a shitty first draft during the prioritizing phase, then revising and iterating once maybe, and then calling it 'good enough' after a max amount of time and just moving on to doing the highest priority thing. Many of the smaller decisions that come up after you're decided the main priorities don't even matter either way... often, the cost of switching back if you made a wrong decision is very very low, so why even bother wasting attention on minor, cheap-to-change decisions? I'd rather worry about prioritizing the right things every week and then reflect on how that worked out at the end of the week.

  Anyway, nothing earth shattering, but I now usually ask: "what would it cost to undo this if I had to?"
  ```

- u/boomfarmer:
  ```
  I'm at a strange impasse. Here's a list of things I want to do, in the order that I think they need to be done (and why)

  1. Revise my Senior Thesis (a defense of Catholicism to The Protestants), annotating why I wrote it (for the grade), why I disagreed with it then and why I then thought it was bad (jumping from "It is necessary that a First Mover exist" to "Jesus is His Son") and why I think it is bad now.
  2. Write down my current set of opinions on Things. (Does anyone have a good self-interview framework for this?)
  3. Reread HPMOR and rewatch TTGL, taking notes on themes, characters, and plot elements ([Here's why](https://www.reddit.com/r/HPMOR/comments/3c7w5y/youve_watched_gurren_lagann_and_read_hpmor_what/))
  4. Read the Sequences and associated works
  5. Figure out how my mind has changed since Point 2.
  6. Write the fic that I've been planning to write.

  I have a whole bunch of uncertainties about this process that are hard to articulate. I'm kind of scared how my mind might change, and I'm kind of scared about writing my thoughts about my lapsing. I'm uncertain why.

  Does anyone have any advice or techniques for comparing brain states and beliefs? I want to know how reading the Sequences will change my mind on things.

  And, of course, does anyone have any advice on writing crossover fanfic?
  ```

  - u/None:
    ```
    > Write down my current set of opinions on Things.

    Which Things, and why write down your opinions?  Ah, for point (5).  Also, has your senior thesis already been submitted?

    It seems like you have two actual tasks in mind:

    1) Write an HPMoR-TTGL crossover fanfic.

    2) Clarify your Views on Things, read a bunch of philosophy stuff, and then (frighteningly) find out if you've changed your Views on Things afterwards.  If this sounds scary, not to worry: you're a lot better at *not* changing your mind than you think you are ;-)!

    You should schedule them.

    >I'm kind of scared how my mind might change, and I'm kind of scared about writing my thoughts about my lapsing. I'm uncertain why.

    Because different frameworks and theories for Thinking About Life are difficult to express in each-other's terms, so it ends up seeming as if you're a different person on one side or the other?

    Well, you're not a different person.

    Also, am I correct to guess that by "lapsing", you mean ceasing to believe in your former religion?  The actual thing about the Sequences is that they take nonreligiosity for granted as a trivial consequence of having even a little scientific education, let alone "Rationality".

    The upside of all that condescension towards religion is that it's rarely mentioned at all.

    The downside of the Sequences in general is that you'll get vastly more out of them if you come at them with preexisting knowledge of the formal scientific and philosophical topics they actually cover: they're not *sufficiently good* introductions to Bayesian statistics, causal inference, meta-philosophical naturalism, machine learning, cognitive science, etc. to replace actually learning those subjects.  They weren't intended to be that.  But it does mean that what you get out of them is partly what you bring to them, and if you come to them *lacking* in background, you might leave thinking some things that their author and the general community did not intend you to think.
    ```

    - u/boomfarmer:
      ```
      > Also, has your senior thesis already been submitted?

      Almost six years ago. It was something like 50% of my grade for the Evangelical Studies class and 50% of my English grade in senior year of high school. (School was non-denom Protestant with Baptist teachers and conservative Anglican backing. My family were token Catholics.)

      I'm pretty formally a Lapsed Catholic, gone full agnostic, but I want to document the reasons I have for why I made that transition.

      > It seems like you have two actual tasks in mind:
      > 1. Write an HPMoR-TTGL crossover fanfic.
      > 2. Clarify your Views on Things, read a bunch of philosophy stuff, and then (frighteningly) find out if you've changed your Views on Things afterwards. If this sounds scary, not to worry: you're a lot better at not changing your mind than you think you are ;-)!

      The problem here, I think, is that 2 blocks 1, because of the research that I'm going to need to do for 1 being "read a bunch of philosophy stuff".

      > ... they're not *sufficiently* good introductions to Bayesian statistics, causal inference, meta-philosophical naturalism, machine learning, cognitive science, etc.

      Eek. I definitely do not have formal training in any of that, except maybe naturalism. (Plant biology, microbiology, some computer science, various communications and marketing techniques, and so on I do have training in.) I'm guessing there isn't a recommended reading guide to the sequences?

      Are there schools of rationalist thought that are web-accessible and friendly that aren't the Less Wrong Sequences? Or are there other places that would be a good place to get started in Less Wrong? I've heard things about "EA"?

      > The upside of all that condescension towards religion is that it's rarely mentioned at all.

      That's pleasant to hear. New-Atheism-style religion-bashing is definitely not my style.
      ```

    - u/boomfarmer:
      ```
      > read a bunch of philosophy stuff, and then (frighteningly) find out if you've changed your Views on Things afterwards. If this sounds scary, not to worry: you're a lot better at not changing your mind than you think you are ;-)!

      To clarify: I'm not worried about changing my views. I'm worried that my views will change and I won't know *in what way* they've changed.

      Do you know of any good ways to write down your self, before and after beginning such an endeavour?
      ```

      - u/MrCogmor:
        ```
        These are a good starting place. 
        http://ww3.haverford.edu/psychology/ddavis/p109g/kohlberg.dilemmas.html
        ```

---

