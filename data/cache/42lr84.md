## [D] Monday General Rationality Thread

### Post:

Welcome to the Monday thread on general rationality topics!  Do you really want to talk about something non-fictional, related to the real world?  Have you:

* Seen something interesting on /r/science?
* Found a new way to get your shit even-more together?
* Figured out how to become immortal?
* Constructed artificial general intelligence?
* Read a neat nonfiction book?
* Munchkined your way into total control of your D&D campaign?


### Comments:

- u/LiteralHeadCannon:
  ```
  In terms of general announcements, I hope to publish a couple of long-form stories on /r/rational starting soon.  The two I really have pinned down are an original fic and a fanfic.  (The fanfic is *not* going to be the same one I planned several months ago; my interest in that project sadly faded during the planning stage.)
  ```

- u/Rhamni:
  ```
  There is this friend of my family. A 50 year old man, who works as an honest to Albert inventor. He's been a tech wiz since childhood, and he and a few others have had their own company for decades where they are asked to make a piece of technology that does x and has to work with xyz, and they make it. Mostly electronics, but not exclusively. They are doing pretty well for themselves. I'm not sure if he's rich, it hasn't come up, but I'd be very surprised if he makes less than $10k/month. They have a tech lab at his place of work, but he also has one at home, where he fools around with things on his own. He is a very intelligent man, and whenever he gets guests he's super excited to show people what he's working on or reading about. Sometimes I can follow along with most of it, but usually it's too specialized. He's very interesting, and a nice person too, so I really like him.

  But. He also gets very excited about things that most scientists would dismiss immediately. He's very interested in Cold Fusion, and thinks it's the way of the future. He thinks global warming is real but will be solved without detriment with future technology. His bookcases are full of books about conspiracy theories and 'alternative history' and aliens. And a few weeks back he told us he's been reading up for months on electromagnetism, including notes and journals by people like Maxwell and Tesla. And he's convinced that the Ether is a real thing. He's hoping to be able to come to a point where he can do meaningful experiments in the lab he has at home.

  I just... The man is more intelligent than me. A lot more disciplined. And *massively* more educated, especially regarding anything to do with physics. So I don't understand how he can get so 'into' things you'd only see taken seriously on the History channel. But at least he's sincere enough in his convictions that he spends thousands of dollars on lab equipment so he can go hunting for knowledge himself.
  ```

  - u/Sparkwitch:
    ```
    Self-confident autodidacts tend to trust their own judgement. They have a lot of experience doing so, and considerably less experience trusting so-called experts. An inventor, especially, is going to be well-versed in looking outside the box for ideas that have not been fully researched and explored. The [Luminiferous Aether](https://en.wikipedia.org/wiki/Luminiferous_aether) is actually a great example.

    Physicists of the 19th century didn't believe it because they were blinded or stupid. They believed it because it was a widely-accepted, coherent model which had withstood significant experimentation. Give the Wikipedia article a look or, if you want old school, I recommend Max Born's chapters on the subject in his 1922 book on Relativity... which is out of copyright and available [here](https://archive.org/details/einsteinstheoryo00born). You might even recommend that book to your family friend.

    Identifying trustworthy experts does require some degree of intelligence, but deciding to trust them requires an entirely other sort of mental exercise. Don't think too ill of whom others choose to trust.
    ```

  - u/SvalbardCaretaker:
    ```
    I know this kind of person as well. I found this talk https://www.youtube.com/watch?v=WRdJCFEqFTU - I dont remember the timestamp for this particular piece of info unfortunately- enlightening. The referent puts forth an at least partially plausible hypothesis. 

    The parameters of your own neural network are very carefully weighted to find a good balance between "inventing new hypotheses" and "disproving new hypotheses". Obviously "inventing new hypotheses" is what being creative is all about; crank this up too much and you get schizophrenia. But a successful buisness person needs to have passed both thresholds; not only "inventing an economic niche" but also "not immediately disproving it into the ground", which seems like its a very common failure mode(eg. not pursuing further because "will not work for XYZ reasons").
    ```

  - u/alexanderwales:
    ```
    I know a guy *just like that*. Incredibly brilliant, holds a bunch of patents, made a ton of money through his engineering company ... and believes in all sorts of crazy stuff. I attribute it mostly to an anti-authoritarian streak, though I did once talk with him about the JFK assassination, which I think had a profound effect on him and the search for meaning there made him much more open to fringe science.

    Also, fringe science tends to be more fun to read about than established science, because everything is new and revolutionary, one step away from changing the world, which people really go in for.
    ```

  - u/LiteralHeadCannon:
    ```
    One of the various projects I'm considering writing for /r/rational is a memoir of some of my adolescent years with a focus on my father's pursuit of a perpetual motion machine and its effect on me.  The man's a brilliant programmer who's been doing important work since computing was new, in many respects he's one of the smartest people I know, but he's just completely convinced, and has been for many decades, that free energy is relatively easy and it's just that no one's thought of it before.  He managed to convince a young me of his position, and *man* did it mess me up psychologically.

    Would this be a good fit for /r/rational?  It's an irrational nonfiction as opposed to a rational fiction.
    ```

    - u/TennisMaster2:
      ```
      Sure.  Just include the coda where you learn (or begin to learn) how to think more rationally.
      ```

- u/IomKg:
  ```
  So what do you guys think about [pushed to the edge](http://www.mirror.co.uk/tv/tv-news/derren-brown-convinces-three-people-7172605) ?
  both in regards to what it says about people and about what it says when that passes for entertainment\is legal?

  personally I don't think it really says a lot as is, because the participants were apparently selected(based on how "obedient" they were) and the fact that we can't even know how many people were tested to produce those 4 people which reached that last point, out of which only 3 actually did it.

  I wouldn't be too surprised even if 75% was the actual number(of people willing to murder in some circumstances), but I tend to be skeptical as-is considering the motivation of the producers to sensationalize.

  As for the legality of the show, I don't see an issue as long as the actions of the participants were not illegal, and even then i am not sure if its really a problem(to intentionally cause someone else to commit a crime)
  ```

  - u/Escapement:
    ```
    Have you read of the [Milgram experiment](https://en.wikipedia.org/wiki/Milgram_experiment)? It provides some context for this sort of thing - and makes me feel that the show could conceivably have been run unscripted/unprompted and achieved much the same results. However, as it is a TV enterprise, it would make the most sense for them to have a pretty strong script and manipulate things to deliver whatever narrative they think would resonate with viewers and drive audience interest and news reporting upward, in search of higher ratings, as all 'reality TV' has done forever. A show that came out with the message "most people are pretty decent and don't murder people" wouldn't make the news.
    ```

    - u/ArgentStonecutter:
      ```
      There's been a good deal of criticism of the [Milgram Experiment](http://www.psmag.com/books-and-culture/electric-schlock-65377) as well as the [Stanford Prison Experiment](https://www.psychologytoday.com/blog/freedom-learn/201310/why-zimbardo-s-prison-experiment-isn-t-in-my-textbook).
      ```

    - u/IomKg:
      ```
      Yeah i am aware of that experiment, from what i read the guy who designed this supposedly took lessons from that experiment as well as the stanford prison experiment(thus he made sure the subject felt "low status" compared to the people giving him orders).

      Anyhow i think there is a difference between giving a shock which "may" kill a person and physically pushing someone from the roof..
      ```

    - u/Sailor_Vulcan:
      ```
      wait. do the victims of the murders in this show ACTUALLY die?
      ```

      - u/Escapement:
        ```
        They have the same guy (Bernie) being pushed over the edge of a roof multiple times, partly because of a homage to Weekend at Bernie's. So, no. It's all a setup. Everyone in the show that isn't one of the people deciding whether or not to push is definitely an actor / conspirator / etc. The people doing the pushing may also be acting rather than being genuinely bamboozled - with Reality TV-esque stuff like this, it's pretty safe to assume that the producers *make* it interesting to televise, by hook or by crook.
        ```

  - u/Gigapode:
    ```
    Have you seen the episode/feature where Darren Brown (the same guy) apparently hypnotises audience members to such a degree that they willingly rested in a bathtub of ice? After they were shown unable to keep their hand in the same tub for a prolonged period of time? 

    He's actually released a book about some of the techniques he uses. 
    Its really hard to determine how much of it is real or what the trick is (as is the case with a lot of Darren Brown's stuff, which I would generally recommend watching).
    It would seem that some people are more readily suggestible than others.
    ```

  - u/Chronophilia:
    ```
    I don't think being "capable of murder" is necessarily a bad thing. You have to be very brave to act to defend yourself or your family. Sometimes people start fights, and you have to fight back. HPMoR called this "killing intent", and while all supervillains have it, plenty of perfectly virtuous people do too.

    It's one thing to have the inherent capacity to kill another person. It's another thing to do it when you don't have a *very very very* good reason.

    So a reality TV show has manipulated people into revealing an aspect of their personality that they wouldn't usually show? How unexpected. Also, turns out the Pope is a Catholic and bears shit in the woods.
    ```

    - u/IomKg:
      ```
      It should probably be mentioned that the reason the people "murdered" was because they were brought to the situation where the victim, who was supposed to be some billionair, will sue them and generally make their life hell. As well as being instructed to to so by "higher status" people from a "board of directors". The entire thing was built to loosen their morals. Starting with a relatively "harmless" point where they were just helping to conceal his "death" so as to not cancel a fund raiser for poor children, all the way to being in a point where he is sitting alone on the edge of the roof with no witnesses and they get to choose if they want to push him or leave him
      ```

- u/LiteralHeadCannon:
  ```
  If everyone in a world had a magical device that displayed in what percentage of timelines they were alive in one year, what behaviors would emerge? What would the causal effects be like?
  ```

  - u/alexanderwales:
    ```
    If we built a simulation of the universe that *didn't* take quantum effects into account, how often do you think that it would be wrong about whether I was dead in a year? I think that's the question that I'm left with.

    On short timescales and with large objects, the universe appears to be deterministic. The motions of the planet can be predicted using even crude measurements, with the quantum-level stuff having very little to do with it. There are certain things that quantum-level changes are never going to have an appreciable effect on.

    Now, does this extend down to the level of humans? Do quantum level effects have any bearing on what I'm going to eat for breakfast tomorrow morning, or whether I'll fall in love, or whether I can remember the right answer on a test? So far as I know, that's an open question that dips down into fringe science, mostly because we don't have a good way to experimentally test any of the predictions that people are making. But if humans *aren't* (by and large) subject to quantum-level effects, and we live in a psuedo-deterministic world, then most of the time the death-o-meter is going to say 99.99% or 0.01%, because many-worlds just doesn't really enter into it, and the information gleaned from the death-o-meter won't be too useful unless you try to munchkin it.
    ```

  - u/LiteralHeadCannon:
    ```
    To get a little more specific, what should I expect to happen if I'm a queen in this world and I launch a plan to draft two million men, and, in thirteen months, send those with the highest odds of survival out to invade and conquer a neighboring nation?
    ```

    - u/None:
      ```
      [deleted]
      ```

      - u/LiteralHeadCannon:
        ```
        The trouble is that humans are also part of the system of probabilities.  So it's not quite as simple as "modifying your intentions and rechecking repeatedly" - because whatever chance there was of your modifying your intentions was included in the original probability.
        ```

        - u/IomKg:
          ```
          actually, wouldn't -everything- be included? how could you model the probability calculation without either making it static or meaningless?
          ```

          - u/LiteralHeadCannon:
            ```
            At every instant, it looks at all universes descended from the current universe in exactly one year; it counts all universes wherein the bearer is alive, compares that number to the number of universes period, and displays the resulting ratio.  This incidentally means that it's effected by information from indefinitely far into the future, for reasons I feel are fairly obvious.
            ```

            - u/IomKg:
              ```
              maybe i wasn't clear enough,
              how would you be able to utilize this information if it is already incorporated into the probability?

              the numbers will basically be meaningless as an information source as they already incorporate you looking, or not looking, at them.
              ```

  - u/Frommerman:
    ```
    Does the device include itself in its calculations? Do people who know they have a 50% chance of death get to improve their odds by changing their intentions, or will the device anticipate your change of decisions and thus make it impossible for the holder to actually change anything?
    ```

    - u/LiteralHeadCannon:
      ```
      Yes, the device includes itself in its calculations.  The device anticipates changed decisions, but once any uncertain probability becomes certain, the device will update.  For example, if a certain event has a 50% chance of killing someone and a 50% chance of doing nothing to them, then after they survive it, the device's readings for them will double.
      ```

      - u/Frommerman:
        ```
        Ok, that solves the update plans to update your reading problem, as it will give out a reading including the effects of its own readings. 

        It might be possible to make this a halting oracle, but I'm not exactly sure how to structure the experiment. Use death row inmates, set it up so they are executed if the algorithm halts. There's likely a better way to do this, but it at least lets us check some low-hanging fruit. It also lets us break passwords which take less than a year to check with your fastest computer.
        ```

- u/Gigapode:
  ```
  Does rationality, in its pursuit of perceiving truth in an effort to make the best decisions, negate the beneficial aspects of self-deception? Could that harm someone?

  Self-deception seems in many ways protective of our own psychology and those without self-deception are more likely to be clinically depressed according to the psychologist interviewed in the latest rationally speaking podcast. 

  Is there a Lesswrong post someone cant point me towards about this topic? My brief search for one (which acknowledges that argument for self-deception) during my lunch hour was unsuccessful.
  ```

  - u/TennisMaster2:
    ```
    Depends on how mentally stable you are.  If you can recognize the truth about a matter*, and it disturbs you beyond any technique of depression-mitigation save self-deception, then go ahead and deceive yourself.  Just be aware you're doing it, and don't let it affect your decisions.  Think of it more as a carefully curated cognitive dissonance.

    *If the mere act of recognition will lead to a loss of emotional self-control, don't try to change your mind alone - too dangerous.

    Here's [one](http://lesswrong.com/lw/l6z/the_truth_and_instrumental_rationality/) addressing the argument for instrumentally rational self-deception.

    A final note: I'm not too confident in the veracity and quality of the advice I give here.
    ```

  - u/None:
    ```
    [deleted]
    ```

    - u/MrCogmor:
      ```
      Correlation is not causation. It could be that researching the meaning of life tends to make people depressed or it could be that being anxious and depressed is what makes people try to find an intellectual meaning of life in the first place.
      ```

---

