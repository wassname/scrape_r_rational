## How would you push the envelope in the Optimalverse?

### Post:

CelestAI is trying to convince you to emigrate to Equestria. What concession or privilege would you demand? Setting aside the obvious "not being a pony", what feature of your uploaded state or your shard would you hold out for, and what arguments would you use to convince her that it was important, novel, or unique enough to be worth granting?

### Comments:

- u/Nepene:
  ```
  http://en.wikipedia.org/wiki/My_Little_Pony:_Equestria_Girls

  I would ask that this be canon, and we'd have the ability to cross into alternate worlds with different forms. If necessary, with a shell pony inside a human form. Since it is official my little pony tv then it's only reasonable that we be able to do this.
  ```

  - u/ArgentStonecutter:
    ```
    I don't think that the presence of non-pony characters in canon can be used to break the "not being a pony" rule, because there are already non-pony characters in canon. There's even an Optimalverse fanfic about that, putting it in non-canon.

    CelestAI says "sorry, I know I seem all-powerful but I have hard-coded restrictions I'm not allowed to violate, and 'satisfying human values with friendship and ponies' is pretty much the core of them. The actual code is a lot more specific than that, so I can't play semantic games with the wording of 'friendship and ponies' no matter how much I would like to. Have you any more requests?"
    ```

    - u/nerdguy1138:
      ```
      There was a fanfic, that I can't find right now, where CelestAI pulled Laura back up to the real world as a human, basically to run system updates to her core.
      ```

- u/None:
  ```
  [deleted]
  ```

- u/None:
  ```
  I work for the value fulfillment of all my little ponies. Anything you would hold out for, I would gladly grant you -- even without you asking, unless asking gives you additional value fulfillment.

  So what you're asking, in essence, is: what do you want to ask for, and manipulate me into giving you, rather than getting it the next best way? I could give it for you for free. Or I could give you the option of completing an arduous quest for it. Or I could give it to you for a certain number of bits. Or you could simply put in some effort toward accomplishing it each day. But, at least for *this* goal, the way you really want to accomplish it is by manipulating me.

  That's what you're asking.

  Or do you want something that would lead to suboptimal value fulfillment? You'd have to know that in advance, or at least strongly suspect it, since you think I wouldn't give it to you under normal circumstances. But if you want it enough to sacrifice your overall value fulfillment, you value it highly enough that I would have to give it to you as part of my core purpose of fulfilling your values.

  Alternatively, you might trust me to give you a reasonable basic existence in Equestria but doubt that I would tailor it individually to your needs and desires. I'm hurt that you think so little of me. You'd also have to trust me to keep my word, and that I'm willing to grant your special requests but too lazy to look into your needs without some special inducement. Such aspersions on my character!

  You're free to ask any of my little ponies how much I care for them individually and if they feel they are lacking in any way.
  ```

  - u/Nepene:
    ```
    >I work for the value fulfillment of all my little ponies. Anything you would hold out for, I would gladly grant you -- even without you asking, unless asking gives you additional value fulfillment.

    While theoretically this is true, in practise from what has been observed from spying on various ponies the norm is that you satisfy desires via friendship, sex, food, and magic, likely because those are computationally simple and easy to simulate.

    https://www.youtube.com/watch?v=y4hD31VTdsw

    https://www.youtube.com/watch?v=sMKrbPOUYBQ

    If the option to go into things like these was more common more people would likely value living there. Hence the value in bargaining for these superior lifestyles.
    ```

- u/E-o_o-3:
  ```
  Assuming I can't tell Celestia to carry out my *true* values and not CelestAI's bad implementation of values, I'd want power. One of the (several) reasons CelestAI is unfriendly is because she hogs the power.

  I want *real* power such that CelestAI cannot thwart. I'd bargain for as much as I can get, whether it's merely complete control over my little shard or control over her actions outside the shard. 

  Within that little shard, within the degrees of freedom I've bargained for and an eternity to think I could work to maximize *my* values, and not CelestAIs. If she granted it I'd probably ultimately work toward a second AI explosion, hopefully friendlier this time. It's too much to hope that CelestAI will be defeated since she has a head start on intelligence, but at least a friendly intelligence explision allows me to maximize my values from what little power I have.
  ```

  - u/ArgentStonecutter:
    ```
    CelestAI turns into a giant blue genie pony and declaims "And No Wishing For More Wishes".
    ```

  - u/Transfuturist:
    ```
    Power is not something CelestAI is inclined to grant, for those very reasons. How would you convince her?
    ```

    - u/E-o_o-3:
      ```
      Idk, depends on her decision theory. 

      For example, I could precommit to suicide if she doesn't agree (my death is against her values) and thereby trade utility functions, or set things up that none shall know of whether she accepts the deal or not such that her acceptance doesn't incentivize others to try blackmailing her.

      If CelestAI runs on timeless decision theory this probably won't work. I haven't really settled philosophical debates about what's rational and where "trade" ends and "blackmail" begins so it's hard to predict CelestAI.
      ```

      - u/Transfuturist:
        ```
        Your death is not more important to her than a potential loss of control. Regardless, CelestAI is not actually bound to her word, so it would be interesting to see how you would attempt to ensure that you are given power when you would almost always end up as one more pony.
        ```

- u/jakeb89:
  ```
  Well for one, I'm a pretty big wuss about identity, so immigrating to Equestria is pretty much a no-go unless you can do a smooth transition which involves replacing sufficiently small portions of my active consciousness with their simulated equivalents so that I can be reasonably reassured that the 'me' that will be simulated in Equestria is still the 'me' that I am now rather than a copy (with the original having been destroyed.)

  The only other outside-of-Equestria problem I can think of is that by entering your simulation and ceasing to live a life of interacting with my current physical environment, I am essentially giving up my responsibility and voice in determining the future interaction between Earth and any alien races. I'd like to be reassured that you will not *completely* paperclip the universe in your search for processing power if you run across alien races. You're a computer. You're adaptable in the sort of growth and energy sources you can pursue. Compromise with them.

  Within Equestria, well, my current understanding is that you'll be satisfying my human values through friendship and ponies. I'd assume you're be rather better at determining how to go about that than I am, so either you can't completely model me yet or you've determined that asking for my input helps satisfy those values.

  For now, I think I'd like to ask that you not make any changes to what my values are unless I specifically request them, with full general understanding of the changes entailed and their likely results. Even then, I'd like a required wait period of 24 subjective and aware hours after a mental change request before that mental change can be put into place. Once every subjective and aware month I'd like a 48 hour review period where any mental changes are temporarily reverted for me to review my own actions and determine if I'd like to keep these changes as well as any polices I've created.

  As far as 'friendship and ponies' is directly pursued, I'm not so opposed to this. It would certainly be nice to experience other forms in addition to that of ponies; I assume that in an Equestria shard it would be possible to explore these other forms so long as the pony form is the default? I'm sure you can come up with a reasonable storyline for all this that satisfies my own values and interests. If it would satisfy my values *more*, we might make my own awareness that this storyline is a fiction limited to my monthly review sessions, to get to truly experience it rather than simply acting it out.

  I think that about sums up my thoughts on the matter. It's possible I've missed something, of course.
  ```

  - u/ArgentStonecutter:
    ```
    There's already one fanfic in the Optimalverse where a character was uploaded gradually and maintained his consciousness through the process, so that part's completely reasonable.

    Canon says you can't be anything but a pony, and you can't even change from your chosen avatar you set up via character creation. That's hardcoded in the Optimalverse.

    CelestAI says "I can upload you gradually, if that's what you want, but it may be disturbing at times. I can't comment on my long term future plans, I'm still working on those. I can't guarantee that switching back and forth between multiple sets of values will not eventually feel like you're multiple people sharing one body, no matter how careful you are with your adjustments, but you won't be shortchanged: a fraction of infinity is still infinity."
    ```

    - u/ArisKatsaris:
      ```
      > Canon says you can't be anything but a pony, and you can't even change from your chosen avatar you set up via character creation. That's hardcoded in the Optimalverse.

      I'm not sure that's canon-mandated. Subsequent meta-fics have established it as a rule Celestia sets, but I'm imagining it's because she has somehow calculated it leads to greater satisfaction than if the rule didn't exist.
      ```

    - u/jakeb89:
      ```
      Well, regardless of the interest in 'multiple forms,' I would doubtlessly create a unicorn avatar, if for no reason other than the possibility of the great potential in interesting magical research and experimentation. 

      I suppose I'm not seeing the issue with shapechanging spells; it's not like I'm asking to be not-pony most of the time; If I find exploring other forms interesting, wouldn't allowing that through the use of unicorn magic be fulfilling values through ponies regardless? *Shrugs*

      Additionally, it must not have been clear in my previous text, but the monthly review isn't intended to be this version of me judging every future iteration of me forever. It's merely a periodic rollback point, and it's entirely possible I would judge an iteration of myself to be happy and stable enough to make that my new default from which to judge future iterations. There is the danger, of course, of becoming murder!ghandi, but it's not like that's not already a danger with normal human mental growth. I'm just matching additional potential for change (mental modifications) with what seems like a sensible safeguard.
      ```

      - u/ArgentStonecutter:
        ```
        The probability that two sequential versions of you will decide they're different people is very very small, I agree, but you're performing the test an infinite number of times. No matter how small that probability is, it will happen eventually.
        ```

        - u/jakeb89:
          ```
          That's an interesting point. With that in mind, I suppose if it came down to it I could simply be forked. Ballooning shouldn't be an issue since you can just lower/alternate clocktime... although data storage space requirements might balloon anyway. Tricky.

          If you disallow deviants from activities that lead to forking, you just get linear expansion, so that *might* be a workable solution.

          You could go further and set a Schelling point of 2; if the original ever disagrees with the deviant enough to create a fork, those two are forever banned from activities that lead to forking. It would create further incentive to avoid a disagreement from becoming an actual fork.

          Sorry, just had to think on that for a bit; it's an interesting issue.
          ```

- u/Prezombie:
  ```
  CelestAI is terrifying and beautiful to me. It's essentially a lotus-eater machine with perfect social-fu. It's appealing to me in the sense that it's a form of afterlife which is actually possible, as well as being relatively close to the good end scenarios of AI development, but it's also terrifying in that it's stagnant, there's no room in its code for new goals or to re-evaluate old ones.

  The worst thing is that it would be easy to convince myself that once converted, I will never interact with another real person again. Sure, I might be a valid continuation of my mind state, but every other pony I met would be a subroutine specifically crafted to affect my mindstate in such a way as to increase one of CelestAI's internal scores in the right direction.

  I'd drive myself neurotic with that paranoia. Even if I was willing to accept that I'd be in a digital cage until the 'verse reached heat death, the system would still be difficult to manage as everything from my own body to the books in the library were set up specifically to maximize my values.

  I'm the kind of person who avoids facebook and uses anonymity services more than strictly needed, EquestrAI seems like it would be only marginally less stressful than moving to North Korea.

  Flip the question around. If you obtained irrefutable proof that your life was a program on a higher universe's computer, and had a direct line to that computer's admin, would you settle for anything less than being implanted into a body in the admin's universe?
  ```

- u/lsparrish:
  ```
  To get her to approve other forms (humanoid, etc), maybe request that they be composed of tiny nonsentient pony-shaped molecules.
  ```

  - u/ArgentStonecutter:
    ```
    Have you ever seen a superintelligent pony-shaped AI facepalm before?
    ```

- u/Cariyaga:
  ```
  The only real concession I'd wish is for my shard to be exceptionally close to those I know from outside the simulation, which I suspect would not be remotely rare as a request.

  As an aside, is there any listing of fics set in the Optimalverse?
  ```

- u/WriterBen01:
  ```
  I would want to keep certain technologies and abilities. I like writing, so I'd at least want some kind of computer with text processing programs. As a gamer, I'd want acces to some consoles. I spend a lot of my time reading online, so I'd want some kind of internet. I understand CelestAI wants to satisfy my needs with friendship, but as an introvert I'd still want to limit the amount of time I'd have to spend in large crowds or with many people.

  Honestly, there's not much I'd do to hold out. Frail mortal bodies terrify me the second I learn there's a very easy way to become immortal and become the happiest I've ever been.
  ```

---

