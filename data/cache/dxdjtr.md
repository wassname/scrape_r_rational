## As we speak, I'm fine-tuning GPT2 on Mother of Learning

### Post:

[Link to content](https://www.reddit.com/r/ArtificialCreativity/comments/dxdcio/as_we_speak_im_finetuning_gpt2_on_mother_of/)

### Comments:

- u/Xxzzeerrtt:
  ```
  Donâ€™t tease me by posting about MoL and it not being the final chapters
  ```

  - u/edwardkmett:
    ```
    Clearly step 2 is to use this model of GPT-2 with the penultimate chapters as a prompt to guess at the contents of the final chapters.
    ```

- u/-James-_:
  ```
  I just gave it the two word prompt 'Eliezer Yudkowski' and that worked out pretty well ðŸ˜†

  > "Eliezer Yudkowski  has just released a new blog post entitled  " The Power of Being Unreasonable ".  Yudkowski argues that the  power of reason  is not unlimited.  He asserts that it is a good to use it only in moderation. 
  The blog post follows his recent appearance on  Skeptoid .  It is a powerful statement of the limits to reason. Yudkowski asserts that we have an obligation to limit the use of reason to the bounds of human reason.
  I am not quite sure I believe Yudkowski.  I don't think reason is unlimited.  I do think reason is not a means to some kind of utopia.  I don't think reason is always good.  There are some things that reason can't or shouldn't do.  I think we need a good balance between reason and other things.  I don't think Yudkowski has given us an excellent balance."
  ```

- u/crivtox:
  ```
  Nice, I did the same whith 40milleniums of cultivation some months ago.
  And also whith marked for dead and the discord log. 
  Might try again whith the full model.
  ```

  - u/abcd_z:
    ```
    I think the last two models go out of memory. I haven't heard of anybody successfully fine-tuning them, at least.
    ```

- u/Makin-:
  ```
  The smallest model is pretty bad, I don't expect good results from this.
  ```

  - u/abcd_z:
    ```
    That's why I'm using it as a predictive keyboard, not a text generator.
    ```

---

