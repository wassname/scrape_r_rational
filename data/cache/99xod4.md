## [World-building] What cognitive biases would alien intelligences have?

### Post:

I've been thinking about alien intelligences, especially those with blue and orange moralities, and the sort of cognitive biases they might have. Especially those biases that humans wouldn't have. Mostly as just an idle musing, but I'd still like to throw the question out there. 

A few example "aliens":

  - Classical Fae, with their insanity to break contacts and inhuman goals.
  - Singletons, like those stories where a single cooperative intelligence evolves  in an ecosystem, instead of multiple competitive ones.
  - Collective Swarm Intelligence, like the zombies in a hero's war or any number of sci-fi robot swarms that get smarter as the swarm grows larger.
  - People living in the UNSONG world with it's weird causality.
  - Nature Spirits.

Thoughts?

### Comments:

- u/BuccaneerRex:
  ```
  It's best if it comes organically out of their evolutionary origins. A lot of human biases and instinct come from our social/tribal nature, ingroup/outgroup dynamics, and natural apophenia/pareidolia. 

  So if your aliens' ancestors were solo predatory hunters, for example, they might have a bias towards instinctive attacking of perceived weakness, or an over-inflated sense of their own correctness. 

  Herd ancestors might lead to instinctive group consensus, where regardless of the correctness of the argument, you can't convince one unless  you convince all.
  ```

  - u/Kachajal:
    ```
    +1. 

    Most of our biases are useful - in a caveman environment. They're only now harmful because our society advanced faster than we evolved. Many are vestigial heuristics.

    So the simplest way to imagine new ones is to create a relatively sudden change in the alien society, and see how tools that used to fit well are now sub-optimal or harmful.

    Considering the fae for a moment:

    - Perhaps they only recently (oh, a few millennia ago) encountered humans, and are still caught off-guard by their willingness to lie and break their word. Say this results in something like the planning fallacy that applies when considering what others will do. Maybe they're consciously aware of it, but it can sneak up on them.

    - Ruled by a Great Fae King for untold aeons, he has recently disappeared. They have since learned to cope, but a lack of initiative remains - they're more susceptible to suggestion than you might expect from a human. Something like an inverse bystander effect - they're *really* easy to command in groups, which has good and bad sides.

    I'm not feeling very creative at the moment, but I think I made the idea clear enough. Some aspect of the world used to be one way, and it's now different - but the aliens have not fully adapted to that change. Maybe it's resource scarcity (hi, obesity epidemic!), or a parasitic species turned symbiotic but still causes distaste... etc.
    ```

    - u/Geminii27:
      ```
      > they're more susceptible to suggestion than you might expect

      Especially from any being which tweaks their 'this one has power' senses. Act like a king, artificially exude an aura of power, and you'll have next to no opposition.
      ```

    - u/MuonManLaserJab:
      ```
      I don't like stories where intelligent aliens haven't figured out lying, unless they're a singleton. It's like an alien species using square wheels. It's such a basic strategy.
      ```

      - u/Kachajal:
        ```
        I think it's all in the execution. If it's part of their alienness, I don't really mind it. And the Fae are typically depicted as being bound to the truth by their very nature. Perhaps at some point in the past the race as a whole made a magical pact to enforce honesty?

        Also, the way I imagine it, it's not so much them not figuring out lying as having an unconscious bias to not take it into consideration. If you think about it, us humans being so horrible at predicting task completion time is absolutely ridiculous - it's not that difficult if you know how to - and yet we have that problem, as a species.
        ```

  - u/vakusdrake:
    ```
    >or an over-inflated sense of their own correctness.

    This seems like a terrible idea for a solitary animal, the whole point of narcissism/overconfidence is to convince other people you're right (a lot of self deception is designed to get you to believe your own lies so you'll be more convincing). If you aren't trying to fool anyone else then being overconfident only harms you.
    ```

    - u/BuccaneerRex:
      ```
      Eh, off the cuff. I was thinking of predator status fights. They're solitary, but they can't be permanently solitary. So they come together occasionally for mating and fighting. As they evolved, this became posturing and posing, which becomes superiority and inflated self-worth. Think that kind of domineering boss with the 'my way or the highway' attitude. As long as it's good enough, things will generally be ok.
      ```

      - u/vakusdrake:
        ```
        Sure they would be good at intimidation, but for a species where posturing is mostly about combat, being overconfident in your abilities is suicidal.
        ```

        - u/BuccaneerRex:
          ```
          I guess that's what makes it a bias then.
          ```

          - u/vakusdrake:
            ```
            Biases which are bad for one's ability to survive and reproduce aren't going evolve in the first place though.
            ```

            - u/BuccaneerRex:
              ```
              only if they lead to negative reproductive success. If they cause problems but not major ones, they will be conserved. Survival of the fit enough. 

              In this particular instance, the over confidence bias is part of the reproductive strategy. It only becomes problematic now that the species is sentient and more social than in their ancestral environment.

              Like young male humans doing stupid dominance and status games. Not really required to survive and reproduce, and still they head butt and leap off of garages onto backyard tables.
              ```

              - u/vakusdrake:
                ```
                Status posturing is one thing, but if you're a solitary species you'll want to be acutely aware of your actual abilities, because males in the sorts of species we're talking about adopt a different strategy if they can't do well in combat. Also importantly getting yourself killed or injured here is not an acceptable outcome because you'd always be better off cutting your losses at some point and either fighting competitors elsewhere or being sneaky.

                Basically the point I'm making is that actual real world animals like deer, elephant seals, etc know when to admit they've been beaten and try something else.
                ```

  - u/Russelsteapot42:
    ```
    Indeed. Spending a lot of time with a small flock of chickens has taught me that any creature with a social instinct and roughly similar biological needs (food, water, sleep, sex) will end up with very similar moral behaviors.
    ```

    - u/addmoreice:
      ```
      Which is why subverting or altering these needs results in some amazing alternate morality and points of view.

      The buggers in Enders game for example with their views on murdering scores of humans (no more amoral from their point of view then disarming an enemy).

      In another book (can't remember the title), the main aliens have had faster than light travel for generations, a part of their 'self' is stored in an organ which even after death can travel a specific distance in a sort of astral projection. FTL spaceships literally use ancestor relay to communicate. Every first contact they have ever experienced has consisted of the other aliens trying to murder them and their ancestors! (ie, radio communication being seen as an attack instead of communication).

      Just off the top of my head, some great alternate needs: 

      * Memory is stored in dna and can be consumed and exchanged relatively easily. Fights of dominance, child rearing, etc all result in sharing less or more of these memories...by eating the flesh of the other being. The conflicts this would cause at first contact are obvious.

      * An ecosystem where radiation is so high and so constant, but importantly something that slowly rose over the evolutionary history, that all life on this planet has multiple sexes beyond the two since it's needed for the redundant error correction. this results in more than just the 'fight and nurture' specialisations of our genders. You could have fight, feed/clean, educate, protect, etc etc splits and the social and political roles which develop from that.

      * Vastly split time scales for two species interacting. One species is essentially formed through the gestalt reaction of mosses and slimes and so focuses entirely on food gathering and harvesting, long term goals for this species might be converting dry plains into swamps. this would be seen as something they do for the their 'day' but the other species 'year'. Their sense of time is just so long that days are mostly ignored. the other species might experience something closer to our time sense, the conflict there is easy to see.

      in general, if you want a blue/orange morality instead of a white/black morality (as we know it), you *need* a significantly different biological/structural/social system with a bias towards the more fundamental structural changes (biological/life cycle) side.
      ```

  - u/Croktopus:
    ```
    >they might have a bias towards instinctive attacking of perceived weakness, or an over-inflated sense of their own correctness

    ok but what about ancestors that were solo predatory hunters? :P

    just cuz, i feel like these are biases that people tend to have already. so what would the solo thing look like. a tendency to look for ways to win through competition rather than cooperation? or even a bias against cooperation in general? inverse tribalness where you try to avoid people that look like you because they're mentally viewed as competition?
    ```

- u/PurposefulZephyr:
  ```
  I find swarms fascinating, so I'll dip my brain cells in this topic:

  * We become incomprehending towards bigger scales. Those swarms could have an opposite bias, focused on bigger quantities, while ignoring small numbers.

  * Swarm itself is all that matters, so individuals (even genius ones) are worth nothing compared to more computational power.

  * A natural tendency of sub-groups of the swarm to specialize. 

  * The more use there is to a skill, more protection/priority it's group will get.  
  A swarm that's constantly hunted will forget most things besides avoiding said hunts.

  * Since it gets smarter with size, it could automatically start doubting it's previous knowledge, even if it's based on solid data.  
  Same goes to opinions of other swarms, if they are smaller. Small is dumb, which could apply to humans as well- a big rally looks smarter than a lone professor. 

  * The size bias could lead to posturing. If a swarm feels threatened, it could spread out, to pretend it's bigger than it is.

  * IQ is useful in survival, so it will always strive to have more members, even when upkeep costs could start to be debilitating.

  * But increasing the number of moving parts increases the chance of it becoming mentally ill or outright broken (especially if new part is... contagiously persuasive). So probably a... safety-of-new-parts bias. It will be more, not less, reluctant to absorb different swarms or deviant individuals, even if they show promise.  
  So a massive swarm will be disgusted (to oppose any desire for closer integration) by encountering a sprawling human civilization.

  * Smaller swarms would seek independency, and in general be wary of bigger swarms (after all, once you get absorbed, it's game over for those genes).  
  Strains of the swarms that are comparable in size could band together regardless, especially if they feel threatened by a bigger competitor.  
  This situation, combined with a general fear of splitting up (since bigger numbers are a real strength), could lead to societies of different swarms. But that would probably come upon odd roadblocks soon enough, if not simply melding together.
  ```

  - u/abnotwhmoanny:
    ```
    Seems to me that a swarm species, after conquering it's natural predators and environment, would massively overpopulate. In a primitive environment, more is always better, because their environment would naturally trim their numbers. In the future, you would see repeating patterns of starvation and disease as their need to be more leads to them massively over exploiting their environment.
    ```

- u/eroticas:
  ```
  Look at common behavioral pathologies in the animal kingdom if you want it to be realistic.

  Whales breaching, birds plucking out all their feathers, dogs scratching way too much, birds feeding cuckoo chicks, insects laying their eggs on any shiny surface, ants getting trapped in spirals, insects flying incessantly towards the light.

  The interesting thing is that humans share some of these (e.g. picking at skin) but not others, so you get a smooth gradation from familiar biases to complex ones. And then there's some biases that you might imagine are near universal e.g  https://psychclassics.yorku.ca/Skinner/Pigeon/
  ```

- u/None:
  ```
  Aliens that have an evolutionary background as solo predatory hunters might have a strong bias towards respecting bigger, stronger people, to the point of instant deference. If two tigers fight in the wild, the bigger, stronger one often wins; for a sentient species evolving from such a situation, unused to doing things like working in groups to take out otherwise un-killable opponents, the idea of doing anything but flee in the face of a stronger opponent might provoke instinctive, crippling fear, and the idea of trying to outsmart or gang up on them might not be obvious. 

  Or interestingly, you could have a situation where a sentient species evolved intelligence, while still being preyed upon by a similarly smart predator that was specialized in hunting them. A cat and mouse situation, only both the cat and the mice are sentient. This could result in a species whose Us vs. Them instinct is always stuck on maximum, the out-group always completely de-humanised. It wouldn't matter to a Mouse species if humans were sentient or not; the Cats were sentient as well and they still killed the mice in droves. The idea of things like the Holocaust or slavery being bad would take a long time for the Mice to understand, as they would have literally started off in what was essentially a war of eradication; their culture would have begun with the genocide of the Cats. Tribalism, to them, would be the only true philosophy.

   Or you could have the Cats be the winners of the conflict, and have an even more interesting situation; humans encountering a species whose survival was literally based upon their ability to de-humanise other sentient beings, with massive cognitive bias surrounding any activity that requires working with an out-group, or cross-species empathy. They would have an incredibly hard time understanding the concept of pets, and, again, wouldn't understand why things like slavery or the holocaust was wrong, as they would have evolved in a situation where exploiting and murdering other sentient beings was their main cultural norm.
  ```

  - u/Ascendant_Mind_01:
    ```
    I wonder what would happen if both sentient species were still extant?
    ```

    - u/None:
      ```
      It could make for an interesting story. You could have a Star Fleet style united humanity, deep believers in diplomacy and mutual understanding as the foundation of the future, walking into a war they can't resolve by being peace brokers. A situation where an eternal war would not be founded one some kind of misunderstanding, or divergent political beliefs, but on biological realities that would be much harder to untangle.

      Both species would be intelligent, but showcasing the differences in their intelligence could be interesting. Predators are usually smarter than their prey. Finding ways for the mice to survive, despite being preyed upon by their equivalent of giant geniuses, could be an awesome exercise for some rational writing.
      ```

- u/OnlyEvonix:
  ```
  As an inverse to humans who tend towards shortsightedness and immediate causes and effects a mind that's a long term thinker by nature (like a sapient tree or hive manager or something) might do poorly in an emergency and pass up a direct, simple, inefficient but near certain stratagy for a long term stratagy that'll reduce the chance of it happening again by do little to help with this emergency in particular.
  ```

- u/serge_cell:
  ```
  Modern branches of science, where single person can not encompass most of scientific knowledge of the branch is classical swarm intelligence. Latency is high and instead of neurotransmission transactions whole papers are send between elements, but still the system is at least order of magnitude more intelligent then single scientist. 
  What kind of cognitive bios modern branches of science have? Very weak if not take into account less-developed branches like medicine and pseudo-sciences like psychology(no offence, but psychology don't use scientific method much) We can make educated guess that for powerful intelligence (> 10*human) cognitive bias is not significant.
  ```

- u/ddejong42:
  ```
  Here's a thought - take your typical skin color bias, but with a species that can see further into the infrared or ultraviolet range than we can.  Two individuals might appear to have identical color to us, but to others of their species one is "obviously better".
  ```

  - u/eroticas:
    ```
    Rational!The Sneetches
    ```

    - u/EliezerYudkowsky:
      ```
      Idempotent operation, result is The Sneetches.
      ```

- u/SimoneNonvelodico:
  ```
  For singletons, I guess they'd probably not have a habit of dealing with other minds. So they'd probably have some kind of "inanimate bias", where they tend to underestimate the amount of complexity that can be introduced by intelligent agents in a system, and think even of artificial stuff like it's just some sort of rule of nature - the opposite of our tendency to anthropomorphize everything, basically.
  ```

---

