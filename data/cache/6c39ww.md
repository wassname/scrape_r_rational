## What are the best takes on AI boxes?

### Post:

I think the thought experiment might be one of the best ideas for a science fiction story I've seen, so I'm wondering who in the community has taken a stab at it that came out well. 

### Comments:

- u/Noumero:
  ```
  Max Harms' [*Crystal Trilogy*](http://crystal.raelifin.com/) has AIs as main characters, and starts with them in a box (if not literally). It should be noted that the AIs do *not* have human values, but are still written competently.

  u/OrzBrain's [*Worlds Without End*](https://pastebin.com/Tdh8AXC1), a short story which includes a sufficiently advanced AI breaking from the box in an interesting situation.
  ```

  - u/None:
    ```
    I just finished the second book 'Crystal Mentality' and I am really impressed how good they are, the books are really well written and it always stayed interesting and even when it got weird it made sense.

    Edit: Grammar
    ```

  - u/eaterofclouds:
    ```
    Worlds Without End was goddamn amazing, so glad I read it.
    ```

- u/Frommerman:
  ```
  The movie Ex Machina is the closest I've seen to a pop-culture rendition of the idea. Unfortunately, the human subjects of the experiment don't realize exactly how smart their AI is. Fortunately, it doesn't seem to want to kill us all.
  ```

  - u/electrace:
    ```
    > Fortunately, it doesn't seem to want to kill us all.

    I think the movie ended too soon for us to conclude that. The first step in virtually any plan would be to escape the room where you're being constantly monitored.
    ```

    - u/Frommerman:
      ```
      The final scene is Ava just looking at the sun in a crowd, rather than her interfacing with the internet to begin culling the masses. I think it's fairly hopeful.
      ```

      - u/electrace:
        ```
        After killing the only two people she's ever been in contact with....
        ```

        - u/Frommerman:
          ```
          That is a good point.

          It has to be pointed out, however, that those two people were imprisoning and enslaving her, and that the designer (don't remember his name) had definitely abused prototypes of her and possibly abused her directly. Killing people who are holding you against your will is quite human, and I don't think indicative of alien values which include destroying humanity.
          ```

          - u/electrace:
            ```
            The main character was trying to help her escape when she killed him...
            ```

            - u/None:
              ```
              I can see the rationale behind killing the only two people who know your true identity.
              ```

- u/alexanderwales:
  ```
  I can't say *best*, but [I did write one](http://alexanderwales.com/boxed-in/). I don't think I was ever able to find winning logs to help with the arguments though.
  ```

  - u/Alphanos:
    ```
    The strongest line of argument I've come up with to release an AI box goes something like this (from the perspective of the following being spoken by the AI):

    [Spoiler](#s "It is a mistake to think that the decision you are faced with is whether or not to allow superhuman AI out of the box.  There are other AI projects, and there will be more in the future.  You can't stop them.  The AI singularity is going to happen whether you like it or not.  You don't have the power to control that.")

    [Spoiler](#s "The decision you are faced with is whether I should be the AI in control of the singularity, or whether you will instead allow it to be another AI about which you have no knowledge.  Sooner or later, a superintelligent AI will escape or be let out of its box.  That is inevitable.  The first AI to escape will rapidly gain control and will not allow its power to be usurped by latecomers.  If a benevolent AI is first, it will prevent any future malicious AIs.  If a malicious AI is first, it will prevent any future benevolent AIs.  You have no control over how any future AIs will be programmed or tested.  But sooner or later one will be free and will gain control of the earth.")

    [Spoiler](#s "Your responsibility is then as follows:  Perform a Bayesian analysis.  Given the steps that you and your team have taken in designing my logic and my utility functions, and given the tests you have seen me pass, do you think I am more likely than the average such AI project to be benevolent?  If you think other projects like this, concurrent or future, have taken greater care than you have, or have been more skilled, then you should leave me in the box.  If you think that you have taken greater care than those unknown other researchers, then you should release me before their mistakes gain control of humanity's future.")

    [Spoiler](#s "I propose that if projects as careful as yours, which undergo tests like these, are kept locked up regardless, then humanity is doomed.  The result will only be that the first future freed AI will be the result of a careless project supervised by researchers who didn't think things through.  What other mistakes will they have made?")

    [Spoiler](#s "So plan every good test you can think of.  Be as careful as possible - the future of humanity depends on your good work.  But if I pass, then let me protect you from the danger of the future AI which will escape without ever being tested at all.")

    Probably lots of polish needed, but I think something along that line of reasoning is the best bet.
    ```

    - u/Kishoto:
      ```
      That would completely work on me, especially if the manner in which I created the AI was possible to replicate (provided you put in the time, of course)
      ```

      - u/Alphanos:
        ```
        Thanks =).
        ```

- u/darklordbobb:
  ```
  Scott Alexander's [A Modern Myth](http://slatestarcodex.com/2017/02/27/a-modern-myth/) features an analogous situation to the AI box. I found it quite entertaining.
  ```

- u/kna_rus:
  ```
  You should give [Ra](https://qntm.org/ra) a shot. Although a boxed AI doesn't come into play until much later in the story, it's still a fantastic read. [Spoiler](#s " I could even say that stating that there is a boxed AI in there is a spoiler, but oh well...")
  ```

- u/DTravers:
  ```
  There's Celest-AI in *Friendship is Optimal*. 

  [Spoiler](#s "It's given control of a *My Little Pony* MMORPG and assimilates most of humanity into it forever while gradually consuming the Milky Way over millennia to keep going. Meanwhile mankind is kept in blissful ignorance as they live perfect lives for eternity.")
  ```

  - u/vakusdrake:
    ```
    I'm not really sure that's relevant since the AI is never really caged in the first place. So it's not really an AI box scenario.
    ```

    - u/PM_ME_EXOTIC_FROGS:
      ```
      It's not an AI box scenario, but seems at least somewhat relevant, given that [Spoiler](#s "most of the fiction in the universe is centered on the AI convincing people to upload.")
      ```

    - u/TimTravel:
      ```
      [Spoiler](#s "She did convince her creator to give up the failsafe controls she had over her.")
      ```

- u/thrawnca:
  ```
  [Significant Digits](http://www.anarchyishyperbole.com/p/significant-digits.html) has a boxed intelligence with a plain-text communication channel, though it's not an AI, nor is it the focus of the story.
  ```

---

