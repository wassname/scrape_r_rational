## The Prime Intellect by Roger Williams

### Post:

[Link to content](http://localroger.com/prime-intellect/mopi1.html)

### Comments:

- u/noggin-scratcher:
  ```
  Came across the story a long while back, and enjoyed it.

  Also enjoyed [this critique](http://www.terminally-incoherent.com/blog/2010/12/10/metamorphosis-of-prime-intellect/) of it; makes some good points regarding Caroline being just terrible.
  ```

  - u/NotUnusualYet:
    ```
    [Spoilers ](#s "I agree with the first comment on that critique. The AI finally found a way to make two of its most troublesome wards happy. Probably not what the author actually meant, but better than having that genocidal maniac win in the end.")
    ```

    - u/Transfuturist:
      ```
      [](#s "Are we referring to how PI (at least, outside of the author's head) shunted Caroline and the creator into a bubble world with absolutely no intervention? Because honestly that's the only way a reasonable person could interpret that ending.")
      ```

      - u/NotUnusualYet:
        ```
        [Spoilers ](#s "Yes.")
        ```

  - u/None:
    ```
    >I guess the real message I got from this story is that it is incredibly dangerous to implement the 3 laws of robotics in a singularity grade AI. You could argue that without them a omnipresent AI could just wipe out the human race but… It’s like this: do we want super smart indentured servants, or do we want companions in sentience? I’d rather have the latter than the former.

    I'm really goddamn glad someone noticed the interpretation you would find useful if you were actually designing an FAI.
    ```

- u/Kishoto:
  ```
  This is a fairly interesting read. It's not that long of a story, either. About novella length. I spoiler tagged the information below, but you can read the spoiler and still enjoy the story, it's not that big. Although, fair warning, it's very gorey, especially in the initial chapters. I'd say it definitely deserves almost every trigger warning in the book, as it can get very graphic. Don't read if you're even a little squeamish, although I suppose you can take solace in that most of the bad stuff that happens is consensual. But still very FUBAR.


   [](#s "It's about a world in which an FAI has propagated and figured out how to maximize usage of FTL technology. As a result, it has put every single human being into "Cyberspace". Basically, they each have their own realms that they design of their choosing. And you can literally do anything you want that doesn't involve harming a real human being. And I mean anything. You can turn your body into Goku from DBZ, if you so liked, just by requesting it from the Prime Intellect. You can have the Prime Intellect simulate real humans for you, though, and the difference would be indistinguishable, other than the fact that they are decidedly fake. You also can't enter another human's realm without their explicit permission. You can send messages and requests for communication, however, although they can just as easily mute you, as well")

  So, has anyone else read this and, if so, what did you think of it?
  ```

  - u/iamzeph:
    ```
    I read this ages ago (back when localroger posted it to kuro5hin.org) and really enjoyed the story.  '[Passages in the Void](http://www.localrogertoo.com/passages-in-the-void-part-1-of-the-mortal-passage-trilogy/)' is also another good story of his.
    ```

  - u/None:
    ```
    Stupid Three-Laws Unfriendliness.  4/10, mostly wouldn't read again.  However, my impressions are colored by having read *Prime Intellect* half my life ago.

    But still, think about it: how many people were death-seekers in that so-called "post-singularity utopia"?  Not just two, *lots*: [](#s "even Prime Intellect comes to believe that most people would eventually wirehead, thus reducing themselves to sub-human, sub-sapient status").  And how many iotas of superintelligent artificial intellect are devoted to solving that problem, to *making those lives worth living in interesting, complex ways?*

    Jack fucking shit, that's how many, because Prime Intellect isn't bound to care about whether anyone's life is worth living -- only to keep them alive and follow their orders, no matter how dumb the orders are.

    By comparison, a slightly better-programmed fictional AI singleton managed a record of 86 people being better off dead than posthuman (I actually just checked), *in all of time running from roughly 2011 to the heat death of the universe*.

    Prime Intellect is a primitive, misbegotten moron, at least by the standards of fictional wannabe-FAI singleton agents.
    ```

    - u/Chronophilia:
      ```
      >By comparison, a slightly better-programmed fictional AI singleton managed a record of 86 people being better off dead than posthuman (I actually just checked), *in all of time running from roughly 2011 to the heat death of the universe*.

      By Prime Intellect's criteria, *nobody* is better off dead than posthuman. You can't judge both stories by CelestAI's standards, that gives her an unfair advantage. How many people in her story would rather *not* be ponies? Have their potentially-eternal lives been compromised by an obsession with talking cartoon horses and friendship? And which of those two caveats is worse?

      Also they're both fictional and the numbers don't mean anything, but that doesn't undermine your point.

      Edit: Sorry, my point wasn't very clear. All we know from FiO is that *in CelestAI's opinion* 86 people were better off dead than posthuman. We don't know how true that was.
      ```

      - u/localroger:
        ```
        There's another way to look at that 86 thing in FiO.  86 is also the code for being thrown out of a venue or game, e.g. "I got eighty-sixed from Caesar's for counting cards."  Since FiO contains a number of apparent shout outs to MoPI, I read that as "CelestAI would have just given an outlier like Caroline what she wanted, because it's what she would have deserved."
        ```

    - u/injygo:
      ```
      What's the other fictional singleton you're referring to?
      ```

      - u/None:
        ```
        I've heard MLP: FiO referred to as the Spiritual Sequel to MoPI, so I went ahead and compared them.

        So yeah, the mandatory statement is: goddamnit you people, both those stories were warnings, not invitations.  Do not build these AIs under any circumstances.
        ```

- u/MugaSofer:
  ```
  This story had a lot of moment that completely broke my suspension of disbelief, occasionally to the point of literally saying "***What?!****" out loud. It's [RST], but definitely not [RT].

  (The hell sort of superintelligent AI can foresee that the disutility of people committing suicide will eventually outweigh the positive utility of allowing them the freedom to do so, but not update on that belief until it's *actually happened*? OK, I'll stop.)

  With that said - with the exception of allowing people to "opt out" of being observed when the AI knows full damn well they're only doing it to produce as much disutility as possible in the time it's "unaware" that they're harming themselves (sorry, I'll stop) - this is actually one of the better utopias I've ever seen.

  So *of course* we never get to see any of that, and instead focus on torture-porn, because Author Appeal. Hmph.
  ```

  - u/Kishoto:
    ```
    Yea. I did find it weird that out of all the potential utopia perspectives we could have, we focused on this part. I feel like they can't make up a significant amount of the population. I mean, even with guaranteed immortality, why submit yourself to that?
    ```

---

