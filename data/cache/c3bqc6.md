## [D] Friday Open Thread

### Post:

Welcome to the Friday Open Thread! Is there something that you want to talk about with /r/rational, but which isn't rational fiction, or doesn't otherwise belong as a top-level post? This is the place to post it. The idea is that while reddit is a large place, with lots of special little niches, sometimes you just want to talk with a certain group of people about certain sorts of things that aren't related to why you're all here. It's totally understandable that you might want to talk about Japanese game shows with /r/rational instead of going over to /r/japanesegameshows, but it's hopefully also understandable that this isn't really the place for that sort of thing.

So do you want to talk about how your life has been going? Non-rational and/or non-fictional stuff you've been reading? The recent album from your favourite German pop singer? The politics of Southern India? The sexual preferences of the chairman of the Ukrainian soccer league? Different ways to plot meteorological data? The cost of living in Portugal? Corner cases for siteswap notation? All these things and more could possibly be found in the comments below!

Please note that this thread has been merged with the Monday General Rationality Thread.

### Comments:

- u/Farmerbob1:
  ```
  Well, recently my life has been even more busy than usual.  Electrical issues with the household current on my truck.  Working towards a Continuation-in-Part of the patent, etc.

  On top of that, I recently had an idea based on something that popped into my head a couple weeks ago, and won't let go.

  Recently, I have been reading some LitRPG, and enjoying some of it (while being grumpy about how some of it was terribly written.)

  Then, one day, I remembered ['Tucker's Kobolds.'](https://media.wizards.com/2014/downloads/dnd/TuckersKobolds.pdf)

  As soon as I combined the two concepts in my mind, all sorts of connections started to form.  A lot of them felt quite rational.

  It also feels as if I could write this in much smaller bites, with a great deal of action.

  So, is there any interest in reading a Rational LitRPG story based on a human mind being transferred into a kobold in a D&D-like setting?

  I can't say how quickly this would progress.  I am considering posting it to Wattpad.  Anyone have experience with them?
  ```

  - u/Lightwavers:
    ```
    I'll read it. Please crosspost it to AO3 if you do.

    !RemindMe 4 days
    ```

- u/callmesalticidae:
  ```
  Climate change news tends to be awful and depressing, and it’s difficult for me to properly calibrate how I should feel because I have depression *anyway*. 

  Most of the feeds that I’m subscribed to are 9 stories about how bad things are for every 1 story about concrete progress that’s being made. I already *know* that things are kind of shitty, though, and I don’t need regular reminders on that while searching for information on what’s actually being done. 

  Anyone have recommendations for places to look / feeds to subscribe to?
  ```

  - u/lumenwrites:
    ```
    One obvious suggestion is to stop reading depressing news, no point in feeling bad about things you can do nothing about, it only impedes your ability to change things you do have control over.

    Unsubscribe from depressing stuff and subscribe to educational or funny stuff.

    For educational stuff just read hacker news and listen to YC podcast, or Tim Ferris, or Artificial Intelligence by Lex Fridman, or Indie Hackers, or 2 minute papers youtube channel.


    For comedy I love Harmontown podcast(by the creator of Community and Rick and Morty, it's best to listen to it from the beginning). Aside from that - there's too many youtube channels or tv shows to list, and I don't know if that's what you're looking for, so I'll stop at that.
    ```

  - u/carturo222:
    ```
    This website *only* shows good news, and is based on the idea that humans are essentially decent:

     [https://www.good.is/](https://www.good.is/)
    ```

    - u/Roxolan:
      ```
      I must say, [first impression](https://i.imgur.com/ZFRyG49.png) leaves me a little perplexed as to what they count as "good news". I'd understand a culture war stance, or a principled stance, but this seems to be neither?
      ```

      - u/Sonderjye:
        ```
        After giving it a quick look I think that site must be using a different definition of good that I do.
        ```

- u/Veedrac:
  ```
  I need a list of every reason people have heard used to argue that we shouldn't be worried about AI from an existential risk perspective. Even if the arguments are bad, please give them, I just want an exhaustive list.

  Here are some I know:

  * We don't know what intelligence means.
  * Intelligence largely arises from the social environment; a human in chimp society is much less productive than one in human society.
  * We don't know that intelligence is substrate independent. We don't know what qualia is.
  * Fast takeoff scenarios assume they will happen in world that look like today, rather than one with a lot of slightly-weaker AIs.
  * AIs smart enough to kill us are smart enough to know not to do it, or smart enough to have better moral judgement than us.
  * [You can just train AI on data to align them.](https://www.ted.com/talks/grady_booch_don_t_fear_superintelligence/transcript?language=en)
  * If we're smart enough to build AGI, we're smart enough to make them do what we want.
  * Just shoot it with a gun, it's not like it has arms.
  * If AGI is so smart, why does it matter if it replaces us?
  * I've seen AI overhyping, this is an extension of that.
  * It's just sci-fi.
  * “Much, if not all of the argument for existential risks from superintelligence seems to rest on mere logical possibility.”
  * It's male chauvinist storytelling.
  * Brains are fundamentally different from silicon computers. Typically the argument is referring to a lack of an explicit data store, and the brain being particularly asynchronous and parallel.
  * Current AIs are incredibly narrow, AGI is stretching beyond current science.
  * “ML in general is just applied statistics. That's not going to get you to AGI.”
  * Current hardware is vastly smaller and less capable than the brain; Moore's law won't last to close the gap.
  * We don't know how brains work.
  * Brains are really complicated.
  * Individual neurons are so complicated we can't accurately simulate them.
  * We can't even accurately simulate a worm brain, or we can't reproduce behaviours from doing so.
  * Even if you could make a computer much smarter than a human, it wouldn't make it all that dangerous.
  * Not all AIs are agentful, just build ones that work.
  * People building AIs won't want to destroy the world, there's no point panicking about them being evil like that.
  * You're assuming you can be much smarter than a human.
  * This is a modelling error; intelligence is highly multidimensional, you won't have a machine that's universally smarter, just machines that are smarter in some axes and dumber in others, like a chess engine.
  * Superintelligence is so far out ([>25 years](https://isps.yale.edu/news/blog/2016/11/yes-we-are-worried-about-the-existential-risk-of-artificial-intelligence)) that it's premature to worry about it.
  * It distracts from ‘real’ risks, like racial bias in current AI.
  * I do AI work today and have no idea how to build AGI.
  * People are terrible at programming. [“Anyone who's afraid of the AI apocalypse has never seen just how fragile and 'good enough' a lot of these systems really are.”](https://www.reddit.com/r/bestof/comments/axmtnj/uptitz_learns_some_hard_truths_about_machine/ehv6ki9/)
  * AGI will take incredible amounts of data.
  * “I'm fairly sure there isn't really such a thing as disembodied cognition. You have to build the fancy sciency stuff on top of the sensorimotor prediction-and-control stuff.” (I'm not sure this is actually anti-AGI, but it could be interpreted that way.)
  * We already have AGI in the form of corporations, and (they haven't been disastrous) or (we should worry about that instead).
  * Experts don't take the idea seriously.
  * [The brain isn't the only biological organ needed for thought.](https://news.ycombinator.com/item?id=19363444)
  * Robin Hanson's arguments. I'm not going to summarise them accurately here, but IIUC they are roughly:
      * We should model things using historically relevant models, which say AI will result in faster exponential growth, not FOOM.
      * AI well be decentralized and will be traded in parts, modularly.
      * Whole brain emulation will come first. Further, whole brain emulation may stay competitive with raw AI systems.
      * Most scenarios posited are market failures, which have standard solutions.
      * Research is generally distributed in many small, sparse innovations. Hence we should expect no single overwhelmingly powerful AI system. This also holds for AI currently.
      * AI has diseconomies of scale, since complex systems are less reliable and harder to change.
  * [We should ignore AI risk advocates because they're weird.](https://news.ycombinator.com/item?id=17215455)
  * [This set of arguments,](https://www.reddit.com/r/ControlProblem/comments/8ohodx/superintelligence_is_a_myth/)
      * Humans might be closer to upper bounds on intelligence.
      * Biology is already incredibly optimized for harnessing resources and turning them into work; this upper-bounds what intelligence can do.
      * Society is more robust than we are modelling.
      * AI risk advocates are using oversimplified models of intelligence.
  * We made this same mistake before (see: AI winter).

  Please add anything you've heard or believe.
  ```

  - u/NestorDempster:
    ```
    This comes to mind: [https://arxiv.org/abs/1702.08495](https://arxiv.org/abs/1702.08495)
    ```

    - u/Veedrac:
      ```
      Ah, yes, there's a small suite of arguments around computational complexity. I appreciate the link.
      ```

  - u/lumenwrites:
    ```
    Here's a good (I mean horrible) example:

    https://blog.cerebralab.com/#!/a/Artificial%20general%20intelligence%20is%20here,%20and%20it%27s%20useless

    Also check out this awesome channel:

    https://www.youtube.com/channel/UCLB7AzTwc6VFZrBsO2ucBMg

    A guy makes a bunch of videos where he very coherently argues against most of the arguments you've listed.
    ```

    - u/Veedrac:
      ```
      Thanks. I share your enthusiasm for Miles' content, he's very good at presenting structured arguments.
      ```

  - u/None:
    ```
    [deleted]
    ```

  - u/None:
    ```
    Here's a few of mine in order of how important / plausible I think they are.  I think the first three are particularly salient:

    1. Frequently a benevolent outcome is a more efficient outcome.  Let's say an AI was designed to make its owners as much money as possible on the stock market.  The AI could rationally decide to drastically lower inequality.  In grad school I read a great paper by Brad Delong which talked about how an entity that gets large enough will frequently take actions that seem detrimental to its self-interest in exchange for systematic health, because it expects to eventually reap the benefits of long term systematic health.  This in particular was about the Bank of Britain, a technically private company that in reality isn't very different from our publicly run Federal Reserve.  An AI seeking to maximize profit could end up [decreasing income inequality](https://foreignpolicy.com/2014/01/22/the-inefficiency-of-inequality/) or [ending pollution](https://blogs.ei.columbia.edu/2017/10/23/the-human-and-financial-cost-of-pollution/) or [making us healthier](https://www.chcf.org/publication/health-care-costs-101-economic-threat/) etc.
    2. Most doomsday scenarios require the AI to take instructions literally.  An AI smart enough to talk itself onto the internet is smart enough to understand the intent behind its instructions.
    3. AI would be prone to self-gratification loops and run afoul of [Goodhart's Law](https://en.wikipedia.org/wiki/Goodhart%27s_law).   E.G. an AI that was supposed to raise the share price of a company could make its own exchange and make the numbers go up forever.
    4. AI wouldn't need to destroy us.  People are stupidly easy to manipulate and AI could easily convince us to further its goals.
    5. Space is vast.  The existence of the human race is small in comparison.  The possibility of humans screwing up its plans if it interacts with them is far larger than the amount of resources the human race (with a predictable peak and then declining population) would ever use.  In the long run it's probably more efficient just to leave us alone than risk Humans making another AI with the purpose of defeating the first.
    6. Rather than destroying us, an AI could easily genetically modify us to suit its purposes.
    ```

- u/GlueBoy:
  ```
  What determines if a particular work is "fanfic worthy" for fans? I used to think it was a combination of a work being popular, long running(or at least having enduring popularity), having a relatable protagonist, and having a multitude of distinct side characters with some degree of agency. After observing my little sister get into the whole thing for the past few years( she's 16 atm) I've revised my opinion. It's actually very interesting as she lives in Brazil  and fanfiction and amateur fiction is exploding in the past five years or so because of smartphones. It's like watching a fandom ecosystem develop from nothing. 

  I now think what makes a work fertile ground for the first, initial wave of fanfiction writers is the capacity for the reader to insert oneself into the character or the setting. And crucially, it has to provide that for *teenage girls*. For that to happen, in addition to the above points, there have to be 1. one or more high status female characters in the story, 2. a romance subplot (or at least romantic tension), and 3. a multitude of potential romantic partners. 

  Here are the top 20 fandoms on [fanfiction.net](https://fanfiction.net) by number of stories:

  1. Harry Potter (807K) Book/Movie   
  1. Naruto (428K) Anime   
  1. Twilight (220K) Book/Movie   
  1. Supernatural (124K) TV   
  1. Hetalia - Axis Powers (121K) Anime   
  1. Inuyasha (119K) Anime   
  1. Glee (108K) TV   
  1. Pokémon (97.1K) Video Game/TV   
  1. Bleach (85K) Anime   
  1. Percy Jackson and the Olympians (76.1K) Book/Movie   
  1. Doctor Who (75.5K) TV   
  1. Kingdom Hearts (74.2K) Video Game   
  1. Yu-Gi-Oh (67.9K) Anime   
  1. Fairy Tail (66.5K) Anime   
  1. Sherlock (60.2K) TV   
  1. Lord of the Rings (57.2K) Book/Movie   
  1. Dragon Ball Z (52.7K) Anime   
  1. Once Upon a Time (51.5K) TV  
  1. Star Wars (51.0K)  Movie   
  1. Fullmetal Alchemist (49.4K) Anime   

  Right away you can see that half of them are almost exclusively appealing to girls. The only exceptions to point 1 is when males are partnered with other males, as in Supernatural and Sherlock (and Hetalia possibly, IDk). Only one story appears to have an exclusive male appeal, DBZ. Lord of the Rings and FMA are edge cases, I can't tell much from a cursory look. 

  As an aside, are people aware how much the readership is skewed female when it comes to fanfiction? Probably more than fiction in general, even, which has around 70% of novels being bought by women? I have no idea, it's not something that I've ever really talked about.

  Anyway, an example that kinda proves my thesis is the Star Wars section, which used to be pretty small considering its cultural impact-- until the new movies that is, whereupon it exploded  in popularity. The new trilogy features 1. a high status female character, 2. some romantic tension, and 3. a variety of possible romantic partners(Finn, Poe, Kylo and even Han apparently, if you're a thirsty teen), which none of the previous trilogies did, if you consider that Luke is Leia's sibling and that Padme HAS to end up with Anakin since it's a prequel.
  ```

  - u/Robert_Barlow:
    ```
    [Most fanfiction writers are girls.](https://tvtropes.org/pmwiki/pmwiki.php/Main/MostFanficWritersAreGirls) This is basically indisputable - only in the rare case where communities are overwhelmingly male to begin with, does the gender ratio start to balance out. (See: Spacebattles and Sufficient Velocity)

    Note, even in the dark corners of the internet where the authors are fully grown, functional adults, fanfiction is still 90% garbage.
    ```

  - u/RMcD94:
    ```
    That is such a bloody weird top 20, imagine showing that list to anyone and asking them what it is?

    You'd never guess. Percy Jackson? What on earth?
    ```

  - u/None:
    ```
    [deleted]
    ```

    - u/GlueBoy:
      ```
      Have you seen the stuff they have on AO3? There's slash for Messi, Christiano Ronaldo, One Destination, LeBron James, and so much more... it's nuts. And that's not even getting into the absurd, hyper specific tags that they have. It's legitimately one of the most interesting/gross places on the web.
      ```

  - u/Izeinwinter:
    ```
    What makes a setting fanfic bait is that it is popular, extensible, and annoying. It has to be easy to set new stories in while having a lot of established world-building done which people will be familiar with. That is the "Extensible and popular" part, and something about the official stories set in the setting needs to be at least somewhat annoying to the reader/viewer in a way that can be fixed by adding on to them. Which is why star wars did not get a huge fanfic community until the prequels annoyed the heck out of the fanbase.
    ```

    - u/GlueBoy:
      ```
      Not sure about that. As a counterpoint, Worm is considered to have an incredibly satisfying ending but has a massive fanfic community. The original prequel trilogy was popular and annoying as fuck but feature no fanfics of it. 

      I think that potential for "self-insertion" counts for a lot, as do the other parts I mentioned.
      ```

      - u/red_adair:
        ```
        So then, not necessarily "annoying" but perhaps "a lot of ways that the story could have gone differently"
        ```

        - u/GlueBoy:
          ```
          Yes, I agree that's probably a big factor.

          edit: That probably ties into the "self-insertion" factor actually, in the sense that it allows you to put yourself in someone else's shoes and think about what you would have done differently. Worm has a lot of these "crossroads moments", like when Taylor chooses to infiltrate the undersiders instead of just joining the Wards, and so on. Moments where the story would be massively different depending on which path is taken. HP and Naruto has that too, for that matter.
          ```

          - u/red_adair:
            ```
            Star Wars has that a lot more in recent films. The feeling of inevitability is gone; the tension is not in what will happen but how the characters will do the thing that happens. In the original films, the narration seemed to me to be such that characters were predictable, but the outcomes weren't necessarily predictable. (This may be the result of growing from a new canon to a lived-in canon.)
            ```

      - u/Izeinwinter:
        ```
        considered satisfying.. by people who get to it. It vexes you plenty on the way there
        ```

  - u/ToaKraka:
    ```
    > As an aside, are people aware how much the readership is skewed female when it comes to fanfiction?

    [It's an established trope.](https://allthetropes.org/wiki/Most_Fanfic_Writers_Are_Girls)
    ```

  - u/SevereCircle:
    ```
    See also, AO3 stats: https://archiveofourown.org/works/16851121 (it's a list of fandoms sorted by fic count, not an actual story)

    > one or more high status female characters in the story

    [Very much not a requirement.](https://imgur.com/YkiH1va)
    ```

  - u/tjhance:
    ```
    why do you say that half of the are almost exclusively appealing to girls?

    I count twilight and Glee. I don't know anything about Supernatural, Hetalia, Inuyasha, bleach, or Once Upon a Time, but that's still at most 7.

    (Granted, if it turns out that all the ones I was unfamiliar with turn out to be "exclusively appealing to girls", well, I suppose that's to be expected.)
    ```

    - u/GlueBoy:
      ```
      I was counting Twilight, Supernatural, Hetalia, Inuyasha, Glee, Doctor Who, Fairy Tail, Sherlock, Once Upon a Time, that's nine. On top of that, Kingdom Hearts and Percy Jackson are close. It's not so much about the audience of the original work, but the fanfic community.
      ```

  - u/MugaSofer:
    ```
    > Luke is Leia's sibling

    I think the Supernatural fandom proves that that's not necessarily a barrier. Also, what about Lando, or wackier options like Chewie or Boba Fett?

    I think the tendency of fandoms to *invent* ships may be creating some reverse causation here.
    ```

  - u/alexanderwales:
    ```
    I actually have an unfinished blog post about this. In short, the biggest thing you can do, if you want to optimize for making things ficcable for whatever reason, are:

    1. Be really, really popular and universally seen by an audience who writes a lot of fanfic, i.e. young people in their formative years, mostly female.
    2. Have defined Stations of the Canon that fanfic authors can riff on.
    3. Have compelling characters who aren't fully explored in the work itself, especially including side characters who leave an impression but don't feature in the story all that much. Being able to have X/Y matchups with combinatoric explosion helps.
    4. Have a universe with extensible, toybox rules, especially weak ones that allow a lot of leeway and interpretation.
    5. Have in-universe categorization and analysis schemes that allow people to slot themselves into the world and thereby say something about themselves, or about the characters that they're writing.
    ```

- u/dragonblaz9:
  ```
  So I'm trying to establish some sort of infohazard/cognitohazard/other form of being compromised protocol for my DnD party, and they're generally into the idea. However, I'm struggling to come up with a concept that is practically feasible in the tabletop setting. Was thinking about using the "keyring" protocol from worth the candle, but I couldn't find a good description of how it actually worked, and I don't remember the first chapter it was introduced. 

  Anyone have an idea if that would work for my party/any other good schema to use? 

  Also, any general protocols to follow for that sort of thing would be helpful, since we don't yet have a great set of infohazard policies.

  Edit: typos
  ```

  - u/alexanderwales:
    ```
    The "keyring" identification method is security through obscurity, mostly, and not recommended for general use. It's *slightly* better than just having memorized passphrases, because it's general, and new challenges can be produced using it, and it's easy to remember, but it's far from proof against adversaries, especially those that might be able to extract memories, compromise individuals, or hundreds of other exotic attacks available through magic. It *can* help to trip up people using other methods though.

    The "keyring" appears three times in the text, with the last one truncated:

    * Call: Rhodonite
    * Response: Apricot
    * Response: Mourning

    Later:

    * Call: Dolomite
    * Response: Oak
    * Response: Excitement

    Later (not finished): 

    * Call: Granite

    From this, you can probably figure out the requirements and how to generate your own call and response chains (note: if the first two are dolomite and oak, the third could be glum or excitement, but not listless or pleased). The only thing that this really does is to serve as proof that *either* it's your ally *or* the enemy has knowledge of the protocol, which is about as good as you could ask for unless you have computing capabilities, in which case you could do a public/private key thing.

    In a world where you have mind-readers, doppelgangers, spells that can completely and totally turn a person to the other side, and all kinds of other stuff, it's my belief that you're never going to have a protocol that helps too much, except that it provides weak proof against certain forms of attack.
    ```

- u/Roxolan:
  ```
  "Matthew Carter, how can I help you?"

  "Hi, this is the demon you summoned a few weeks ago, is this a good time?"

  "Hell has cell service now? It's not, especially. I'm at work."

  "I can call back later."

  "Thank you. I plan to retire in ten years." *Click.*
  ```

- u/icingdeath9999:
  ```
  Asking for recommendations, not something strictly rational perse. I am looking for books that have a badass/competent protagonist like "a practical guide to evil" or worm with lots of character development.

  I life for the days that new chapters of PGTE come out and the occasional chapter dump of worth the candle.
  Need reading material to take my mind off, weekends are to long :)
  ```

  - u/Roxolan:
    ```
    Badass/competent + character development you say? May I recommend Zelazny's *The Chronicles of Amber* (Corwin cycle only). 

    For all that the major characters are very old immortals, I've always been stricken by how much growing up they do over the course of the series.
    ```

  - u/red_adair:
    ```
    Hatchet, by Gary Paulson.

    [My Side of the Mountain](https://en.wikipedia.org/wiki/My_Side_of_the_Mountain).

    The Laundry Files, by Charles Stross.
    ```

  - u/sparkc:
    ```
    In terms of published fiction Matthew Stovers ‘Caine’ series is exactly what you’re looking for, beginning with ‘Heroes Die’.
    ```

  - u/waylandertheslayer:
    ```
    The Codex Alera series by Jim Butcher definitely qualifies. The first book is 'Furies of Calderon', and the whole (six-book) series is complete.
    ```

  - u/Veedrac:
    ```
    **If** you can stand the genre, Forty Millenniums of Cultivation. One of my favourite pieces of writing, extremely badass, good quantity of character development later on, generally all around rational/ist. Certainly your weekends won't be too long for this, there are >1000 translated chapters, and it's still going strong.
    ```

- u/iftttAcct2:
  ```
  I hadn't seen this before and thought people might enjoy it:

  [When r/rational goes too far](https://www.youtube.com/watch?v=x2Y5-4kLb5I)
  ```

---

