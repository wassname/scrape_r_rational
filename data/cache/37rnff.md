## [HSF][DC]Android Stress Test

### Post:

[Link to content](http://imgur.com/gallery/oIDB4)

### Comments:

- u/None:
  ```
  [deleted]
  ```

  - u/rdestenay:
    ```
    I'm curious, what are you're criteria for considering it equal to human?
    ```

    - u/FuguofAnotherWorld:
      ```
      In this case; pain, confusion, fear, human level emotions and expressions. Internal monologue involving conscious though even when muted. An AI designed to give the appearance of humanity without the attendant emotions would not have worried in such a manner about the broken finger after being muted. Obviously from such a short you can't get the full story but from what we can see it seems to be thinking just like a person with only a few differences regarding not being allowed to defend itself and the rather unimportant matter of using silicon instead of carbon as the computing substrate.
      ```

- u/Traiden04:
  ```
  I found this while surfing the internet and felt that I must share it with you fine folks here at /r/rational. I really think this might actually happen and need to have a good long think about this and how it made me feel. I would also like to hear your thoughts on this, and your reactions.
  ```

  - u/None:
    ```
    Well, at this time, the top imgur comment says roughly:

    >I thought he was gonna rape it.

    I'm damn glad that didn't happen.  Look, in real life, I don't think we're actually going to have androids with humanlike minds, emotions, and subjective experiences (unless someone already human ditched their meat-body and wanted a meat-like android body for some reason), but within the fictional conceit of doing so, I'm pretty damn ticked off.  *Beating and murdering children is a special kind of evil.*

    Also, mangaka are still doing a good job of pretending Japan is a world leader in scifi-grade high technology despite two and a half Lost Decades.
    ```

    - u/BadGoyWithAGun:
      ```
      >Also, mangaka are still doing a good job of pretending Japan is a world leader in scifi-grade high technology despite two and a half Lost Decades.

      This one's Korean, or at least the untranslated exclamation balloons are.
      ```

- u/Nighzmarquls:
  ```
  I think that on the one hand having a machine that did feel emotional things like a meat organism is kind of disgusting (I can't in good conscience say this is even just the purview of mammals when they are finding results that suggest fruit flies have a fear response).

  But having an android that is willing to 'play the part' has it's place.

  However the ethics of it shift in that regard from the actual torture of a self aware being, and it being a DEPICTION of the torture of a self aware being.

  That is different ethical question for me.
  ```

- u/xamueljones:
  ```
  From the title, I thought it was about stress testing an Android phone.

  From the comments, I thought it was about stress testing an Android phone's ability to make emotional sounds and this was a post to talk about the ethics of listening to a phone screaming and whimpering.

  From the first few images, I thought it was going to be about rape and I was very annoyed that there wasn't a NSFW tag here. I wanted to click away, but I had to know why anyone would post it to here.

  What I got was so, so, so much worse......

  It was an ethical gut punch.

  It wasn't visually horrible in any way. There was no gore, no blood, no viscerally disgusting images, or anything else that would make me have an instinctive reaction. But seeing one possible way humans could treat machines so good at emotional reactions that it's a challenge to say whether or not she's sentient (I already think of her as a person after just a few images!), this makes me feel sad to see the limitations of [human empathy](http://en.wikipedia.org/wiki/Dunbar%27s_number).
  ```

  - u/autowikibot:
    ```
    #####&#009;

    ######&#009;

    ####&#009;
     [**Dunbar's number**](https://en.wikipedia.org/wiki/Dunbar%27s%20number): [](#sfw) 

    ---

    >__Dunbar's number__ is a suggested [cognitive](https://en.wikipedia.org/wiki/Cognition) limit to the number of people with whom one can maintain stable [social relationships](https://en.wikipedia.org/wiki/Interpersonal_relationship). These are relationships in which an [individual](https://en.wikipedia.org/wiki/Individual) knows who each person is and how each person relates to every other person.       This number was first proposed in the 1990s by British [anthropologist](https://en.wikipedia.org/wiki/Anthropology) [Robin Dunbar](https://en.wikipedia.org/wiki/Robin_Dunbar), who found a correlation between primate brain size and average social group size.  By using the average human brain size and extrapolating from the results of primates, he proposed that humans can only comfortably maintain 150 stable relationships.  Proponents assert that numbers larger than this generally require more restrictive rules, laws, and enforced norms to maintain a stable, cohesive [group](https://en.wikipedia.org/wiki/Social_group). It has been proposed to lie between 100 and 250, with a commonly used value of 150.   Dunbar's number states the number of people one knows and keeps social contact with, and it does not include the number of people known personally with a ceased social relationship, nor people just generally known with a lack of persistent social relationship, a number which might be much higher and likely depends on [long-term memory](https://en.wikipedia.org/wiki/Long-term_memory) size.

    >

    ---

    ^Interesting: [^Robin ^Dunbar](https://en.wikipedia.org/wiki/Robin_Dunbar) ^| [^Clique](https://en.wikipedia.org/wiki/Clique) ^| [^Attention ^management](https://en.wikipedia.org/wiki/Attention_management) ^| [^Social ^thermodynamics ^theory](https://en.wikipedia.org/wiki/Social_thermodynamics_theory) 

    ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&subject=AutoWikibot NSFW toggle&message=%2Btoggle-nsfw+crphmxp) ^or[](#or) [^delete](/message/compose?to=autowikibot&subject=AutoWikibot Deletion&message=%2Bdelete+crphmxp)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
    ```

---

